{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DataFrameOperations",
            "id": "DataFrameOperations-tj6w0",
            "name": "output",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "DataFrameOperations-wInpK",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-DataFrameOperations-tj6w0{œdataTypeœ:œDataFrameOperationsœ,œidœ:œDataFrameOperations-tj6w0œ,œnameœ:œoutputœ,œoutput_typesœ:[œDataFrameœ]}-DataFrameOperations-wInpK{œfieldNameœ:œdfœ,œidœ:œDataFrameOperations-wInpKœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "DataFrameOperations-tj6w0",
        "sourceHandle": "{œdataTypeœ:œDataFrameOperationsœ,œidœ:œDataFrameOperations-tj6w0œ,œnameœ:œoutputœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "DataFrameOperations-wInpK",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œDataFrameOperations-wInpKœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DataFrameOperations",
            "id": "DataFrameOperations-wInpK",
            "name": "output",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "DataFrameOperations-sTdsg",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-DataFrameOperations-wInpK{œdataTypeœ:œDataFrameOperationsœ,œidœ:œDataFrameOperations-wInpKœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataFrameœ]}-DataFrameOperations-sTdsg{œfieldNameœ:œdfœ,œidœ:œDataFrameOperations-sTdsgœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "DataFrameOperations-wInpK",
        "sourceHandle": "{œdataTypeœ:œDataFrameOperationsœ,œidœ:œDataFrameOperations-wInpKœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "DataFrameOperations-sTdsg",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œDataFrameOperations-sTdsgœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "VllmChatModel",
            "id": "VllmChatModel-rUKJT",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "judge_llm",
            "id": "LLMRouterComponent-skDFt",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-VllmChatModel-rUKJT{œdataTypeœ:œVllmChatModelœ,œidœ:œVllmChatModel-rUKJTœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-LLMRouterComponent-skDFt{œfieldNameœ:œjudge_llmœ,œidœ:œLLMRouterComponent-skDFtœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "VllmChatModel-rUKJT",
        "sourceHandle": "{œdataTypeœ:œVllmChatModelœ,œidœ:œVllmChatModel-rUKJTœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "LLMRouterComponent-skDFt",
        "targetHandle": "{œfieldNameœ:œjudge_llmœ,œidœ:œLLMRouterComponent-skDFtœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Directory",
            "id": "Directory-Hvzf0",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "LoopPlusComponent-cRenT",
            "inputTypes": [
              "Data",
              "DataInput",
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-Directory-Hvzf0{œdataTypeœ:œDirectoryœ,œidœ:œDirectory-Hvzf0œ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-LoopPlusComponent-cRenT{œfieldNameœ:œdataœ,œidœ:œLoopPlusComponent-cRenTœ,œinputTypesœ:[œDataœ,œDataInputœ,œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "Directory-Hvzf0",
        "sourceHandle": "{œdataTypeœ:œDirectoryœ,œidœ:œDirectory-Hvzf0œ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "LoopPlusComponent-cRenT",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œLoopPlusComponent-cRenTœ,œinputTypesœ:[œDataœ,œDataInputœ,œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LoopPlusComponent",
            "id": "LoopPlusComponent-cRenT",
            "name": "item",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-WcjW2",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-LoopPlusComponent-cRenT{œdataTypeœ:œLoopPlusComponentœ,œidœ:œLoopPlusComponent-cRenTœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}-ParserComponent-WcjW2{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-WcjW2œ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "LoopPlusComponent-cRenT",
        "sourceHandle": "{œdataTypeœ:œLoopPlusComponentœ,œidœ:œLoopPlusComponent-cRenTœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParserComponent-WcjW2",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-WcjW2œ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LoopPlusComponent",
            "id": "LoopPlusComponent-cRenT",
            "name": "done",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-4g5OK",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-LoopPlusComponent-cRenT{œdataTypeœ:œLoopPlusComponentœ,œidœ:œLoopPlusComponent-cRenTœ,œnameœ:œdoneœ,œoutput_typesœ:[œDataFrameœ]}-ChatOutput-4g5OK{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-4g5OKœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "LoopPlusComponent-cRenT",
        "sourceHandle": "{œdataTypeœ:œLoopPlusComponentœ,œidœ:œLoopPlusComponent-cRenTœ,œnameœ:œdoneœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ChatOutput-4g5OK",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-4g5OKœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-J4S7M",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "template",
            "id": "VariablePromptComponent-gbzH7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-J4S7M{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-J4S7Mœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-VariablePromptComponent-gbzH7{œfieldNameœ:œtemplateœ,œidœ:œVariablePromptComponent-gbzH7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-J4S7M",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-J4S7Mœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "VariablePromptComponent-gbzH7",
        "targetHandle": "{œfieldNameœ:œtemplateœ,œidœ:œVariablePromptComponent-gbzH7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-F1CeB",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "file_name",
            "id": "VariablePromptComponent-gbzH7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-F1CeB{œdataTypeœ:œTextInputœ,œidœ:œTextInput-F1CeBœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-VariablePromptComponent-gbzH7{œfieldNameœ:œfile_nameœ,œidœ:œVariablePromptComponent-gbzH7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-F1CeB",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-F1CeBœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "VariablePromptComponent-gbzH7",
        "targetHandle": "{œfieldNameœ:œfile_nameœ,œidœ:œVariablePromptComponent-gbzH7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "VariablePromptComponent",
            "id": "VariablePromptComponent-gbzH7",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "TypeConverterComponent-U7VX1",
            "inputTypes": [
              "Message",
              "Data",
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-VariablePromptComponent-gbzH7{œdataTypeœ:œVariablePromptComponentœ,œidœ:œVariablePromptComponent-gbzH7œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-TypeConverterComponent-U7VX1{œfieldNameœ:œinput_dataœ,œidœ:œTypeConverterComponent-U7VX1œ,œinputTypesœ:[œMessageœ,œDataœ,œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "VariablePromptComponent-gbzH7",
        "sourceHandle": "{œdataTypeœ:œVariablePromptComponentœ,œidœ:œVariablePromptComponent-gbzH7œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TypeConverterComponent-U7VX1",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œTypeConverterComponent-U7VX1œ,œinputTypesœ:[œMessageœ,œDataœ,œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CreateList",
            "id": "CreateList-qjl02",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "LoopPlusComponent-sR9vl",
            "inputTypes": [
              "Data",
              "DataInput",
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CreateList-qjl02{œdataTypeœ:œCreateListœ,œidœ:œCreateList-qjl02œ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-LoopPlusComponent-sR9vl{œfieldNameœ:œdataœ,œidœ:œLoopPlusComponent-sR9vlœ,œinputTypesœ:[œDataœ,œDataInputœ,œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CreateList-qjl02",
        "sourceHandle": "{œdataTypeœ:œCreateListœ,œidœ:œCreateList-qjl02œ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "LoopPlusComponent-sR9vl",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œLoopPlusComponent-sR9vlœ,œinputTypesœ:[œDataœ,œDataInputœ,œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LoopPlusComponent",
            "id": "LoopPlusComponent-sR9vl",
            "name": "item",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-J4S7M",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-LoopPlusComponent-sR9vl{œdataTypeœ:œLoopPlusComponentœ,œidœ:œLoopPlusComponent-sR9vlœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}-ParserComponent-J4S7M{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-J4S7Mœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "LoopPlusComponent-sR9vl",
        "sourceHandle": "{œdataTypeœ:œLoopPlusComponentœ,œidœ:œLoopPlusComponent-sR9vlœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParserComponent-J4S7M",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-J4S7Mœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TypeConverterComponent",
            "id": "TypeConverterComponent-U7VX1",
            "name": "data_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "dataType": "LoopPlusComponent",
            "id": "LoopPlusComponent-sR9vl",
            "name": "item",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-TypeConverterComponent-U7VX1{œdataTypeœ:œTypeConverterComponentœ,œidœ:œTypeConverterComponent-U7VX1œ,œnameœ:œdata_outputœ,œoutput_typesœ:[œDataœ]}-LoopPlusComponent-sR9vl{œdataTypeœ:œLoopPlusComponentœ,œidœ:œLoopPlusComponent-sR9vlœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}",
        "selected": false,
        "source": "TypeConverterComponent-U7VX1",
        "sourceHandle": "{œdataTypeœ:œTypeConverterComponentœ,œidœ:œTypeConverterComponent-U7VX1œ,œnameœ:œdata_outputœ,œoutput_typesœ:[œDataœ]}",
        "target": "LoopPlusComponent-sR9vl",
        "targetHandle": "{œdataTypeœ:œLoopPlusComponentœ,œidœ:œLoopPlusComponent-sR9vlœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LoopPlusComponent",
            "id": "LoopPlusComponent-sR9vl",
            "name": "done",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "DataFrameOperations-iendh",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-LoopPlusComponent-sR9vl{œdataTypeœ:œLoopPlusComponentœ,œidœ:œLoopPlusComponent-sR9vlœ,œnameœ:œdoneœ,œoutput_typesœ:[œDataFrameœ]}-DataFrameOperations-iendh{œfieldNameœ:œdfœ,œidœ:œDataFrameOperations-iendhœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "LoopPlusComponent-sR9vl",
        "sourceHandle": "{œdataTypeœ:œLoopPlusComponentœ,œidœ:œLoopPlusComponent-sR9vlœ,œnameœ:œdoneœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "DataFrameOperations-iendh",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œDataFrameOperations-iendhœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-BkcR6",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text2",
            "id": "CombineText-X7Dk0",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-BkcR6{œdataTypeœ:œTextInputœ,œidœ:œTextInput-BkcR6œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CombineText-X7Dk0{œfieldNameœ:œtext2œ,œidœ:œCombineText-X7Dk0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-BkcR6",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-BkcR6œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-X7Dk0",
        "targetHandle": "{œfieldNameœ:œtext2œ,œidœ:œCombineText-X7Dk0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-YwVrd",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text2",
            "id": "CombineText-DkpBV",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-YwVrd{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YwVrdœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CombineText-DkpBV{œfieldNameœ:œtext2œ,œidœ:œCombineText-DkpBVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-YwVrd",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YwVrdœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-DkpBV",
        "targetHandle": "{œfieldNameœ:œtext2œ,œidœ:œCombineText-DkpBVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-ePwtA",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text2",
            "id": "CombineText-Qi7eN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-ePwtA{œdataTypeœ:œTextInputœ,œidœ:œTextInput-ePwtAœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CombineText-Qi7eN{œfieldNameœ:œtext2œ,œidœ:œCombineText-Qi7eNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-ePwtA",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-ePwtAœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-Qi7eN",
        "targetHandle": "{œfieldNameœ:œtext2œ,œidœ:œCombineText-Qi7eNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TransposeDataFrame",
            "id": "TransposeDataFrame-5XW4u",
            "name": "transposed_df",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-5WdEV",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-TransposeDataFrame-5XW4u{œdataTypeœ:œTransposeDataFrameœ,œidœ:œTransposeDataFrame-5XW4uœ,œnameœ:œtransposed_dfœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-5WdEV{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-5WdEVœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "TransposeDataFrame-5XW4u",
        "sourceHandle": "{œdataTypeœ:œTransposeDataFrameœ,œidœ:œTransposeDataFrame-5XW4uœ,œnameœ:œtransposed_dfœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-5WdEV",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-5WdEVœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-YICqp",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "BatchRunComponent-diRMN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-YICqp{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YICqpœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-BatchRunComponent-diRMN{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-diRMNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-YICqp",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YICqpœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "BatchRunComponent-diRMN",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-diRMNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-YICqp",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "BatchRunComponent-cXI9j",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-YICqp{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YICqpœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-BatchRunComponent-cXI9j{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-cXI9jœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-YICqp",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YICqpœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "BatchRunComponent-cXI9j",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-cXI9jœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-4CD6T",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text2",
            "id": "CombineText-GULRk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-4CD6T{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-4CD6Tœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-CombineText-GULRk{œfieldNameœ:œtext2œ,œidœ:œCombineText-GULRkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-4CD6T",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-4CD6Tœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-GULRk",
        "targetHandle": "{œfieldNameœ:œtext2œ,œidœ:œCombineText-GULRkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RAGFlowChatModel",
            "id": "RAGFlowChatModel-y0w1w",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "model",
            "id": "BatchRunComponent-8dWWo",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-RAGFlowChatModel-y0w1w{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-y0w1wœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-BatchRunComponent-8dWWo{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-8dWWoœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "RAGFlowChatModel-y0w1w",
        "sourceHandle": "{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-y0w1wœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "BatchRunComponent-8dWWo",
        "targetHandle": "{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-8dWWoœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-YICqp",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "BatchRunComponent-8dWWo",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-YICqp{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YICqpœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-BatchRunComponent-8dWWo{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-8dWWoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-YICqp",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YICqpœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "BatchRunComponent-8dWWo",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-8dWWoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-cXI9j",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "BatchRunComponent-8dWWo",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-cXI9j{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-cXI9jœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-BatchRunComponent-8dWWo{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-8dWWoœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-cXI9j",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-cXI9jœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "BatchRunComponent-8dWWo",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-8dWWoœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-8oF62",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text3",
            "id": "CombineText-GULRk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-8oF62{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-8oF62œ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-CombineText-GULRk{œfieldNameœ:œtext3œ,œidœ:œCombineText-GULRkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-8oF62",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-8oF62œ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-GULRk",
        "targetHandle": "{œfieldNameœ:œtext3œ,œidœ:œCombineText-GULRkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-8dWWo",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "BatchRunComponent-2we8A",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-8dWWo{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-8dWWoœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-BatchRunComponent-2we8A{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-2we8Aœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-8dWWo",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-8dWWoœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "BatchRunComponent-2we8A",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-2we8Aœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RAGFlowChatModel",
            "id": "RAGFlowChatModel-y0w1w",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "model",
            "id": "BatchRunComponent-2we8A",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-RAGFlowChatModel-y0w1w{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-y0w1wœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-BatchRunComponent-2we8A{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-2we8Aœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "RAGFlowChatModel-y0w1w",
        "sourceHandle": "{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-y0w1wœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "BatchRunComponent-2we8A",
        "targetHandle": "{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-2we8Aœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-YICqp",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "BatchRunComponent-2we8A",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-YICqp{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YICqpœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-BatchRunComponent-2we8A{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-2we8Aœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-YICqp",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YICqpœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "BatchRunComponent-2we8A",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-2we8Aœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-2we8A",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "BatchRunComponent-5KjJT",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-2we8A{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-2we8Aœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-BatchRunComponent-5KjJT{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-5KjJTœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-2we8A",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-2we8Aœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "BatchRunComponent-5KjJT",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-5KjJTœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-YICqp",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "BatchRunComponent-5KjJT",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-YICqp{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YICqpœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-BatchRunComponent-5KjJT{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-5KjJTœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-YICqp",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YICqpœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "BatchRunComponent-5KjJT",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-5KjJTœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RAGFlowChatModel",
            "id": "RAGFlowChatModel-y0w1w",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "model",
            "id": "BatchRunComponent-5KjJT",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-RAGFlowChatModel-y0w1w{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-y0w1wœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-BatchRunComponent-5KjJT{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-5KjJTœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "RAGFlowChatModel-y0w1w",
        "sourceHandle": "{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-y0w1wœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "BatchRunComponent-5KjJT",
        "targetHandle": "{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-5KjJTœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RAGFlowChatModel",
            "id": "RAGFlowChatModel-y0w1w",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "model",
            "id": "BatchRunComponent-qweGM",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-RAGFlowChatModel-y0w1w{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-y0w1wœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-BatchRunComponent-qweGM{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-qweGMœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "RAGFlowChatModel-y0w1w",
        "sourceHandle": "{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-y0w1wœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "BatchRunComponent-qweGM",
        "targetHandle": "{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-qweGMœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-YICqp",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "BatchRunComponent-qweGM",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-YICqp{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YICqpœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-BatchRunComponent-qweGM{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-qweGMœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-YICqp",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YICqpœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "BatchRunComponent-qweGM",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-qweGMœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-jA80n",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text4",
            "id": "CombineText-GULRk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-jA80n{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-jA80nœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-CombineText-GULRk{œfieldNameœ:œtext4œ,œidœ:œCombineText-GULRkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-jA80n",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-jA80nœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-GULRk",
        "targetHandle": "{œfieldNameœ:œtext4œ,œidœ:œCombineText-GULRkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-d2GaL",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text5",
            "id": "CombineText-GULRk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-d2GaL{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-d2GaLœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-CombineText-GULRk{œfieldNameœ:œtext5œ,œidœ:œCombineText-GULRkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-d2GaL",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-d2GaLœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-GULRk",
        "targetHandle": "{œfieldNameœ:œtext5œ,œidœ:œCombineText-GULRkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-kGA1v",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text6",
            "id": "CombineText-GULRk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-kGA1v{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-kGA1vœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-CombineText-GULRk{œfieldNameœ:œtext6œ,œidœ:œCombineText-GULRkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-kGA1v",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-kGA1vœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-GULRk",
        "targetHandle": "{œfieldNameœ:œtext6œ,œidœ:œCombineText-GULRkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RAGFlowChatModel",
            "id": "RAGFlowChatModel-y0w1w",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "model",
            "id": "BatchRunComponent-diRMN",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-RAGFlowChatModel-y0w1w{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-y0w1wœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-BatchRunComponent-diRMN{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-diRMNœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "RAGFlowChatModel-y0w1w",
        "sourceHandle": "{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-y0w1wœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "BatchRunComponent-diRMN",
        "targetHandle": "{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-diRMNœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RAGFlowChatModel",
            "id": "RAGFlowChatModel-y0w1w",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "model",
            "id": "BatchRunComponent-cXI9j",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-RAGFlowChatModel-y0w1w{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-y0w1wœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-BatchRunComponent-cXI9j{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-cXI9jœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "RAGFlowChatModel-y0w1w",
        "sourceHandle": "{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-y0w1wœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "BatchRunComponent-cXI9j",
        "targetHandle": "{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-cXI9jœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "MessageToLocalFile",
            "id": "MessageToLocalFile-kbCOY",
            "name": "result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "field_1_key",
            "id": "CreateData-8fHO6",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "dict"
          }
        },
        "id": "reactflow__edge-MessageToLocalFile-kbCOY{œdataTypeœ:œMessageToLocalFileœ,œidœ:œMessageToLocalFile-kbCOYœ,œnameœ:œresultœ,œoutput_typesœ:[œMessageœ]}-CreateData-8fHO6{œfieldNameœ:œfield_1_keyœ,œidœ:œCreateData-8fHO6œ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œdictœ}",
        "selected": false,
        "source": "MessageToLocalFile-kbCOY",
        "sourceHandle": "{œdataTypeœ:œMessageToLocalFileœ,œidœ:œMessageToLocalFile-kbCOYœ,œnameœ:œresultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CreateData-8fHO6",
        "targetHandle": "{œfieldNameœ:œfield_1_keyœ,œidœ:œCreateData-8fHO6œ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œdictœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CreateData",
            "id": "CreateData-8fHO6",
            "name": "data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "dataType": "LoopPlusComponent",
            "id": "LoopPlusComponent-cRenT",
            "name": "item",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CreateData-8fHO6{œdataTypeœ:œCreateDataœ,œidœ:œCreateData-8fHO6œ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-LoopPlusComponent-cRenT{œdataTypeœ:œLoopPlusComponentœ,œidœ:œLoopPlusComponent-cRenTœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}",
        "selected": false,
        "source": "CreateData-8fHO6",
        "sourceHandle": "{œdataTypeœ:œCreateDataœ,œidœ:œCreateData-8fHO6œ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "LoopPlusComponent-cRenT",
        "targetHandle": "{œdataTypeœ:œLoopPlusComponentœ,œidœ:œLoopPlusComponent-cRenTœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-diRMN",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "BatchRunComponent-cXI9j",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-diRMN{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-diRMNœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-BatchRunComponent-cXI9j{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-cXI9jœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-diRMN",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-diRMNœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "BatchRunComponent-cXI9j",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-cXI9jœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-kOe2b",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text1",
            "id": "CombineText-GULRk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-kOe2b{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-kOe2bœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-CombineText-GULRk{œfieldNameœ:œtext1œ,œidœ:œCombineText-GULRkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-kOe2b",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-kOe2bœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-GULRk",
        "targetHandle": "{œfieldNameœ:œtext1œ,œidœ:œCombineText-GULRkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-4wUOO",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "file_path_msg",
            "id": "MoveFileComponent-2rbae",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-4wUOO{œdataTypeœ:œTextInputœ,œidœ:œTextInput-4wUOOœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-MoveFileComponent-2rbae{œfieldNameœ:œfile_path_msgœ,œidœ:œMoveFileComponent-2rbaeœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-4wUOO",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-4wUOOœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MoveFileComponent-2rbae",
        "targetHandle": "{œfieldNameœ:œfile_path_msgœ,œidœ:œMoveFileComponent-2rbaeœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "JSONtoData",
            "id": "JSONtoData-sEp7A",
            "name": "data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "FilterData-xN6hf",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-JSONtoData-sEp7A{œdataTypeœ:œJSONtoDataœ,œidœ:œJSONtoData-sEp7Aœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-FilterData-xN6hf{œfieldNameœ:œdataœ,œidœ:œFilterData-xN6hfœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "JSONtoData-sEp7A",
        "sourceHandle": "{œdataTypeœ:œJSONtoDataœ,œidœ:œJSONtoData-sEp7Aœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "FilterData-xN6hf",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œFilterData-xN6hfœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "JSONtoData",
            "id": "JSONtoData-sEp7A",
            "name": "data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "FilterData-5vIiT",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-JSONtoData-sEp7A{œdataTypeœ:œJSONtoDataœ,œidœ:œJSONtoData-sEp7Aœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-FilterData-5vIiT{œfieldNameœ:œdataœ,œidœ:œFilterData-5vIiTœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "JSONtoData-sEp7A",
        "sourceHandle": "{œdataTypeœ:œJSONtoDataœ,œidœ:œJSONtoData-sEp7Aœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "FilterData-5vIiT",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œFilterData-5vIiTœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "FilterData",
            "id": "FilterData-5vIiT",
            "name": "filtered_data",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "path",
            "id": "Directory-Hvzf0",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-FilterData-5vIiT{œdataTypeœ:œFilterDataœ,œidœ:œFilterData-5vIiTœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œMessageœ]}-Directory-Hvzf0{œfieldNameœ:œpathœ,œidœ:œDirectory-Hvzf0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "FilterData-5vIiT",
        "sourceHandle": "{œdataTypeœ:œFilterDataœ,œidœ:œFilterData-5vIiTœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Directory-Hvzf0",
        "targetHandle": "{œfieldNameœ:œpathœ,œidœ:œDirectory-Hvzf0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "JSONtoData",
            "id": "JSONtoData-sEp7A",
            "name": "data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "FilterData-nQJ3a",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-JSONtoData-sEp7A{œdataTypeœ:œJSONtoDataœ,œidœ:œJSONtoData-sEp7Aœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-FilterData-nQJ3a{œfieldNameœ:œdataœ,œidœ:œFilterData-nQJ3aœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "JSONtoData-sEp7A",
        "sourceHandle": "{œdataTypeœ:œJSONtoDataœ,œidœ:œJSONtoData-sEp7Aœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "FilterData-nQJ3a",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œFilterData-nQJ3aœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "JSONtoData",
            "id": "JSONtoData-sEp7A",
            "name": "data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "FilterData-KIDFD",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-JSONtoData-sEp7A{œdataTypeœ:œJSONtoDataœ,œidœ:œJSONtoData-sEp7Aœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-FilterData-KIDFD{œfieldNameœ:œdataœ,œidœ:œFilterData-KIDFDœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "JSONtoData-sEp7A",
        "sourceHandle": "{œdataTypeœ:œJSONtoDataœ,œidœ:œJSONtoData-sEp7Aœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "FilterData-KIDFD",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œFilterData-KIDFDœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "FilterData",
            "id": "FilterData-xN6hf",
            "name": "filtered_data",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "destination_dir_msg",
            "id": "MoveFileComponent-2rbae",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-FilterData-xN6hf{œdataTypeœ:œFilterDataœ,œidœ:œFilterData-xN6hfœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œMessageœ]}-MoveFileComponent-2rbae{œfieldNameœ:œdestination_dir_msgœ,œidœ:œMoveFileComponent-2rbaeœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "FilterData-xN6hf",
        "sourceHandle": "{œdataTypeœ:œFilterDataœ,œidœ:œFilterData-xN6hfœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MoveFileComponent-2rbae",
        "targetHandle": "{œfieldNameœ:œdestination_dir_msgœ,œidœ:œMoveFileComponent-2rbaeœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "FilterData",
            "id": "FilterData-nQJ3a",
            "name": "filtered_data",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "output_folder",
            "id": "MessageToLocalFile-kbCOY",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-FilterData-nQJ3a{œdataTypeœ:œFilterDataœ,œidœ:œFilterData-nQJ3aœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œMessageœ]}-MessageToLocalFile-kbCOY{œfieldNameœ:œoutput_folderœ,œidœ:œMessageToLocalFile-kbCOYœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "FilterData-nQJ3a",
        "sourceHandle": "{œdataTypeœ:œFilterDataœ,œidœ:œFilterData-nQJ3aœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MessageToLocalFile-kbCOY",
        "targetHandle": "{œfieldNameœ:œoutput_folderœ,œidœ:œMessageToLocalFile-kbCOYœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "JSONtoData",
            "id": "JSONtoData-sEp7A",
            "name": "data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "FilterData-RYq4v",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-JSONtoData-sEp7A{œdataTypeœ:œJSONtoDataœ,œidœ:œJSONtoData-sEp7Aœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-FilterData-RYq4v{œfieldNameœ:œdataœ,œidœ:œFilterData-RYq4vœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "JSONtoData-sEp7A",
        "sourceHandle": "{œdataTypeœ:œJSONtoDataœ,œidœ:œJSONtoData-sEp7Aœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "FilterData-RYq4v",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œFilterData-RYq4vœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "JSONtoData",
            "id": "JSONtoData-sEp7A",
            "name": "data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "FilterData-n0F3q",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-JSONtoData-sEp7A{œdataTypeœ:œJSONtoDataœ,œidœ:œJSONtoData-sEp7Aœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-FilterData-n0F3q{œfieldNameœ:œdataœ,œidœ:œFilterData-n0F3qœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "JSONtoData-sEp7A",
        "sourceHandle": "{œdataTypeœ:œJSONtoDataœ,œidœ:œJSONtoData-sEp7Aœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "FilterData-n0F3q",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œFilterData-n0F3qœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "FilterData",
            "id": "FilterData-RYq4v",
            "name": "filtered_data",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "ragflow_chat_id",
            "id": "RAGFlowChatModel-y0w1w",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-FilterData-RYq4v{œdataTypeœ:œFilterDataœ,œidœ:œFilterData-RYq4vœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œMessageœ]}-RAGFlowChatModel-y0w1w{œfieldNameœ:œragflow_chat_idœ,œidœ:œRAGFlowChatModel-y0w1wœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "FilterData-RYq4v",
        "sourceHandle": "{œdataTypeœ:œFilterDataœ,œidœ:œFilterData-RYq4vœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œMessageœ]}",
        "target": "RAGFlowChatModel-y0w1w",
        "targetHandle": "{œfieldNameœ:œragflow_chat_idœ,œidœ:œRAGFlowChatModel-y0w1wœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "FilterData",
            "id": "FilterData-n0F3q",
            "name": "filtered_data",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "ragflow_chat_api_key",
            "id": "RAGFlowChatModel-y0w1w",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-FilterData-n0F3q{œdataTypeœ:œFilterDataœ,œidœ:œFilterData-n0F3qœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œMessageœ]}-RAGFlowChatModel-y0w1w{œfieldNameœ:œragflow_chat_api_keyœ,œidœ:œRAGFlowChatModel-y0w1wœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "FilterData-n0F3q",
        "sourceHandle": "{œdataTypeœ:œFilterDataœ,œidœ:œFilterData-n0F3qœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œMessageœ]}",
        "target": "RAGFlowChatModel-y0w1w",
        "targetHandle": "{œfieldNameœ:œragflow_chat_api_keyœ,œidœ:œRAGFlowChatModel-y0w1wœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-diRMN",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-8xHeQ",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-diRMN{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-diRMNœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-8xHeQ{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-8xHeQœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-diRMN",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-diRMNœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-8xHeQ",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-8xHeQœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-8xHeQ",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "Memory-D3mVi",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-8xHeQ{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-8xHeQœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Memory-D3mVi{œfieldNameœ:œmessageœ,œidœ:œMemory-D3mViœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-8xHeQ",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-8xHeQœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Memory-D3mVi",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œMemory-D3mViœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-dQjhd",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextInput-YICqp",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt Template-dQjhd{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-dQjhdœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-TextInput-YICqp{œfieldNameœ:œinput_valueœ,œidœ:œTextInput-YICqpœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt Template-dQjhd",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-dQjhdœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TextInput-YICqp",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTextInput-YICqpœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-cXI9j",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-IeMjy",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-cXI9j{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-cXI9jœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-IeMjy{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-IeMjyœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-cXI9j",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-cXI9jœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-IeMjy",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-IeMjyœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-IeMjy",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "Memory-zXRE1",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-IeMjy{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-IeMjyœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Memory-zXRE1{œfieldNameœ:œmessageœ,œidœ:œMemory-zXRE1œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-IeMjy",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-IeMjyœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Memory-zXRE1",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œMemory-zXRE1œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-8dWWo",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-NWvdW",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-8dWWo{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-8dWWoœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-NWvdW{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-NWvdWœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-8dWWo",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-8dWWoœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-NWvdW",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-NWvdWœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-NWvdW",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "Memory-kkihI",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-NWvdW{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-NWvdWœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Memory-kkihI{œfieldNameœ:œmessageœ,œidœ:œMemory-kkihIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-NWvdW",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-NWvdWœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Memory-kkihI",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œMemory-kkihIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-2we8A",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-ZL7rg",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-2we8A{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-2we8Aœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-ZL7rg{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-ZL7rgœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-2we8A",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-2we8Aœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-ZL7rg",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-ZL7rgœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-ZL7rg",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "Memory-JxkYD",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-ZL7rg{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-ZL7rgœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Memory-JxkYD{œfieldNameœ:œmessageœ,œidœ:œMemory-JxkYDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-ZL7rg",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-ZL7rgœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Memory-JxkYD",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œMemory-JxkYDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-5KjJT",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-Lw8Y0",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-5KjJT{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-5KjJTœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-Lw8Y0{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-Lw8Y0œ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-5KjJT",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-5KjJTœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-Lw8Y0",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-Lw8Y0œ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-Lw8Y0",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "Memory-so4FG",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-Lw8Y0{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-Lw8Y0œ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Memory-so4FG{œfieldNameœ:œmessageœ,œidœ:œMemory-so4FGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-Lw8Y0",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-Lw8Y0œ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Memory-so4FG",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œMemory-so4FGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-qweGM",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-w2utj",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-qweGM{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-qweGMœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-w2utj{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-w2utjœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-qweGM",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-qweGMœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-w2utj",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-w2utjœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-w2utj",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "Memory-laxv0",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-w2utj{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-w2utjœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Memory-laxv0{œfieldNameœ:œmessageœ,œidœ:œMemory-laxv0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-w2utj",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-w2utjœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Memory-laxv0",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œMemory-laxv0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-WcjW2",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "RegexExtractorComponent-h1F8N",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-WcjW2{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-WcjW2œ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-RegexExtractorComponent-h1F8N{œfieldNameœ:œinput_textœ,œidœ:œRegexExtractorComponent-h1F8Nœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-WcjW2",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-WcjW2œ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "RegexExtractorComponent-h1F8N",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œRegexExtractorComponent-h1F8Nœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RegexExtractorComponent",
            "id": "RegexExtractorComponent-h1F8N",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "session_id",
            "id": "Memory-Y2uuC",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-RegexExtractorComponent-h1F8N{œdataTypeœ:œRegexExtractorComponentœ,œidœ:œRegexExtractorComponent-h1F8Nœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Memory-Y2uuC{œfieldNameœ:œsession_idœ,œidœ:œMemory-Y2uuCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "RegexExtractorComponent-h1F8N",
        "sourceHandle": "{œdataTypeœ:œRegexExtractorComponentœ,œidœ:œRegexExtractorComponent-h1F8Nœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Memory-Y2uuC",
        "targetHandle": "{œfieldNameœ:œsession_idœ,œidœ:œMemory-Y2uuCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RegexExtractorComponent",
            "id": "RegexExtractorComponent-h1F8N",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "session_id",
            "id": "Memory-D3mVi",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-RegexExtractorComponent-h1F8N{œdataTypeœ:œRegexExtractorComponentœ,œidœ:œRegexExtractorComponent-h1F8Nœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Memory-D3mVi{œfieldNameœ:œsession_idœ,œidœ:œMemory-D3mViœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "RegexExtractorComponent-h1F8N",
        "sourceHandle": "{œdataTypeœ:œRegexExtractorComponentœ,œidœ:œRegexExtractorComponent-h1F8Nœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Memory-D3mVi",
        "targetHandle": "{œfieldNameœ:œsession_idœ,œidœ:œMemory-D3mViœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RegexExtractorComponent",
            "id": "RegexExtractorComponent-h1F8N",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "session_id",
            "id": "Memory-zXRE1",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-RegexExtractorComponent-h1F8N{œdataTypeœ:œRegexExtractorComponentœ,œidœ:œRegexExtractorComponent-h1F8Nœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Memory-zXRE1{œfieldNameœ:œsession_idœ,œidœ:œMemory-zXRE1œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "RegexExtractorComponent-h1F8N",
        "sourceHandle": "{œdataTypeœ:œRegexExtractorComponentœ,œidœ:œRegexExtractorComponent-h1F8Nœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Memory-zXRE1",
        "targetHandle": "{œfieldNameœ:œsession_idœ,œidœ:œMemory-zXRE1œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RegexExtractorComponent",
            "id": "RegexExtractorComponent-h1F8N",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "session_id",
            "id": "Memory-kkihI",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-RegexExtractorComponent-h1F8N{œdataTypeœ:œRegexExtractorComponentœ,œidœ:œRegexExtractorComponent-h1F8Nœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Memory-kkihI{œfieldNameœ:œsession_idœ,œidœ:œMemory-kkihIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "RegexExtractorComponent-h1F8N",
        "sourceHandle": "{œdataTypeœ:œRegexExtractorComponentœ,œidœ:œRegexExtractorComponent-h1F8Nœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Memory-kkihI",
        "targetHandle": "{œfieldNameœ:œsession_idœ,œidœ:œMemory-kkihIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RegexExtractorComponent",
            "id": "RegexExtractorComponent-h1F8N",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "session_id",
            "id": "Memory-JxkYD",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-RegexExtractorComponent-h1F8N{œdataTypeœ:œRegexExtractorComponentœ,œidœ:œRegexExtractorComponent-h1F8Nœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Memory-JxkYD{œfieldNameœ:œsession_idœ,œidœ:œMemory-JxkYDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "RegexExtractorComponent-h1F8N",
        "sourceHandle": "{œdataTypeœ:œRegexExtractorComponentœ,œidœ:œRegexExtractorComponent-h1F8Nœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Memory-JxkYD",
        "targetHandle": "{œfieldNameœ:œsession_idœ,œidœ:œMemory-JxkYDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RegexExtractorComponent",
            "id": "RegexExtractorComponent-h1F8N",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "session_id",
            "id": "Memory-so4FG",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-RegexExtractorComponent-h1F8N{œdataTypeœ:œRegexExtractorComponentœ,œidœ:œRegexExtractorComponent-h1F8Nœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Memory-so4FG{œfieldNameœ:œsession_idœ,œidœ:œMemory-so4FGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "RegexExtractorComponent-h1F8N",
        "sourceHandle": "{œdataTypeœ:œRegexExtractorComponentœ,œidœ:œRegexExtractorComponent-h1F8Nœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Memory-so4FG",
        "targetHandle": "{œfieldNameœ:œsession_idœ,œidœ:œMemory-so4FGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RegexExtractorComponent",
            "id": "RegexExtractorComponent-h1F8N",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "session_id",
            "id": "Memory-laxv0",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-RegexExtractorComponent-h1F8N{œdataTypeœ:œRegexExtractorComponentœ,œidœ:œRegexExtractorComponent-h1F8Nœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Memory-laxv0{œfieldNameœ:œsession_idœ,œidœ:œMemory-laxv0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "RegexExtractorComponent-h1F8N",
        "sourceHandle": "{œdataTypeœ:œRegexExtractorComponentœ,œidœ:œRegexExtractorComponent-h1F8Nœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Memory-laxv0",
        "targetHandle": "{œfieldNameœ:œsession_idœ,œidœ:œMemory-laxv0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-WcjW2",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextInput-4wUOO",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-WcjW2{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-WcjW2œ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-TextInput-4wUOO{œfieldNameœ:œinput_valueœ,œidœ:œTextInput-4wUOOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-WcjW2",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-WcjW2œ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TextInput-4wUOO",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTextInput-4wUOOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-SuEWV",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input",
            "id": "MessageToLocalFile-X9sAz",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-SuEWV{œdataTypeœ:œTextInputœ,œidœ:œTextInput-SuEWVœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-MessageToLocalFile-X9sAz{œfieldNameœ:œinputœ,œidœ:œMessageToLocalFile-X9sAzœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-SuEWV",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-SuEWVœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MessageToLocalFile-X9sAz",
        "targetHandle": "{œfieldNameœ:œinputœ,œidœ:œMessageToLocalFile-X9sAzœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-qweGM",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "dataframe",
            "id": "ConcatDataFrame-PCzAc",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-qweGM{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-qweGMœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-ConcatDataFrame-PCzAc{œfieldNameœ:œdataframeœ,œidœ:œConcatDataFrame-PCzAcœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-qweGM",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-qweGMœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ConcatDataFrame-PCzAc",
        "targetHandle": "{œfieldNameœ:œdataframeœ,œidœ:œConcatDataFrame-PCzAcœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-5KjJT",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "BatchRunComponent-qweGM",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-5KjJT{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-5KjJTœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-BatchRunComponent-qweGM{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-qweGMœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-5KjJT",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-5KjJTœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "BatchRunComponent-qweGM",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-qweGMœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "FilterData",
            "id": "FilterData-KIDFD",
            "name": "filtered_data",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "destination_dir_msg",
            "id": "ConcatDataFrame-PCzAc",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-FilterData-KIDFD{œdataTypeœ:œFilterDataœ,œidœ:œFilterData-KIDFDœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œMessageœ]}-ConcatDataFrame-PCzAc{œfieldNameœ:œdestination_dir_msgœ,œidœ:œConcatDataFrame-PCzAcœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "FilterData-KIDFD",
        "sourceHandle": "{œdataTypeœ:œFilterDataœ,œidœ:œFilterData-KIDFDœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConcatDataFrame-PCzAc",
        "targetHandle": "{œfieldNameœ:œdestination_dir_msgœ,œidœ:œConcatDataFrame-PCzAcœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-40JUD",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "SplitMessageToQueryData-zMTZu",
            "inputTypes": [
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-Prompt Template-40JUD{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-40JUDœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-SplitMessageToQueryData-zMTZu{œfieldNameœ:œmessageœ,œidœ:œSplitMessageToQueryData-zMTZuœ,œinputTypesœ:[œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "Prompt Template-40JUD",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-40JUDœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "SplitMessageToQueryData-zMTZu",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œSplitMessageToQueryData-zMTZuœ,œinputTypesœ:[œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DataToDataFrame",
            "id": "DataToDataFrame-J7Pe5",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "BatchRunComponent-diRMN",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-DataToDataFrame-J7Pe5{œdataTypeœ:œDataToDataFrameœ,œidœ:œDataToDataFrame-J7Pe5œ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-BatchRunComponent-diRMN{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-diRMNœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "DataToDataFrame-J7Pe5",
        "sourceHandle": "{œdataTypeœ:œDataToDataFrameœ,œidœ:œDataToDataFrame-J7Pe5œ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "BatchRunComponent-diRMN",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-diRMNœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "MoveFileComponent",
            "id": "MoveFileComponent-2rbae",
            "name": "output_message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "file_name",
            "id": "Prompt Template-40JUD",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-MoveFileComponent-2rbae{œdataTypeœ:œMoveFileComponentœ,œidœ:œMoveFileComponent-2rbaeœ,œnameœ:œoutput_messageœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-40JUD{œfieldNameœ:œfile_nameœ,œidœ:œPrompt Template-40JUDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "MoveFileComponent-2rbae",
        "sourceHandle": "{œdataTypeœ:œMoveFileComponentœ,œidœ:œMoveFileComponent-2rbaeœ,œnameœ:œoutput_messageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-40JUD",
        "targetHandle": "{œfieldNameœ:œfile_nameœ,œidœ:œPrompt Template-40JUDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SplitMessageToQueryData",
            "id": "SplitMessageToQueryData-zMTZu",
            "name": "query_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "DataOperations-7E3hs",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-SplitMessageToQueryData-zMTZu{œdataTypeœ:œSplitMessageToQueryDataœ,œidœ:œSplitMessageToQueryData-zMTZuœ,œnameœ:œquery_dataœ,œoutput_typesœ:[œDataœ]}-DataOperations-7E3hs{œfieldNameœ:œdataœ,œidœ:œDataOperations-7E3hsœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "SplitMessageToQueryData-zMTZu",
        "sourceHandle": "{œdataTypeœ:œSplitMessageToQueryDataœ,œidœ:œSplitMessageToQueryData-zMTZuœ,œnameœ:œquery_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "DataOperations-7E3hs",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œDataOperations-7E3hsœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DataOperations",
            "id": "DataOperations-7E3hs",
            "name": "data_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data_list",
            "id": "DataToDataFrame-J7Pe5",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-DataOperations-7E3hs{œdataTypeœ:œDataOperationsœ,œidœ:œDataOperations-7E3hsœ,œnameœ:œdata_outputœ,œoutput_typesœ:[œDataœ]}-DataToDataFrame-J7Pe5{œfieldNameœ:œdata_listœ,œidœ:œDataToDataFrame-J7Pe5œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "DataOperations-7E3hs",
        "sourceHandle": "{œdataTypeœ:œDataOperationsœ,œidœ:œDataOperations-7E3hsœ,œnameœ:œdata_outputœ,œoutput_typesœ:[œDataœ]}",
        "target": "DataToDataFrame-J7Pe5",
        "targetHandle": "{œfieldNameœ:œdata_listœ,œidœ:œDataToDataFrame-J7Pe5œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "FilterData",
            "id": "FilterData-xN6hf",
            "name": "filtered_data",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "original_dir_msg",
            "id": "ConcatDataFrame-PCzAc",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-FilterData-xN6hf{œdataTypeœ:œFilterDataœ,œidœ:œFilterData-xN6hfœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œMessageœ]}-ConcatDataFrame-PCzAc{œfieldNameœ:œoriginal_dir_msgœ,œidœ:œConcatDataFrame-PCzAcœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "FilterData-xN6hf",
        "sourceHandle": "{œdataTypeœ:œFilterDataœ,œidœ:œFilterData-xN6hfœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConcatDataFrame-PCzAc",
        "targetHandle": "{œfieldNameœ:œoriginal_dir_msgœ,œidœ:œConcatDataFrame-PCzAcœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConcatDataFrame",
            "id": "ConcatDataFrame-PCzAc",
            "name": "concatenated_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input",
            "id": "MessageToLocalFile-kbCOY",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ConcatDataFrame-PCzAc{œdataTypeœ:œConcatDataFrameœ,œidœ:œConcatDataFrame-PCzAcœ,œnameœ:œconcatenated_dataœ,œoutput_typesœ:[œDataœ]}-MessageToLocalFile-kbCOY{œfieldNameœ:œinputœ,œidœ:œMessageToLocalFile-kbCOYœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConcatDataFrame-PCzAc",
        "sourceHandle": "{œdataTypeœ:œConcatDataFrameœ,œidœ:œConcatDataFrame-PCzAcœ,œnameœ:œconcatenated_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "MessageToLocalFile-kbCOY",
        "targetHandle": "{œfieldNameœ:œinputœ,œidœ:œMessageToLocalFile-kbCOYœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "DataFrameOperations-tj6w0",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Perform various operations on a DataFrame.",
            "display_name": "DataFrame Operations",
            "documentation": "https://docs.langflow.org/components-processing#dataframe-operations",
            "edited": false,
            "field_order": [
              "df",
              "operation",
              "column_name",
              "filter_value",
              "filter_operator",
              "ascending",
              "new_column_name",
              "new_column_value",
              "columns_to_select",
              "num_rows",
              "replace_value",
              "replacement_value"
            ],
            "frozen": false,
            "icon": "table",
            "key": "DataFrameOperations",
            "last_updated": "2026-02-02T03:24:48.880Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "loop_types": null,
                "method": "perform_operation",
                "name": "output",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_frontend_node_flow_id": {
                "value": "ce767eeb-d198-4f14-b5a1-2ec08b22b1ec"
              },
              "_frontend_node_folder_id": {
                "value": "ad4db6bf-94a7-4138-978a-b55a38dc9cf4"
              },
              "_type": "Component",
              "ascending": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Sort Ascending",
                "dynamic": true,
                "info": "Whether to sort in ascending order.",
                "list": false,
                "list_add_label": "Add More",
                "name": "ascending",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import pandas as pd\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs import SortableListInput\nfrom langflow.io import (\n    BoolInput,\n    DataFrameInput,\n    DropdownInput,\n    IntInput,\n    MessageTextInput,\n    Output,\n    StrInput,\n)\nfrom langflow.logging import logger\nfrom langflow.schema.dataframe import DataFrame\n\n\nclass DataFrameOperationsComponent(Component):\n    display_name = \"DataFrame Operations\"\n    description = \"Perform various operations on a DataFrame.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#dataframe-operations\"\n    icon = \"table\"\n    name = \"DataFrameOperations\"\n\n    OPERATION_CHOICES = [\n        \"Add Column\",\n        \"Drop Column\",\n        \"Filter\",\n        \"Head\",\n        \"Rename Column\",\n        \"Replace Value\",\n        \"Select Columns\",\n        \"Sort\",\n        \"Tail\",\n        \"Drop Duplicates\",\n    ]\n\n    inputs = [\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The input DataFrame to operate on.\",\n            required=True,\n        ),\n        SortableListInput(\n            name=\"operation\",\n            display_name=\"Operation\",\n            placeholder=\"Select Operation\",\n            info=\"Select the DataFrame operation to perform.\",\n            options=[\n                {\"name\": \"Add Column\", \"icon\": \"plus\"},\n                {\"name\": \"Drop Column\", \"icon\": \"minus\"},\n                {\"name\": \"Filter\", \"icon\": \"filter\"},\n                {\"name\": \"Head\", \"icon\": \"arrow-up\"},\n                {\"name\": \"Rename Column\", \"icon\": \"pencil\"},\n                {\"name\": \"Replace Value\", \"icon\": \"replace\"},\n                {\"name\": \"Select Columns\", \"icon\": \"columns\"},\n                {\"name\": \"Sort\", \"icon\": \"arrow-up-down\"},\n                {\"name\": \"Tail\", \"icon\": \"arrow-down\"},\n                {\"name\": \"Drop Duplicates\", \"icon\": \"copy-x\"},\n            ],\n            real_time_refresh=True,\n            limit=1,\n        ),\n        StrInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=\"The column name to use for the operation.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"filter_value\",\n            display_name=\"Filter Value\",\n            info=\"The value to filter rows by.\",\n            dynamic=True,\n            show=False,\n        ),\n        DropdownInput(\n            name=\"filter_operator\",\n            display_name=\"Filter Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"greater than\", \"less than\"],\n            value=\"equals\",\n            info=\"The operator to apply for filtering rows.\",\n            advanced=False,\n            dynamic=True,\n            show=False,\n        ),\n        BoolInput(\n            name=\"ascending\",\n            display_name=\"Sort Ascending\",\n            info=\"Whether to sort in ascending order.\",\n            dynamic=True,\n            show=False,\n            value=True,\n        ),\n        StrInput(\n            name=\"new_column_name\",\n            display_name=\"New Column Name\",\n            info=\"The new column name when renaming or adding a column.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"new_column_value\",\n            display_name=\"New Column Value\",\n            info=\"The value to populate the new column with.\",\n            dynamic=True,\n            show=False,\n        ),\n        StrInput(\n            name=\"columns_to_select\",\n            display_name=\"Columns to Select\",\n            dynamic=True,\n            is_list=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"num_rows\",\n            display_name=\"Number of Rows\",\n            info=\"Number of rows to return (for head/tail).\",\n            dynamic=True,\n            show=False,\n            value=5,\n        ),\n        MessageTextInput(\n            name=\"replace_value\",\n            display_name=\"Value to Replace\",\n            info=\"The value to replace in the column.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"replacement_value\",\n            display_name=\"Replacement Value\",\n            info=\"The value to replace with.\",\n            dynamic=True,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"DataFrame\",\n            name=\"output\",\n            method=\"perform_operation\",\n            info=\"The resulting DataFrame after the operation.\",\n        )\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        dynamic_fields = [\n            \"column_name\",\n            \"filter_value\",\n            \"filter_operator\",\n            \"ascending\",\n            \"new_column_name\",\n            \"new_column_value\",\n            \"columns_to_select\",\n            \"num_rows\",\n            \"replace_value\",\n            \"replacement_value\",\n        ]\n        for field in dynamic_fields:\n            build_config[field][\"show\"] = False\n\n        if field_name == \"operation\":\n            # Handle SortableListInput format\n            if isinstance(field_value, list):\n                operation_name = field_value[0].get(\"name\", \"\") if field_value else \"\"\n            else:\n                operation_name = field_value or \"\"\n\n            # If no operation selected, all dynamic fields stay hidden (already set to False above)\n            if not operation_name:\n                return build_config\n\n            if operation_name == \"Filter\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"filter_value\"][\"show\"] = True\n                build_config[\"filter_operator\"][\"show\"] = True\n            elif operation_name == \"Sort\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"ascending\"][\"show\"] = True\n            elif operation_name == \"Drop Column\":\n                build_config[\"column_name\"][\"show\"] = True\n            elif operation_name == \"Rename Column\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"new_column_name\"][\"show\"] = True\n            elif operation_name == \"Add Column\":\n                build_config[\"new_column_name\"][\"show\"] = True\n                build_config[\"new_column_value\"][\"show\"] = True\n            elif operation_name == \"Select Columns\":\n                build_config[\"columns_to_select\"][\"show\"] = True\n            elif operation_name in {\"Head\", \"Tail\"}:\n                build_config[\"num_rows\"][\"show\"] = True\n            elif operation_name == \"Replace Value\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"replace_value\"][\"show\"] = True\n                build_config[\"replacement_value\"][\"show\"] = True\n            elif operation_name == \"Drop Duplicates\":\n                build_config[\"column_name\"][\"show\"] = True\n\n        return build_config\n\n    def perform_operation(self) -> DataFrame:\n        df_copy = self.df.copy()\n\n        # Handle SortableListInput format for operation\n        operation_input = getattr(self, \"operation\", [])\n        if isinstance(operation_input, list) and len(operation_input) > 0:\n            op = operation_input[0].get(\"name\", \"\")\n        else:\n            op = \"\"\n\n        # If no operation selected, return original DataFrame\n        if not op:\n            return df_copy\n\n        if op == \"Filter\":\n            return self.filter_rows_by_value(df_copy)\n        if op == \"Sort\":\n            return self.sort_by_column(df_copy)\n        if op == \"Drop Column\":\n            return self.drop_column(df_copy)\n        if op == \"Rename Column\":\n            return self.rename_column(df_copy)\n        if op == \"Add Column\":\n            return self.add_column(df_copy)\n        if op == \"Select Columns\":\n            return self.select_columns(df_copy)\n        if op == \"Head\":\n            return self.head(df_copy)\n        if op == \"Tail\":\n            return self.tail(df_copy)\n        if op == \"Replace Value\":\n            return self.replace_values(df_copy)\n        if op == \"Drop Duplicates\":\n            return self.drop_duplicates(df_copy)\n        msg = f\"Unsupported operation: {op}\"\n        logger.error(msg)\n        raise ValueError(msg)\n\n    def filter_rows_by_value(self, df: DataFrame) -> DataFrame:\n        column = df[self.column_name]\n        filter_value = self.filter_value\n\n        # Handle regular DropdownInput format (just a string value)\n        operator = getattr(self, \"filter_operator\", \"equals\")  # Default to equals for backward compatibility\n\n        if operator == \"equals\":\n            mask = column == filter_value\n        elif operator == \"not equals\":\n            mask = column != filter_value\n        elif operator == \"contains\":\n            mask = column.astype(str).str.contains(str(filter_value), na=False)\n        elif operator == \"starts with\":\n            mask = column.astype(str).str.startswith(str(filter_value), na=False)\n        elif operator == \"ends with\":\n            mask = column.astype(str).str.endswith(str(filter_value), na=False)\n        elif operator == \"greater than\":\n            try:\n                # Try to convert filter_value to numeric for comparison\n                numeric_value = pd.to_numeric(filter_value)\n                mask = column > numeric_value\n            except (ValueError, TypeError):\n                # If conversion fails, compare as strings\n                mask = column.astype(str) > str(filter_value)\n        elif operator == \"less than\":\n            try:\n                # Try to convert filter_value to numeric for comparison\n                numeric_value = pd.to_numeric(filter_value)\n                mask = column < numeric_value\n            except (ValueError, TypeError):\n                # If conversion fails, compare as strings\n                mask = column.astype(str) < str(filter_value)\n        else:\n            mask = column == filter_value  # Fallback to equals\n\n        return DataFrame(df[mask])\n\n    def sort_by_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.sort_values(by=self.column_name, ascending=self.ascending))\n\n    def drop_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.drop(columns=[self.column_name]))\n\n    def rename_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.rename(columns={self.column_name: self.new_column_name}))\n\n    def add_column(self, df: DataFrame) -> DataFrame:\n        df[self.new_column_name] = [self.new_column_value] * len(df)\n        return DataFrame(df)\n\n    def select_columns(self, df: DataFrame) -> DataFrame:\n        columns = [col.strip() for col in self.columns_to_select]\n        return DataFrame(df[columns])\n\n    def head(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.head(self.num_rows))\n\n    def tail(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.tail(self.num_rows))\n\n    def replace_values(self, df: DataFrame) -> DataFrame:\n        df[self.column_name] = df[self.column_name].replace(self.replace_value, self.replacement_value)\n        return DataFrame(df)\n\n    def drop_duplicates(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.drop_duplicates(subset=self.column_name))\n"
              },
              "column_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": true,
                "info": "The column name to use for the operation.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "columns_to_select": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Columns to Select",
                "dynamic": true,
                "info": "",
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "columns_to_select",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "batch_index",
                  "model_response"
                ]
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The input DataFrame to operate on.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "filter_operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Filter Operator",
                "dynamic": true,
                "info": "The operator to apply for filtering rows.",
                "name": "filter_operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "greater than",
                  "less than"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "equals"
              },
              "filter_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Filter Value",
                "dynamic": true,
                "info": "The value to filter rows by.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "filter_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "new_column_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "New Column Name",
                "dynamic": true,
                "info": "The new column name when renaming or adding a column.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "new_column_name",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "new_column_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "New Column Value",
                "dynamic": true,
                "info": "The value to populate the new column with.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "new_column_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "num_rows": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Rows",
                "dynamic": true,
                "info": "Number of rows to return (for head/tail).",
                "list": false,
                "list_add_label": "Add More",
                "name": "num_rows",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "operation": {
                "_input_type": "SortableListInput",
                "advanced": false,
                "display_name": "Operation",
                "dynamic": false,
                "info": "Select the DataFrame operation to perform.",
                "limit": 1,
                "name": "operation",
                "options": [
                  {
                    "icon": "plus",
                    "name": "Add Column"
                  },
                  {
                    "icon": "minus",
                    "name": "Drop Column"
                  },
                  {
                    "icon": "filter",
                    "name": "Filter"
                  },
                  {
                    "icon": "arrow-up",
                    "name": "Head"
                  },
                  {
                    "icon": "pencil",
                    "name": "Rename Column"
                  },
                  {
                    "icon": "replace",
                    "name": "Replace Value"
                  },
                  {
                    "icon": "columns",
                    "name": "Select Columns"
                  },
                  {
                    "icon": "arrow-up-down",
                    "name": "Sort"
                  },
                  {
                    "icon": "arrow-down",
                    "name": "Tail"
                  },
                  {
                    "icon": "copy-x",
                    "name": "Drop Duplicates"
                  }
                ],
                "placeholder": "Select Operation",
                "real_time_refresh": true,
                "required": false,
                "search_category": [],
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "sortableList",
                "value": [
                  {
                    "chosen": false,
                    "icon": "columns",
                    "name": "Select Columns",
                    "selected": false
                  }
                ]
              },
              "replace_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Value to Replace",
                "dynamic": true,
                "info": "The value to replace in the column.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "replace_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "replacement_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Replacement Value",
                "dynamic": true,
                "info": "The value to replace with.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "replacement_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DataFrameOperations"
        },
        "dragging": false,
        "id": "DataFrameOperations-tj6w0",
        "measured": {
          "height": 375,
          "width": 320
        },
        "position": {
          "x": 865.181036522903,
          "y": -371.7845684186325
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DataFrameOperations-wInpK",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Perform various operations on a DataFrame.",
            "display_name": "DataFrame Operations",
            "documentation": "https://docs.langflow.org/components-processing#dataframe-operations",
            "edited": false,
            "field_order": [
              "df",
              "operation",
              "column_name",
              "filter_value",
              "filter_operator",
              "ascending",
              "new_column_name",
              "new_column_value",
              "columns_to_select",
              "num_rows",
              "replace_value",
              "replacement_value"
            ],
            "frozen": false,
            "icon": "table",
            "key": "DataFrameOperations",
            "last_updated": "2026-02-02T03:24:48.881Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "loop_types": null,
                "method": "perform_operation",
                "name": "output",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_frontend_node_flow_id": {
                "value": "ce767eeb-d198-4f14-b5a1-2ec08b22b1ec"
              },
              "_frontend_node_folder_id": {
                "value": "ad4db6bf-94a7-4138-978a-b55a38dc9cf4"
              },
              "_type": "Component",
              "ascending": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Sort Ascending",
                "dynamic": true,
                "info": "Whether to sort in ascending order.",
                "list": false,
                "list_add_label": "Add More",
                "name": "ascending",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import pandas as pd\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs import SortableListInput\nfrom langflow.io import (\n    BoolInput,\n    DataFrameInput,\n    DropdownInput,\n    IntInput,\n    MessageTextInput,\n    Output,\n    StrInput,\n)\nfrom langflow.logging import logger\nfrom langflow.schema.dataframe import DataFrame\n\n\nclass DataFrameOperationsComponent(Component):\n    display_name = \"DataFrame Operations\"\n    description = \"Perform various operations on a DataFrame.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#dataframe-operations\"\n    icon = \"table\"\n    name = \"DataFrameOperations\"\n\n    OPERATION_CHOICES = [\n        \"Add Column\",\n        \"Drop Column\",\n        \"Filter\",\n        \"Head\",\n        \"Rename Column\",\n        \"Replace Value\",\n        \"Select Columns\",\n        \"Sort\",\n        \"Tail\",\n        \"Drop Duplicates\",\n    ]\n\n    inputs = [\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The input DataFrame to operate on.\",\n            required=True,\n        ),\n        SortableListInput(\n            name=\"operation\",\n            display_name=\"Operation\",\n            placeholder=\"Select Operation\",\n            info=\"Select the DataFrame operation to perform.\",\n            options=[\n                {\"name\": \"Add Column\", \"icon\": \"plus\"},\n                {\"name\": \"Drop Column\", \"icon\": \"minus\"},\n                {\"name\": \"Filter\", \"icon\": \"filter\"},\n                {\"name\": \"Head\", \"icon\": \"arrow-up\"},\n                {\"name\": \"Rename Column\", \"icon\": \"pencil\"},\n                {\"name\": \"Replace Value\", \"icon\": \"replace\"},\n                {\"name\": \"Select Columns\", \"icon\": \"columns\"},\n                {\"name\": \"Sort\", \"icon\": \"arrow-up-down\"},\n                {\"name\": \"Tail\", \"icon\": \"arrow-down\"},\n                {\"name\": \"Drop Duplicates\", \"icon\": \"copy-x\"},\n            ],\n            real_time_refresh=True,\n            limit=1,\n        ),\n        StrInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=\"The column name to use for the operation.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"filter_value\",\n            display_name=\"Filter Value\",\n            info=\"The value to filter rows by.\",\n            dynamic=True,\n            show=False,\n        ),\n        DropdownInput(\n            name=\"filter_operator\",\n            display_name=\"Filter Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"greater than\", \"less than\"],\n            value=\"equals\",\n            info=\"The operator to apply for filtering rows.\",\n            advanced=False,\n            dynamic=True,\n            show=False,\n        ),\n        BoolInput(\n            name=\"ascending\",\n            display_name=\"Sort Ascending\",\n            info=\"Whether to sort in ascending order.\",\n            dynamic=True,\n            show=False,\n            value=True,\n        ),\n        StrInput(\n            name=\"new_column_name\",\n            display_name=\"New Column Name\",\n            info=\"The new column name when renaming or adding a column.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"new_column_value\",\n            display_name=\"New Column Value\",\n            info=\"The value to populate the new column with.\",\n            dynamic=True,\n            show=False,\n        ),\n        StrInput(\n            name=\"columns_to_select\",\n            display_name=\"Columns to Select\",\n            dynamic=True,\n            is_list=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"num_rows\",\n            display_name=\"Number of Rows\",\n            info=\"Number of rows to return (for head/tail).\",\n            dynamic=True,\n            show=False,\n            value=5,\n        ),\n        MessageTextInput(\n            name=\"replace_value\",\n            display_name=\"Value to Replace\",\n            info=\"The value to replace in the column.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"replacement_value\",\n            display_name=\"Replacement Value\",\n            info=\"The value to replace with.\",\n            dynamic=True,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"DataFrame\",\n            name=\"output\",\n            method=\"perform_operation\",\n            info=\"The resulting DataFrame after the operation.\",\n        )\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        dynamic_fields = [\n            \"column_name\",\n            \"filter_value\",\n            \"filter_operator\",\n            \"ascending\",\n            \"new_column_name\",\n            \"new_column_value\",\n            \"columns_to_select\",\n            \"num_rows\",\n            \"replace_value\",\n            \"replacement_value\",\n        ]\n        for field in dynamic_fields:\n            build_config[field][\"show\"] = False\n\n        if field_name == \"operation\":\n            # Handle SortableListInput format\n            if isinstance(field_value, list):\n                operation_name = field_value[0].get(\"name\", \"\") if field_value else \"\"\n            else:\n                operation_name = field_value or \"\"\n\n            # If no operation selected, all dynamic fields stay hidden (already set to False above)\n            if not operation_name:\n                return build_config\n\n            if operation_name == \"Filter\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"filter_value\"][\"show\"] = True\n                build_config[\"filter_operator\"][\"show\"] = True\n            elif operation_name == \"Sort\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"ascending\"][\"show\"] = True\n            elif operation_name == \"Drop Column\":\n                build_config[\"column_name\"][\"show\"] = True\n            elif operation_name == \"Rename Column\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"new_column_name\"][\"show\"] = True\n            elif operation_name == \"Add Column\":\n                build_config[\"new_column_name\"][\"show\"] = True\n                build_config[\"new_column_value\"][\"show\"] = True\n            elif operation_name == \"Select Columns\":\n                build_config[\"columns_to_select\"][\"show\"] = True\n            elif operation_name in {\"Head\", \"Tail\"}:\n                build_config[\"num_rows\"][\"show\"] = True\n            elif operation_name == \"Replace Value\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"replace_value\"][\"show\"] = True\n                build_config[\"replacement_value\"][\"show\"] = True\n            elif operation_name == \"Drop Duplicates\":\n                build_config[\"column_name\"][\"show\"] = True\n\n        return build_config\n\n    def perform_operation(self) -> DataFrame:\n        df_copy = self.df.copy()\n\n        # Handle SortableListInput format for operation\n        operation_input = getattr(self, \"operation\", [])\n        if isinstance(operation_input, list) and len(operation_input) > 0:\n            op = operation_input[0].get(\"name\", \"\")\n        else:\n            op = \"\"\n\n        # If no operation selected, return original DataFrame\n        if not op:\n            return df_copy\n\n        if op == \"Filter\":\n            return self.filter_rows_by_value(df_copy)\n        if op == \"Sort\":\n            return self.sort_by_column(df_copy)\n        if op == \"Drop Column\":\n            return self.drop_column(df_copy)\n        if op == \"Rename Column\":\n            return self.rename_column(df_copy)\n        if op == \"Add Column\":\n            return self.add_column(df_copy)\n        if op == \"Select Columns\":\n            return self.select_columns(df_copy)\n        if op == \"Head\":\n            return self.head(df_copy)\n        if op == \"Tail\":\n            return self.tail(df_copy)\n        if op == \"Replace Value\":\n            return self.replace_values(df_copy)\n        if op == \"Drop Duplicates\":\n            return self.drop_duplicates(df_copy)\n        msg = f\"Unsupported operation: {op}\"\n        logger.error(msg)\n        raise ValueError(msg)\n\n    def filter_rows_by_value(self, df: DataFrame) -> DataFrame:\n        column = df[self.column_name]\n        filter_value = self.filter_value\n\n        # Handle regular DropdownInput format (just a string value)\n        operator = getattr(self, \"filter_operator\", \"equals\")  # Default to equals for backward compatibility\n\n        if operator == \"equals\":\n            mask = column == filter_value\n        elif operator == \"not equals\":\n            mask = column != filter_value\n        elif operator == \"contains\":\n            mask = column.astype(str).str.contains(str(filter_value), na=False)\n        elif operator == \"starts with\":\n            mask = column.astype(str).str.startswith(str(filter_value), na=False)\n        elif operator == \"ends with\":\n            mask = column.astype(str).str.endswith(str(filter_value), na=False)\n        elif operator == \"greater than\":\n            try:\n                # Try to convert filter_value to numeric for comparison\n                numeric_value = pd.to_numeric(filter_value)\n                mask = column > numeric_value\n            except (ValueError, TypeError):\n                # If conversion fails, compare as strings\n                mask = column.astype(str) > str(filter_value)\n        elif operator == \"less than\":\n            try:\n                # Try to convert filter_value to numeric for comparison\n                numeric_value = pd.to_numeric(filter_value)\n                mask = column < numeric_value\n            except (ValueError, TypeError):\n                # If conversion fails, compare as strings\n                mask = column.astype(str) < str(filter_value)\n        else:\n            mask = column == filter_value  # Fallback to equals\n\n        return DataFrame(df[mask])\n\n    def sort_by_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.sort_values(by=self.column_name, ascending=self.ascending))\n\n    def drop_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.drop(columns=[self.column_name]))\n\n    def rename_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.rename(columns={self.column_name: self.new_column_name}))\n\n    def add_column(self, df: DataFrame) -> DataFrame:\n        df[self.new_column_name] = [self.new_column_value] * len(df)\n        return DataFrame(df)\n\n    def select_columns(self, df: DataFrame) -> DataFrame:\n        columns = [col.strip() for col in self.columns_to_select]\n        return DataFrame(df[columns])\n\n    def head(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.head(self.num_rows))\n\n    def tail(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.tail(self.num_rows))\n\n    def replace_values(self, df: DataFrame) -> DataFrame:\n        df[self.column_name] = df[self.column_name].replace(self.replace_value, self.replacement_value)\n        return DataFrame(df)\n\n    def drop_duplicates(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.drop_duplicates(subset=self.column_name))\n"
              },
              "column_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": true,
                "info": "The column name to use for the operation.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "model_response"
              },
              "columns_to_select": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Columns to Select",
                "dynamic": true,
                "info": "",
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "columns_to_select",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The input DataFrame to operate on.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "filter_operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Filter Operator",
                "dynamic": true,
                "info": "The operator to apply for filtering rows.",
                "name": "filter_operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "greater than",
                  "less than"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "equals"
              },
              "filter_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Filter Value",
                "dynamic": true,
                "info": "The value to filter rows by.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "filter_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "new_column_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "New Column Name",
                "dynamic": true,
                "info": "The new column name when renaming or adding a column.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "new_column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text"
              },
              "new_column_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "New Column Value",
                "dynamic": true,
                "info": "The value to populate the new column with.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "new_column_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "num_rows": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Rows",
                "dynamic": true,
                "info": "Number of rows to return (for head/tail).",
                "list": false,
                "list_add_label": "Add More",
                "name": "num_rows",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "operation": {
                "_input_type": "SortableListInput",
                "advanced": false,
                "display_name": "Operation",
                "dynamic": false,
                "info": "Select the DataFrame operation to perform.",
                "limit": 1,
                "name": "operation",
                "options": [
                  {
                    "icon": "plus",
                    "name": "Add Column"
                  },
                  {
                    "icon": "minus",
                    "name": "Drop Column"
                  },
                  {
                    "icon": "filter",
                    "name": "Filter"
                  },
                  {
                    "icon": "arrow-up",
                    "name": "Head"
                  },
                  {
                    "icon": "pencil",
                    "name": "Rename Column"
                  },
                  {
                    "icon": "replace",
                    "name": "Replace Value"
                  },
                  {
                    "icon": "columns",
                    "name": "Select Columns"
                  },
                  {
                    "icon": "arrow-up-down",
                    "name": "Sort"
                  },
                  {
                    "icon": "arrow-down",
                    "name": "Tail"
                  },
                  {
                    "icon": "copy-x",
                    "name": "Drop Duplicates"
                  }
                ],
                "placeholder": "Select Operation",
                "real_time_refresh": true,
                "required": false,
                "search_category": [],
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "sortableList",
                "value": [
                  {
                    "chosen": false,
                    "icon": "pencil",
                    "name": "Rename Column",
                    "selected": false
                  }
                ]
              },
              "replace_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Value to Replace",
                "dynamic": true,
                "info": "The value to replace in the column.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "replace_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "replacement_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Replacement Value",
                "dynamic": true,
                "info": "The value to replace with.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "replacement_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DataFrameOperations"
        },
        "dragging": false,
        "id": "DataFrameOperations-wInpK",
        "measured": {
          "height": 413,
          "width": 320
        },
        "position": {
          "x": 1270.6108307101167,
          "y": -346.8023148955267
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LLMRouterComponent-skDFt",
          "node": {
            "base_classes": [
              "Any",
              "Data",
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes the input to the most appropriate LLM based on OpenRouter model specifications",
            "display_name": "LLM Router",
            "documentation": "https://docs.langflow.org/components-processing#llm-router",
            "edited": true,
            "field_order": [
              "models",
              "input_value",
              "judge_llm",
              "optimization",
              "use_openrouter_specs",
              "timeout",
              "fallback_to_first"
            ],
            "frozen": false,
            "icon": "git-branch",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output",
                "group_outputs": false,
                "hidden": null,
                "method": "route_to_model",
                "name": "output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Selected Model Info",
                "group_outputs": false,
                "hidden": null,
                "method": "get_selected_model_info",
                "name": "selected_model_info",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Routing Decision",
                "group_outputs": false,
                "hidden": null,
                "method": "get_routing_decision",
                "name": "routing_decision",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "hidden": null,
                "method": "get_language_model",
                "name": "language_model",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel",
                  "Any"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import asyncio\nimport http  # Added for HTTPStatus\nimport json\nfrom typing import Any\n\nimport aiohttp\n\nfrom langflow.base.models.chat_result import get_chat_result\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, IntInput, MultilineInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass LLMRouterComponent(Component):\n    display_name = \"LLM Router\"\n    description = \"Routes the input to the most appropriate LLM based on OpenRouter model specifications\"\n    documentation: str = \"https://docs.langflow.org/components-processing#llm-router\"\n    icon = \"git-branch\"\n\n    # Constants for magic values\n    MAX_DESCRIPTION_LENGTH = 500\n    QUERY_PREVIEW_MAX_LENGTH = 1000\n\n    inputs = [\n        HandleInput(\n            name=\"models\",\n            display_name=\"Language Models\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n            is_list=True,\n            info=\"List of LLMs to route between\",\n        ),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            required=True,\n            info=\"The input message to be routed\",\n        ),\n        HandleInput(\n            name=\"judge_llm\",\n            display_name=\"Judge LLM\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n            info=\"LLM that will evaluate and select the most appropriate model\",\n        ),\n        DropdownInput(\n            name=\"optimization\",\n            display_name=\"Optimization\",\n            options=[\"quality\", \"speed\", \"cost\", \"balanced\"],\n            value=\"balanced\",\n            info=\"Optimization preference for model selection\",\n        ),\n        BoolInput(\n            name=\"use_openrouter_specs\",\n            display_name=\"Use OpenRouter Specs\",\n            value=True,\n            info=(\n                \"Fetch model specifications from OpenRouter API for enhanced routing decisions. \"\n                \"If false, only model names will be used.\"\n            ),\n            advanced=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"API Timeout\",\n            value=10,\n            info=\"Timeout for API requests in seconds\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"fallback_to_first\",\n            display_name=\"Fallback to First Model\",\n            value=True,\n            info=\"Use first model as fallback when routing fails\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"route_to_model\"),\n        Output(\n            display_name=\"Selected Model Info\",\n            name=\"selected_model_info\",\n            method=\"get_selected_model_info\",\n            types=[\"Data\"],\n        ),\n        Output(\n            display_name=\"Routing Decision\",\n            name=\"routing_decision\",\n            method=\"get_routing_decision\",\n        ),\n        Output(\n            display_name=\"Language Model\",\n            name=\"language_model\",\n            method=\"get_language_model\",\n            types=[\"LanguageModel\"],  # Batch Run accepts inputs of this type\n        ),\n    ]\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._selected_model_name: str | None = None\n        self._selected_api_model_id: str | None = None\n        self._routing_decision: str = \"\"\n        self._models_api_cache: dict[str, dict[str, Any]] = {}\n        self._model_name_to_api_id: dict[str, str] = {}\n\n    def _simplify_model_name(self, name: str) -> str:\n        \"\"\"Simplify model name for matching by lowercasing and removing non-alphanumerics.\"\"\"\n        return \"\".join(c.lower() for c in name if c.isalnum())\n\n    async def _fetch_openrouter_models_data(self) -> None:\n        \"\"\"Fetch all models from OpenRouter API and cache them along with name mappings.\"\"\"\n        if self._models_api_cache and self._model_name_to_api_id:\n            return\n\n        if not self.use_openrouter_specs:\n            self.log(\"OpenRouter specs are disabled. Skipping fetch.\")\n            return\n\n        try:\n            self.status = \"Fetching OpenRouter model specifications...\"\n            self.log(\"Fetching all model specifications from OpenRouter API: https://openrouter.ai/api/v1/models\")\n            async with (\n                aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=self.timeout)) as session,\n                session.get(\"https://openrouter.ai/api/v1/models\") as response,\n            ):\n                if response.status == http.HTTPStatus.OK:\n                    data = await response.json()\n                    models_list = data.get(\"data\", [])\n\n                    _models_api_cache_temp = {}\n                    _model_name_to_api_id_temp = {}\n\n                    for model_data in models_list:\n                        api_model_id = model_data.get(\"id\")\n                        if not api_model_id:\n                            continue\n\n                        _models_api_cache_temp[api_model_id] = model_data\n                        _model_name_to_api_id_temp[api_model_id] = api_model_id\n\n                        api_model_name = model_data.get(\"name\")\n                        if api_model_name:\n                            _model_name_to_api_id_temp[api_model_name] = api_model_id\n                            simplified_api_name = self._simplify_model_name(api_model_name)\n                            _model_name_to_api_id_temp[simplified_api_name] = api_model_id\n\n                        hugging_face_id = model_data.get(\"hugging_face_id\")\n                        if hugging_face_id:\n                            _model_name_to_api_id_temp[hugging_face_id] = api_model_id\n                            simplified_hf_id = self._simplify_model_name(hugging_face_id)\n                            _model_name_to_api_id_temp[simplified_hf_id] = api_model_id\n\n                        if \"/\" in api_model_id:\n                            try:\n                                model_name_part_of_id = api_model_id.split(\"/\", 1)[1]\n                                if model_name_part_of_id:\n                                    _model_name_to_api_id_temp[model_name_part_of_id] = api_model_id\n                                    simplified_part_id = self._simplify_model_name(model_name_part_of_id)\n                                    _model_name_to_api_id_temp[simplified_part_id] = api_model_id\n                            except IndexError:\n                                pass  # Should not happen if '/' is present\n\n                    self._models_api_cache = _models_api_cache_temp\n                    self._model_name_to_api_id = _model_name_to_api_id_temp\n                    log_msg = (\n                        f\"Successfully fetched and cached {len(self._models_api_cache)} \"\n                        f\"model specifications from OpenRouter.\"\n                    )\n                    self.log(log_msg)\n                else:\n                    err_text = await response.text()\n                    self.log(f\"Failed to fetch OpenRouter models: HTTP {response.status} - {err_text}\")\n                    self._models_api_cache = {}\n                    self._model_name_to_api_id = {}\n        except aiohttp.ClientError as e:\n            self.log(f\"AIOHTTP ClientError fetching OpenRouter models: {e!s}\", \"error\")\n            self._models_api_cache = {}\n            self._model_name_to_api_id = {}\n        except asyncio.TimeoutError:\n            self.log(\"Timeout fetching OpenRouter model specifications.\", \"error\")\n            self._models_api_cache = {}\n            self._model_name_to_api_id = {}\n        except json.JSONDecodeError as e:\n            self.log(f\"JSON decode error fetching OpenRouter models: {e!s}\", \"error\")\n            self._models_api_cache = {}\n            self._model_name_to_api_id = {}\n        finally:\n            self.status = \"\"\n\n    def _get_api_model_id_for_langflow_model(self, langflow_model_name: str) -> str | None:\n        \"\"\"Attempt to find the OpenRouter API ID for a given Langflow model name.\"\"\"\n        if not langflow_model_name:\n            return None\n\n        potential_names_to_check = [langflow_model_name, self._simplify_model_name(langflow_model_name)]\n\n        if langflow_model_name.startswith(\"models/\"):\n            name_without_prefix = langflow_model_name[len(\"models/\") :]\n            potential_names_to_check.append(name_without_prefix)\n            potential_names_to_check.append(self._simplify_model_name(name_without_prefix))\n\n        elif langflow_model_name.startswith(\"community_models/\"):\n            name_without_prefix = langflow_model_name[len(\"community_models/\") :]\n            potential_names_to_check.append(name_without_prefix)\n            simplified_no_prefix = self._simplify_model_name(name_without_prefix)\n            potential_names_to_check.append(simplified_no_prefix)\n\n        elif langflow_model_name.startswith(\"community_models/\"):\n            name_without_prefix = langflow_model_name[len(\"community_models/\") :]\n            potential_names_to_check.append(name_without_prefix)\n            simplified_no_prefix_comm = self._simplify_model_name(name_without_prefix)\n            potential_names_to_check.append(simplified_no_prefix_comm)\n\n        unique_names_to_check = list(dict.fromkeys(potential_names_to_check))\n\n        for name_variant in unique_names_to_check:\n            if name_variant in self._model_name_to_api_id:\n                return self._model_name_to_api_id[name_variant]\n\n        self.log(\n            f\"Could not map Langflow model name '{langflow_model_name}' \"\n            f\"(tried variants: {unique_names_to_check}) to an OpenRouter API ID.\"\n        )\n        return None\n\n    def _get_model_specs_dict(self, langflow_model_name: str) -> dict[str, Any]:\n        \"\"\"Get a dictionary of relevant model specifications for a given Langflow model name.\"\"\"\n        if not self.use_openrouter_specs or not self._models_api_cache:\n            return {\n                \"id\": langflow_model_name,\n                \"name\": langflow_model_name,\n                \"description\": \"Specifications not available.\",\n            }\n\n        api_model_id = self._get_api_model_id_for_langflow_model(langflow_model_name)\n\n        if not api_model_id or api_model_id not in self._models_api_cache:\n            log_msg = (\n                f\"No cached API data found for Langflow model '{langflow_model_name}' \"\n                f\"(mapped API ID: {api_model_id}). Returning basic info.\"\n            )\n            self.log(log_msg)\n            return {\n                \"id\": langflow_model_name,\n                \"name\": langflow_model_name,\n                \"description\": \"Full specifications not found in cache.\",\n            }\n\n        model_data = self._models_api_cache[api_model_id]\n        top_provider_data = model_data.get(\"top_provider\", {})\n        architecture_data = model_data.get(\"architecture\", {})\n        pricing_data = model_data.get(\"pricing\", {})\n        description = model_data.get(\"description\", \"No description available\")\n        truncated_description = (\n            description[: self.MAX_DESCRIPTION_LENGTH - 3] + \"...\"\n            if len(description) > self.MAX_DESCRIPTION_LENGTH\n            else description\n        )\n\n        specs = {\n            \"id\": model_data.get(\"id\"),\n            \"name\": model_data.get(\"name\"),\n            \"description\": truncated_description,\n            \"context_length\": top_provider_data.get(\"context_length\") or model_data.get(\"context_length\"),\n            \"max_completion_tokens\": (\n                top_provider_data.get(\"max_completion_tokens\") or model_data.get(\"max_completion_tokens\")\n            ),\n            \"tokenizer\": architecture_data.get(\"tokenizer\"),\n            \"input_modalities\": architecture_data.get(\"input_modalities\", []),\n            \"output_modalities\": architecture_data.get(\"output_modalities\", []),\n            \"pricing_prompt\": pricing_data.get(\"prompt\"),\n            \"pricing_completion\": pricing_data.get(\"completion\"),\n            \"is_moderated\": top_provider_data.get(\"is_moderated\"),\n            \"supported_parameters\": model_data.get(\"supported_parameters\", []),\n        }\n        return {k: v for k, v in specs.items() if v is not None}\n\n    def _create_system_prompt(self) -> str:\n        \"\"\"Create system prompt for the judge LLM.\"\"\"\n        return \"\"\"\\\nYou are an expert AI model selection specialist. Your task is to analyze the user's input query,\ntheir optimization preference, and a list of available models with their specifications,\nthen select the most appropriate model.\n\nEach model will be presented as a JSON object with its capabilities and characteristics.\n\nYour decision should be based on:\n1. Task complexity and requirements derived from the user's query.\n2. Context length needed for the input.\n3. Model capabilities (e.g., context window, input/output modalities, tokenizer).\n4. Pricing considerations, if relevant to the optimization preference.\n5. User's stated optimization preference (quality, speed, cost, balanced).\n\nReturn ONLY the index number (0, 1, 2, etc.) of the best model from the provided list.\nDo not provide any explanation or reasoning, just the index number.\nIf multiple models seem equally suitable according to the preference, you may pick the first one that matches.\nIf no model seems suitable, pick the first model in the list (index 0) as a fallback.\"\"\"\n\n    async def route_to_model(self) -> Message:\n        \"\"\"Main routing method.\"\"\"\n        if not self.models or not self.input_value or not self.judge_llm:\n            error_msg = \"Missing required inputs: models, input_value, or judge_llm\"\n            self.status = error_msg\n            self.log(f\"Validation Error: {error_msg}\", \"error\")\n            raise ValueError(error_msg)\n\n        successful_result: Message | None = None\n        try:\n            self.log(f\"Starting model routing with {len(self.models)} available Langflow models.\")\n            self.log(f\"Optimization preference: {self.optimization}\")\n            self.log(f\"Input length: {len(self.input_value)} characters\")\n\n            if self.use_openrouter_specs and not self._models_api_cache:\n                await self._fetch_openrouter_models_data()\n\n            system_prompt_content = self._create_system_prompt()\n            system_message = {\"role\": \"system\", \"content\": system_prompt_content}\n\n            self.status = \"Analyzing available models and preparing specifications...\"\n            model_specs_for_judge = []\n            for i, langflow_model_instance in enumerate(self.models):\n                langflow_model_name = get_model_name(langflow_model_instance)\n                if not langflow_model_name:\n                    self.log(f\"Warning: Could not determine name for model at index {i}. Using placeholder.\", \"warning\")\n                    spec_dict = {\n                        \"id\": f\"unknown_model_{i}\",\n                        \"name\": f\"Unknown Model {i}\",\n                        \"description\": \"Name could not be determined.\",\n                    }\n                else:\n                    spec_dict = self._get_model_specs_dict(langflow_model_name)\n\n                model_specs_for_judge.append({\"index\": i, \"langflow_name\": langflow_model_name, \"specs\": spec_dict})\n                self.log(\n                    f\"Prepared specs for Langflow model {i} ('{langflow_model_name}'): {spec_dict.get('name', 'N/A')}\"\n                )\n\n            estimated_tokens = len(self.input_value.split()) * 1.3\n            self.log(f\"Estimated input tokens: {int(estimated_tokens)}\")\n\n            query_preview = self.input_value[: self.QUERY_PREVIEW_MAX_LENGTH]\n            if len(self.input_value) > self.QUERY_PREVIEW_MAX_LENGTH:\n                query_preview += \"...\"\n\n            user_message_content = f\"\"\"User Query: \"{query_preview}\"\nOptimization Preference: {self.optimization}\nEstimated Input Tokens: ~{int(estimated_tokens)}\n\nAvailable Models (JSON list):\n{json.dumps(model_specs_for_judge, indent=2)}\n\nBased on the user query, optimization preference, and the detailed model specifications,\nselect the index of the most appropriate model.\nReturn ONLY the index number:\"\"\"\n\n            user_message = {\"role\": \"user\", \"content\": user_message_content}\n\n            self.log(\"Requesting model selection from judge LLM...\")\n            self.status = \"Judge LLM analyzing options...\"\n\n            response = await self.judge_llm.ainvoke([system_message, user_message])\n            selected_index, chosen_model_instance = self._parse_judge_response(response.content.strip())\n            self._selected_model_name = get_model_name(chosen_model_instance)\n            if self._selected_model_name:\n                self._selected_api_model_id = (\n                    self._get_api_model_id_for_langflow_model(self._selected_model_name) or self._selected_model_name\n                )\n            else:\n                self._selected_api_model_id = \"unknown_model\"\n\n            specs_source = (\n                \"OpenRouter API\"\n                if self.use_openrouter_specs and self._models_api_cache\n                else \"Basic (Langflow model names only)\"\n            )\n            self._routing_decision = f\"\"\"Model Selection Decision:\n- Selected Model Index: {selected_index}\n- Selected Langflow Model Name: {self._selected_model_name}\n- Selected API Model ID (if resolved): {self._selected_api_model_id}\n- Optimization Preference: {self.optimization}\n- Input Query Length: {len(self.input_value)} characters (~{int(estimated_tokens)} tokens)\n- Number of Models Considered: {len(self.models)}\n- Specifications Source: {specs_source}\"\"\"\n\n            log_msg = (\n                f\"DECISION by Judge LLM: Selected model index {selected_index} -> \"\n                f\"Langflow Name: '{self._selected_model_name}', API ID: '{self._selected_api_model_id}'\"\n            )\n            self.log(log_msg)\n\n            self.status = f\"Generating response with: {self._selected_model_name}\"\n            input_message_obj = Message(text=self.input_value)\n\n            raw_result = get_chat_result(\n                runnable=chosen_model_instance,\n                input_value=input_message_obj,\n            )\n            result = Message(text=str(raw_result)) if not isinstance(raw_result, Message) else raw_result\n\n            self.status = f\"Successfully routed to: {self._selected_model_name}\"\n            successful_result = result\n\n        except (ValueError, TypeError, AttributeError, KeyError, RuntimeError) as e:\n            error_msg = f\"Routing error: {type(e).__name__} - {e!s}\"\n            self.log(f\"{error_msg}\", \"error\")\n            self.log(\"Detailed routing error occurred. Check logs for details.\", \"error\")\n            self.status = error_msg\n\n            if self.fallback_to_first and self.models:\n                self.log(\"Activating fallback to first model due to error.\", \"warning\")\n                chosen_model_instance = self.models[0]\n                self._selected_model_name = get_model_name(chosen_model_instance)\n                if self._selected_model_name:\n                    mapped_id = self._get_api_model_id_for_langflow_model(self._selected_model_name)\n                    self._selected_api_model_id = mapped_id or self._selected_model_name\n                else:\n                    self._selected_api_model_id = \"fallback_model\"\n                self._routing_decision = f\"\"\"Fallback Decision:\n- Error During Routing: {error_msg}\n- Fallback Model Langflow Name: {self._selected_model_name}\n- Fallback Model API ID (if resolved): {self._selected_api_model_id}\n- Reason: Automatic fallback enabled\"\"\"\n\n                self.status = f\"Fallback: Using {self._selected_model_name}\"\n                input_message_obj = Message(text=self.input_value)\n\n                raw_fallback_result = get_chat_result(\n                    runnable=chosen_model_instance,\n                    input_value=input_message_obj,\n                )\n                if not isinstance(raw_fallback_result, Message):\n                    successful_result = Message(text=str(raw_fallback_result))\n                else:\n                    successful_result = raw_fallback_result\n            else:\n                self.log(\"No fallback model available or fallback disabled. Raising error.\", \"error\")\n                raise\n\n        if successful_result is None:\n            error_message = \"Unexpected state in route_to_model: No result produced.\"\n            self.log(f\"Error: {error_message}\", \"error\")\n            raise RuntimeError(error_message)\n        return successful_result\n\n    def _parse_judge_response(self, response_content: str) -> tuple[int, Any]:\n        \"\"\"Parse the judge's response to extract model index.\"\"\"\n        try:\n            cleaned_response = \"\".join(filter(str.isdigit, response_content.strip()))\n            if not cleaned_response:\n                self.log(f\"Judge LLM response was non-numeric: '{response_content}'. Defaulting to index 0.\", \"warning\")\n                return 0, self.models[0]\n\n            selected_index = int(cleaned_response)\n\n            if 0 <= selected_index < len(self.models):\n                self.log(f\"Judge LLM selected index: {selected_index}\")\n                return selected_index, self.models[selected_index]\n            log_msg = (\n                f\"Judge LLM selected index {selected_index} is out of bounds \"\n                f\"(0-{len(self.models) - 1}). Defaulting to index 0.\"\n            )\n            self.log(log_msg, \"warning\")\n            return 0, self.models[0]\n\n        except ValueError:\n            self.log(\n                f\"Could not parse judge LLM response to integer: '{response_content}'. Defaulting to index 0.\",\n                \"warning\",\n            )\n            return 0, self.models[0]\n        except (AttributeError, IndexError) as e:\n            self.log(f\"Error parsing judge response '{response_content}': {e!s}. Defaulting to index 0.\", \"error\")\n            return 0, self.models[0]\n\n    def get_selected_model_info(self) -> list[Data]:\n        \"\"\"Return detailed information about the selected model as a list of Data objects.\"\"\"\n        if self._selected_model_name:\n            specs_dict = self._get_model_specs_dict(self._selected_model_name)\n            if \"langflow_name\" not in specs_dict:\n                specs_dict[\"langflow_model_name_used_for_lookup\"] = self._selected_model_name\n            if self._selected_api_model_id and specs_dict.get(\"id\") != self._selected_api_model_id:\n                specs_dict[\"resolved_api_model_id\"] = self._selected_api_model_id\n            data_output = [Data(data=specs_dict)]\n            self.status = data_output\n            return data_output\n\n        data_output = [Data(data={\"info\": \"No model selected yet - run the router first.\"})]\n        self.status = data_output\n        return data_output\n\n    def get_routing_decision(self) -> Message:\n        \"\"\"Return the comprehensive routing decision explanation.\"\"\"\n        if self._routing_decision:\n            message_output = Message(text=f\"{self._routing_decision}\")\n            self.status = message_output\n            return message_output\n\n        message_output = Message(text=\"No routing decision made yet - run the router first.\")\n        self.status = message_output\n        return message_output\n    \n    def get_language_model(self) -> Any:\n        \"\"\"\n        Output the actual selected Language Model instance.\n        Useful for downstream components like Batch Run.\n        \"\"\"\n        # Defensive: If you haven't routed yet, fallback to first\n        try:\n            # Try to find the chosen model by name (use internal tracking)\n            if self._selected_model_name and self.models:\n                for m in self.models:\n                    if get_model_name(m) == self._selected_model_name:\n                        return m\n                # Fallback if name resolution fails\n                return self.models[0]\n            elif self.models:\n                # If nothing was routed yet, fallback to first\n                return self.models[0]\n            else:\n                return None\n        except Exception as e:\n            self.log(f\"Error in get_language_model: {e!s}\", \"error\")\n            return None\n"
              },
              "fallback_to_first": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Fallback to First Model",
                "dynamic": false,
                "info": "Use first model as fallback when routing fails",
                "list": false,
                "list_add_label": "Add More",
                "name": "fallback_to_first",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input message to be routed",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "      Here is the knowledge base:\n      {knowledge}\n      The above is the knowledge base."
              },
              "judge_llm": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Judge LLM",
                "dynamic": false,
                "info": "LLM that will evaluate and select the most appropriate model",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "judge_llm",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "models": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Models",
                "dynamic": false,
                "info": "List of LLMs to route between",
                "input_types": [
                  "LanguageModel"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "models",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "optimization": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Optimization",
                "dynamic": false,
                "external_options": {},
                "info": "Optimization preference for model selection",
                "load_from_db": false,
                "name": "optimization",
                "options": [
                  "quality",
                  "speed",
                  "cost",
                  "balanced"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "quality"
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "API Timeout",
                "dynamic": false,
                "info": "Timeout for API requests in seconds",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "use_openrouter_specs": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Use OpenRouter Specs",
                "dynamic": false,
                "info": "Fetch model specifications from OpenRouter API for enhanced routing decisions. If false, only model names will be used.",
                "list": false,
                "list_add_label": "Add More",
                "name": "use_openrouter_specs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "selected_output": "language_model",
          "showNode": true,
          "type": "LLMRouterComponent"
        },
        "dragging": false,
        "id": "LLMRouterComponent-skDFt",
        "measured": {
          "height": 396,
          "width": 320
        },
        "position": {
          "x": -2190.544100720812,
          "y": 26.487323271250546
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Directory-Hvzf0",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Recursively load files from a directory.",
            "display_name": "Directory",
            "documentation": "https://docs.langflow.org/components-data#directory",
            "edited": true,
            "field_order": [
              "path",
              "types",
              "depth",
              "max_concurrency",
              "load_hidden",
              "recursive",
              "silent_errors",
              "use_multithreading"
            ],
            "frozen": false,
            "icon": "folder",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Loaded Files",
                "group_outputs": false,
                "hidden": null,
                "method": "as_dataframe",
                "name": "dataframe",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data, retrieve_file_paths\r\nfrom langflow.custom.custom_component.component import Component\r\nfrom langflow.io import BoolInput, IntInput, MessageTextInput, MultiselectInput\r\nfrom langflow.schema.data import Data\r\nfrom langflow.schema.dataframe import DataFrame\r\nfrom langflow.template.field.base import Output\r\n\r\n\r\nclass DirectoryComponent(Component):\r\n    display_name = \"Directory\"\r\n    description = \"Recursively load files from a directory.\"\r\n    documentation: str = \"https://docs.langflow.org/components-data#directory\"\r\n    icon = \"folder\"\r\n    name = \"Directory\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"path\",\r\n            display_name=\"Path\",\r\n            info=\"Path to the directory to load files from. Defaults to current directory ('.')\",\r\n            value=\".\",\r\n            tool_mode=True,\r\n        ),\r\n        MultiselectInput(\r\n            name=\"types\",\r\n            display_name=\"File Types\",\r\n            info=\"File types to load. Select one or more types or leave empty to load all supported types.\",\r\n            options=TEXT_FILE_TYPES,\r\n            value=[],\r\n        ),\r\n        IntInput(\r\n            name=\"depth\",\r\n            display_name=\"Depth\",\r\n            info=\"Depth to search for files.\",\r\n            value=0,\r\n        ),\r\n        IntInput(\r\n            name=\"max_concurrency\",\r\n            display_name=\"Max Concurrency\",\r\n            advanced=True,\r\n            info=\"Maximum concurrency for loading files.\",\r\n            value=2,\r\n        ),\r\n        BoolInput(\r\n            name=\"load_hidden\",\r\n            display_name=\"Load Hidden\",\r\n            advanced=True,\r\n            info=\"If true, hidden files will be loaded.\",\r\n        ),\r\n        BoolInput(\r\n            name=\"recursive\",\r\n            display_name=\"Recursive\",\r\n            advanced=True,\r\n            info=\"If true, the search will be recursive.\",\r\n        ),\r\n        BoolInput(\r\n            name=\"silent_errors\",\r\n            display_name=\"Silent Errors\",\r\n            advanced=True,\r\n            info=\"If true, errors will not raise an exception.\",\r\n        ),\r\n        BoolInput(\r\n            name=\"use_multithreading\",\r\n            display_name=\"Use Multithreading\",\r\n            advanced=True,\r\n            info=\"If true, multithreading will be used.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Loaded Files\", name=\"dataframe\", method=\"as_dataframe\"),\r\n    ]\r\n\r\n    def load_directory(self) -> list[Data]:\r\n        path = self.path\r\n        types = self.types\r\n        depth = self.depth\r\n        max_concurrency = self.max_concurrency\r\n        load_hidden = self.load_hidden\r\n        recursive = self.recursive\r\n        silent_errors = self.silent_errors\r\n        use_multithreading = self.use_multithreading\r\n\r\n        resolved_path = self.resolve_path(path)\r\n\r\n        # If no types are specified, use all supported types\r\n        if not types:\r\n            types = TEXT_FILE_TYPES\r\n\r\n        # Check if all specified types are valid\r\n        invalid_types = [t for t in types if t not in TEXT_FILE_TYPES]\r\n        if invalid_types:\r\n            msg = f\"Invalid file types specified: {invalid_types}. Valid types are: {TEXT_FILE_TYPES}\"\r\n            raise ValueError(msg)\r\n\r\n        valid_types = types\r\n\r\n        file_paths = retrieve_file_paths(\r\n            resolved_path, load_hidden=load_hidden, recursive=recursive, depth=depth, types=valid_types\r\n        )\r\n\r\n        loaded_data = []\r\n        if use_multithreading:\r\n            loaded_data = parallel_load_data(file_paths, silent_errors=silent_errors, max_concurrency=max_concurrency)\r\n        else:\r\n            loaded_data = [parse_text_file_to_data(file_path, silent_errors=silent_errors) for file_path in file_paths]\r\n\r\n        valid_data = [x for x in loaded_data if x is not None and isinstance(x, Data)]\r\n        self.status = valid_data\r\n        return valid_data\r\n\r\n    def as_dataframe(self) -> DataFrame:\r\n        data = self.load_directory()\r\n        # Add file_id starting from 1\r\n        for idx, d in enumerate(data, start=1):\r\n            d.data[\"file_id\"] = \"F00\" + str(idx)\r\n        return DataFrame(data)\r\n\r\n"
              },
              "depth": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Depth",
                "dynamic": false,
                "info": "Depth to search for files.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "depth",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "load_hidden": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Load Hidden",
                "dynamic": false,
                "info": "If true, hidden files will be loaded.",
                "list": false,
                "list_add_label": "Add More",
                "name": "load_hidden",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_concurrency": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Concurrency",
                "dynamic": false,
                "info": "Maximum concurrency for loading files.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 2
              },
              "path": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Path",
                "dynamic": false,
                "info": "Path to the directory to load files from. Defaults to current directory ('.')",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "recursive": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Recursive",
                "dynamic": false,
                "info": "If true, the search will be recursive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "recursive",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "silent_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Silent Errors",
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "list": false,
                "list_add_label": "Add More",
                "name": "silent_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "types": {
                "_input_type": "MultiselectInput",
                "advanced": false,
                "combobox": false,
                "display_name": "File Types",
                "dynamic": false,
                "info": "File types to load. Select one or more types or leave empty to load all supported types.",
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "types",
                "options": [
                  "csv",
                  "json",
                  "pdf",
                  "txt",
                  "md",
                  "mdx",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "txt"
                ]
              },
              "use_multithreading": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Use Multithreading",
                "dynamic": false,
                "info": "If true, multithreading will be used.",
                "list": false,
                "list_add_label": "Add More",
                "name": "use_multithreading",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Directory"
        },
        "dragging": false,
        "id": "Directory-Hvzf0",
        "measured": {
          "height": 373,
          "width": 320
        },
        "position": {
          "x": -2791.4376391725746,
          "y": 1466.107589515225
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DataFrameOperations-sTdsg",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Perform various operations on a DataFrame.",
            "display_name": "DataFrame Operations",
            "documentation": "https://docs.langflow.org/components-processing#dataframe-operations",
            "edited": false,
            "field_order": [
              "df",
              "operation",
              "column_name",
              "filter_value",
              "filter_operator",
              "ascending",
              "new_column_name",
              "new_column_value",
              "columns_to_select",
              "num_rows",
              "replace_value",
              "replacement_value"
            ],
            "frozen": false,
            "icon": "table",
            "key": "DataFrameOperations",
            "last_updated": "2026-02-02T03:24:48.883Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "loop_types": null,
                "method": "perform_operation",
                "name": "output",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_frontend_node_flow_id": {
                "value": "ce767eeb-d198-4f14-b5a1-2ec08b22b1ec"
              },
              "_frontend_node_folder_id": {
                "value": "ad4db6bf-94a7-4138-978a-b55a38dc9cf4"
              },
              "_type": "Component",
              "ascending": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Sort Ascending",
                "dynamic": true,
                "info": "Whether to sort in ascending order.",
                "list": false,
                "list_add_label": "Add More",
                "name": "ascending",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import pandas as pd\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs import SortableListInput\nfrom langflow.io import (\n    BoolInput,\n    DataFrameInput,\n    DropdownInput,\n    IntInput,\n    MessageTextInput,\n    Output,\n    StrInput,\n)\nfrom langflow.logging import logger\nfrom langflow.schema.dataframe import DataFrame\n\n\nclass DataFrameOperationsComponent(Component):\n    display_name = \"DataFrame Operations\"\n    description = \"Perform various operations on a DataFrame.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#dataframe-operations\"\n    icon = \"table\"\n    name = \"DataFrameOperations\"\n\n    OPERATION_CHOICES = [\n        \"Add Column\",\n        \"Drop Column\",\n        \"Filter\",\n        \"Head\",\n        \"Rename Column\",\n        \"Replace Value\",\n        \"Select Columns\",\n        \"Sort\",\n        \"Tail\",\n        \"Drop Duplicates\",\n    ]\n\n    inputs = [\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The input DataFrame to operate on.\",\n            required=True,\n        ),\n        SortableListInput(\n            name=\"operation\",\n            display_name=\"Operation\",\n            placeholder=\"Select Operation\",\n            info=\"Select the DataFrame operation to perform.\",\n            options=[\n                {\"name\": \"Add Column\", \"icon\": \"plus\"},\n                {\"name\": \"Drop Column\", \"icon\": \"minus\"},\n                {\"name\": \"Filter\", \"icon\": \"filter\"},\n                {\"name\": \"Head\", \"icon\": \"arrow-up\"},\n                {\"name\": \"Rename Column\", \"icon\": \"pencil\"},\n                {\"name\": \"Replace Value\", \"icon\": \"replace\"},\n                {\"name\": \"Select Columns\", \"icon\": \"columns\"},\n                {\"name\": \"Sort\", \"icon\": \"arrow-up-down\"},\n                {\"name\": \"Tail\", \"icon\": \"arrow-down\"},\n                {\"name\": \"Drop Duplicates\", \"icon\": \"copy-x\"},\n            ],\n            real_time_refresh=True,\n            limit=1,\n        ),\n        StrInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=\"The column name to use for the operation.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"filter_value\",\n            display_name=\"Filter Value\",\n            info=\"The value to filter rows by.\",\n            dynamic=True,\n            show=False,\n        ),\n        DropdownInput(\n            name=\"filter_operator\",\n            display_name=\"Filter Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"greater than\", \"less than\"],\n            value=\"equals\",\n            info=\"The operator to apply for filtering rows.\",\n            advanced=False,\n            dynamic=True,\n            show=False,\n        ),\n        BoolInput(\n            name=\"ascending\",\n            display_name=\"Sort Ascending\",\n            info=\"Whether to sort in ascending order.\",\n            dynamic=True,\n            show=False,\n            value=True,\n        ),\n        StrInput(\n            name=\"new_column_name\",\n            display_name=\"New Column Name\",\n            info=\"The new column name when renaming or adding a column.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"new_column_value\",\n            display_name=\"New Column Value\",\n            info=\"The value to populate the new column with.\",\n            dynamic=True,\n            show=False,\n        ),\n        StrInput(\n            name=\"columns_to_select\",\n            display_name=\"Columns to Select\",\n            dynamic=True,\n            is_list=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"num_rows\",\n            display_name=\"Number of Rows\",\n            info=\"Number of rows to return (for head/tail).\",\n            dynamic=True,\n            show=False,\n            value=5,\n        ),\n        MessageTextInput(\n            name=\"replace_value\",\n            display_name=\"Value to Replace\",\n            info=\"The value to replace in the column.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"replacement_value\",\n            display_name=\"Replacement Value\",\n            info=\"The value to replace with.\",\n            dynamic=True,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"DataFrame\",\n            name=\"output\",\n            method=\"perform_operation\",\n            info=\"The resulting DataFrame after the operation.\",\n        )\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        dynamic_fields = [\n            \"column_name\",\n            \"filter_value\",\n            \"filter_operator\",\n            \"ascending\",\n            \"new_column_name\",\n            \"new_column_value\",\n            \"columns_to_select\",\n            \"num_rows\",\n            \"replace_value\",\n            \"replacement_value\",\n        ]\n        for field in dynamic_fields:\n            build_config[field][\"show\"] = False\n\n        if field_name == \"operation\":\n            # Handle SortableListInput format\n            if isinstance(field_value, list):\n                operation_name = field_value[0].get(\"name\", \"\") if field_value else \"\"\n            else:\n                operation_name = field_value or \"\"\n\n            # If no operation selected, all dynamic fields stay hidden (already set to False above)\n            if not operation_name:\n                return build_config\n\n            if operation_name == \"Filter\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"filter_value\"][\"show\"] = True\n                build_config[\"filter_operator\"][\"show\"] = True\n            elif operation_name == \"Sort\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"ascending\"][\"show\"] = True\n            elif operation_name == \"Drop Column\":\n                build_config[\"column_name\"][\"show\"] = True\n            elif operation_name == \"Rename Column\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"new_column_name\"][\"show\"] = True\n            elif operation_name == \"Add Column\":\n                build_config[\"new_column_name\"][\"show\"] = True\n                build_config[\"new_column_value\"][\"show\"] = True\n            elif operation_name == \"Select Columns\":\n                build_config[\"columns_to_select\"][\"show\"] = True\n            elif operation_name in {\"Head\", \"Tail\"}:\n                build_config[\"num_rows\"][\"show\"] = True\n            elif operation_name == \"Replace Value\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"replace_value\"][\"show\"] = True\n                build_config[\"replacement_value\"][\"show\"] = True\n            elif operation_name == \"Drop Duplicates\":\n                build_config[\"column_name\"][\"show\"] = True\n\n        return build_config\n\n    def perform_operation(self) -> DataFrame:\n        df_copy = self.df.copy()\n\n        # Handle SortableListInput format for operation\n        operation_input = getattr(self, \"operation\", [])\n        if isinstance(operation_input, list) and len(operation_input) > 0:\n            op = operation_input[0].get(\"name\", \"\")\n        else:\n            op = \"\"\n\n        # If no operation selected, return original DataFrame\n        if not op:\n            return df_copy\n\n        if op == \"Filter\":\n            return self.filter_rows_by_value(df_copy)\n        if op == \"Sort\":\n            return self.sort_by_column(df_copy)\n        if op == \"Drop Column\":\n            return self.drop_column(df_copy)\n        if op == \"Rename Column\":\n            return self.rename_column(df_copy)\n        if op == \"Add Column\":\n            return self.add_column(df_copy)\n        if op == \"Select Columns\":\n            return self.select_columns(df_copy)\n        if op == \"Head\":\n            return self.head(df_copy)\n        if op == \"Tail\":\n            return self.tail(df_copy)\n        if op == \"Replace Value\":\n            return self.replace_values(df_copy)\n        if op == \"Drop Duplicates\":\n            return self.drop_duplicates(df_copy)\n        msg = f\"Unsupported operation: {op}\"\n        logger.error(msg)\n        raise ValueError(msg)\n\n    def filter_rows_by_value(self, df: DataFrame) -> DataFrame:\n        column = df[self.column_name]\n        filter_value = self.filter_value\n\n        # Handle regular DropdownInput format (just a string value)\n        operator = getattr(self, \"filter_operator\", \"equals\")  # Default to equals for backward compatibility\n\n        if operator == \"equals\":\n            mask = column == filter_value\n        elif operator == \"not equals\":\n            mask = column != filter_value\n        elif operator == \"contains\":\n            mask = column.astype(str).str.contains(str(filter_value), na=False)\n        elif operator == \"starts with\":\n            mask = column.astype(str).str.startswith(str(filter_value), na=False)\n        elif operator == \"ends with\":\n            mask = column.astype(str).str.endswith(str(filter_value), na=False)\n        elif operator == \"greater than\":\n            try:\n                # Try to convert filter_value to numeric for comparison\n                numeric_value = pd.to_numeric(filter_value)\n                mask = column > numeric_value\n            except (ValueError, TypeError):\n                # If conversion fails, compare as strings\n                mask = column.astype(str) > str(filter_value)\n        elif operator == \"less than\":\n            try:\n                # Try to convert filter_value to numeric for comparison\n                numeric_value = pd.to_numeric(filter_value)\n                mask = column < numeric_value\n            except (ValueError, TypeError):\n                # If conversion fails, compare as strings\n                mask = column.astype(str) < str(filter_value)\n        else:\n            mask = column == filter_value  # Fallback to equals\n\n        return DataFrame(df[mask])\n\n    def sort_by_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.sort_values(by=self.column_name, ascending=self.ascending))\n\n    def drop_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.drop(columns=[self.column_name]))\n\n    def rename_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.rename(columns={self.column_name: self.new_column_name}))\n\n    def add_column(self, df: DataFrame) -> DataFrame:\n        df[self.new_column_name] = [self.new_column_value] * len(df)\n        return DataFrame(df)\n\n    def select_columns(self, df: DataFrame) -> DataFrame:\n        columns = [col.strip() for col in self.columns_to_select]\n        return DataFrame(df[columns])\n\n    def head(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.head(self.num_rows))\n\n    def tail(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.tail(self.num_rows))\n\n    def replace_values(self, df: DataFrame) -> DataFrame:\n        df[self.column_name] = df[self.column_name].replace(self.replace_value, self.replacement_value)\n        return DataFrame(df)\n\n    def drop_duplicates(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.drop_duplicates(subset=self.column_name))\n"
              },
              "column_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": true,
                "info": "The column name to use for the operation.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "batch_index"
              },
              "columns_to_select": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Columns to Select",
                "dynamic": true,
                "info": "",
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "columns_to_select",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The input DataFrame to operate on.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "filter_operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Filter Operator",
                "dynamic": true,
                "external_options": {},
                "info": "The operator to apply for filtering rows.",
                "name": "filter_operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "greater than",
                  "less than"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "equals"
              },
              "filter_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Filter Value",
                "dynamic": true,
                "info": "The value to filter rows by.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "filter_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "new_column_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "New Column Name",
                "dynamic": true,
                "info": "The new column name when renaming or adding a column.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "new_column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "file_path"
              },
              "new_column_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "New Column Value",
                "dynamic": true,
                "info": "The value to populate the new column with.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "new_column_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "num_rows": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Rows",
                "dynamic": true,
                "info": "Number of rows to return (for head/tail).",
                "list": false,
                "list_add_label": "Add More",
                "name": "num_rows",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "operation": {
                "_input_type": "SortableListInput",
                "advanced": false,
                "display_name": "Operation",
                "dynamic": false,
                "info": "Select the DataFrame operation to perform.",
                "limit": 1,
                "name": "operation",
                "options": [
                  {
                    "icon": "plus",
                    "name": "Add Column"
                  },
                  {
                    "icon": "minus",
                    "name": "Drop Column"
                  },
                  {
                    "icon": "filter",
                    "name": "Filter"
                  },
                  {
                    "icon": "arrow-up",
                    "name": "Head"
                  },
                  {
                    "icon": "pencil",
                    "name": "Rename Column"
                  },
                  {
                    "icon": "replace",
                    "name": "Replace Value"
                  },
                  {
                    "icon": "columns",
                    "name": "Select Columns"
                  },
                  {
                    "icon": "arrow-up-down",
                    "name": "Sort"
                  },
                  {
                    "icon": "arrow-down",
                    "name": "Tail"
                  },
                  {
                    "icon": "copy-x",
                    "name": "Drop Duplicates"
                  }
                ],
                "placeholder": "Select Operation",
                "real_time_refresh": true,
                "required": false,
                "search_category": [],
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "sortableList",
                "value": [
                  {
                    "chosen": false,
                    "icon": "pencil",
                    "name": "Rename Column",
                    "selected": false
                  }
                ]
              },
              "replace_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Value to Replace",
                "dynamic": true,
                "info": "The value to replace in the column.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "replace_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "replacement_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Replacement Value",
                "dynamic": true,
                "info": "The value to replace with.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "replacement_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DataFrameOperations"
        },
        "dragging": false,
        "id": "DataFrameOperations-sTdsg",
        "measured": {
          "height": 413,
          "width": 320
        },
        "position": {
          "x": 1722.7487351042805,
          "y": -391.02938237670924
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-5WdEV",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "last_updated": "2025-10-21T09:45:34.352Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Clean Data",
                "dynamic": false,
                "info": "Enable to clean the data by removing empty rows and lines in each cell of the DataFrame/ Data object.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\\n\\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-5WdEV",
        "measured": {
          "height": 425,
          "width": 320
        },
        "position": {
          "x": 4364.542343852423,
          "y": 3085.610039607243
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "RAGFlowChatModel-EfYmF",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using RAGFlow.",
            "display_name": "RAGFlow Chat Model",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "ragflow_ca_bundle",
              "ragflow_chat_base_url",
              "ragflow_chat_id",
              "ragflow_chat_api_key",
              "timeout",
              "max_retries",
              "model_name",
              "temperature",
              "max_tokens",
              "json_mode",
              "use_responses_api",
              "model_kwargs"
            ],
            "frozen": false,
            "icon": "SunshineCoder",
            "last_updated": "2025-10-01T07:31:49.404Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import httpx\nimport ssl\n\nfrom typing import Any\nfrom pydantic.v1 import SecretStr\nfrom langchain_openai import ChatOpenAI\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    IntInput,\n    MessageInput,\n    MultilineInput,\n    SecretStrInput,\n    SliderInput,\n    StrInput,\n)\nfrom langflow.components.sunshine_coder.constants import (\n    CA_BUNDLE,\n    RAGFLOW_CHAT_BASE_URL,\n    RAGFLOW_CHAT_MODEL_LIST,\n)\nfrom langflow.logging import logger\n\n\nclass RAGFlowChatModelComponent(LCModelComponent):\n    name = \"RAGFlowChatModel\"\n    display_name = \"RAGFlow Chat Model\"\n    description = \"Generates text using RAGFlow.\"\n    icon = \"SunshineCoder\"\n    inputs = [\n        *LCModelComponent._base_inputs,\n        MultilineInput(\n            name=\"ragflow_ca_bundle\",\n            display_name=\"RAGFlow CA Bundle\",\n            info=\"Leave empty unless you're using a self-signed certificate. \"\n            \"Paste the entire certificate including the '-----BEGIN/END CERTIFICATE-----' lines. \"\n            \"Not sure? Just leave it blank!\",\n            value=CA_BUNDLE,\n            advanced=True,\n            dynamic=True,\n        ),\n        StrInput(\n            name=\"ragflow_chat_base_url\",\n            display_name=\"RAGFlow Chat Base URL\",\n            value=RAGFLOW_CHAT_BASE_URL,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"ragflow_chat_id\",\n            display_name=\"RAGFlow Chat Id\",\n            required=True\n        ),\n        SecretStrInput(\n            name=\"ragflow_chat_api_key\",\n            display_name=\"RAGFlow Chat API Key\",\n            required=True\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            value=600,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            value=3,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=RAGFLOW_CHAT_MODEL_LIST,\n            value=RAGFLOW_CHAT_MODEL_LIST[0],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=262144),\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"use_responses_api\",\n            display_name=\"Use Responses API\",\n            info=\"Whether to use the Responses API instead of the Chat API.\",\n            advanced=True,\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            info=\"Additional keyword arguments to pass to the model.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        self.log(f\"Executing request with model: {self.model_name}\")\n        ssl_ctx = None\n        if self.ragflow_ca_bundle:\n            try:\n                ssl_ctx = ssl.create_default_context()\n                ssl_ctx.load_verify_locations(cadata=self.ragflow_ca_bundle)\n            except (ssl.SSLError, ValueError) as e:\n                logger.error(f\"Failed to load CA bundle: {e}\")\n                raise ValueError(f\"Invalid CA bundle: {e}\") from e\n        parameters = {\n            \"base_url\": self.ragflow_chat_base_url + \"/\" + self.ragflow_chat_id,\n            \"api_key\": (\n                SecretStr(self.ragflow_chat_api_key).get_secret_value()\n                if self.ragflow_chat_api_key\n                else None\n            ),\n            \"timeout\": self.timeout,\n            \"max_retries\": self.max_retries,\n            \"model_name\": self.model_name,\n            \"temperature\": self.temperature,\n            \"max_tokens\": self.max_tokens or None,\n            \"use_responses_api\": self.use_responses_api or None,\n            \"model_kwargs\": self.model_kwargs or {},\n        }\n        output = ChatOpenAI(\n            http_client=httpx.Client(verify=ssl_ctx) if self.ragflow_ca_bundle else None,\n            http_async_client=httpx.AsyncClient(verify=ssl_ctx) if self.ragflow_ca_bundle else None,\n            **parameters\n        )\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(\n        self, build_config: dict, field_value: Any, field_name: str | None = None\n    ) -> dict:\n        build_config[\"temperature\"][\"show\"] = True\n        if \"system_message\" in build_config:\n            build_config[\"system_message\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 3
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 262144,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "external_options": {},
                "info": "",
                "name": "model_name",
                "options": [
                  "qwen3-coder-30b-a3b",
                  "qwen3-30b-a3b-thinking",
                  "xmainframe-instruct-10.5b"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "xmainframe-instruct-10.5b"
              },
              "ragflow_ca_bundle": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "RAGFlow CA Bundle",
                "dynamic": true,
                "info": "Leave empty unless you're using a self-signed certificate. Paste the entire certificate including the '-----BEGIN/END CERTIFICATE-----' lines. Not sure? Just leave it blank!",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "ragflow_ca_bundle",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "-----BEGIN CERTIFICATE-----\nMIIFEzCCAvugAwIBAgIQHNtXzZext4JPNifVibRoXzANBgkqhkiG9w0BAQsFADAc\nMRowGAYDVQQDExFOQ1NEZXZOZXQgUm9vdCBDQTAeFw0yMDA0MDIwNjQ5MjBaFw0z\nNTA0MDIwNjU5MTlaMBwxGjAYBgNVBAMTEU5DU0Rldk5ldCBSb290IENBMIICIjAN\nBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAywoxwa5oCujD63Dg+XR2Lre7Nfd/\nNohA4eG5oTbbC3Ng6h95m6QfnyzzrZYcftW8aqRhakIDQITYp9QXR6fJ9DvHxWO9\n7Jb/8TPER7xHPPwiKocPjCNeWPETiWjpNg9YyAzOAwLWJJRNpLzynvdVsD4el6ZD\n43J2iUlohMhE0qGL56PwNgt8Z4BHcr81Ymm8mgpZyaq0CspnzdUQxhZYPsTBqvnh\nzRktfZlNu6C4u9xrGClKNH1Q1H9L8YUoKFf5Y/ePJtNYviAINqvYyDqiba2SnFSC\n4KELQZpLb2SqfEgWLI4T8mSrbAMV17ybsbWxrFrY34dTYA1vKIVQm2ea9sB73Pat\no0uX7gPyZiAneXRXdtwLTBnDz5+PowzE/jwVxth4ZlHq14nODLvrfpjMxmXUDlhO\nuWfpvNiMkWitK5Q6vrPe04V1v7IwNywRb1AqZciPdznOkP79Mv70lUqNid2goYws\ncIOL3sRcDedMuxEtWKIyfyqC38MqgLpjKEfU4ozxrE2nvf2qPrAf4n8KBRy9KDf2\n7BeUr6mJULofseohMh2n3RIljcP02nMVdOy6p9N93AIQwL996Oe0mOikkYU+rFtM\naLHOeCmw7tbASoVymT+ja1NGoO99S7p1UwehF5//pV1PXUQmO5Z3F6fGWebLV6F2\nArnGzR6CXTkdjcECAwEAAaNRME8wCwYDVR0PBAQDAgGGMA8GA1UdEwEB/wQFMAMB\nAf8wHQYDVR0OBBYEFDpqUad1Arn/92XUwq2uqs1hbYtpMBAGCSsGAQQBgjcVAQQD\nAgEAMA0GCSqGSIb3DQEBCwUAA4ICAQACXcOTV7NeAQdvbAM9DO9ef+peFm1oCzJj\nh66VW8wtXknTDykprciB9JRE2ac5fx9xOfIl/gdzVXuddYoVr9JJdD3mKDij0uqS\nkD1BhNxTpc9tD3U5lPcRcjbSXmKGICM+dGG9IUt8Gs0p/NuzYho0P2jDnar8ZFhL\n/BPAFdVifjUlFLRjEE3gET11pSnyaeF6zYrBY6rQVjm3Hk+q/TioAn3P57WCWzzt\nLx2t8WGB8QxZd/A1aBC7TXkOJTOidJp15/98fImyOpu096u9WfRPyrWDCzeUFBkc\n9WeS52P+qlpQksUnLq1c9XJfqGJZiBvf+XeuCLP9S3LXb0ShKyha0xwf3sIos4Hi\ngj7RP30KZRJXXBV9w4RicI/kzCScZhSkvn8EJ2t7qaVJA6v8QVmIQ18R/9inG0TJ\ntRuw7Yfwc+EAdzDp2e4Fijm6wa8OcKx9FGNDKLR6W2o/iGGOrK+5N4L/ZMxXWXtF\nYsJh6dFmWGMmckM0kRXnfIhvQkLv49+lD2np+MzCVeRxvGdEq2/zYjMljyjaTaqA\nYPPrPKH+VqKGXlXHnMM/9UrYw8gj28BRrKfAYbLL38BSOTbsvYa1QqgTvF7u1PDS\nGcLEjC6llllje/0GAo25einsDGvsyUbvn4/gigLYYvE4a1G6oo1Lg4YwhQw5W/s+\nCKGHxKUDLg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIE0zCCA7ugAwIBAgIJANu+mC2Jt3uTMA0GCSqGSIb3DQEBCwUAMIGhMQswCQYD\nVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTERMA8GA1UEBxMIU2FuIEpvc2Ux\nFTATBgNVBAoTDFpzY2FsZXIgSW5jLjEVMBMGA1UECxMMWnNjYWxlciBJbmMuMRgw\nFgYDVQQDEw9ac2NhbGVyIFJvb3QgQ0ExIjAgBgkqhkiG9w0BCQEWE3N1cHBvcnRA\nenNjYWxlci5jb20wHhcNMTQxMjE5MDAyNzU1WhcNNDIwNTA2MDAyNzU1WjCBoTEL\nMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExETAPBgNVBAcTCFNhbiBK\nb3NlMRUwEwYDVQQKEwxac2NhbGVyIEluYy4xFTATBgNVBAsTDFpzY2FsZXIgSW5j\nLjEYMBYGA1UEAxMPWnNjYWxlciBSb290IENBMSIwIAYJKoZIhvcNAQkBFhNzdXBw\nb3J0QHpzY2FsZXIuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA\nqT7STSxZRTgEFFf6doHajSc1vk5jmzmM6BWuOo044EsaTc9eVEV/HjH/1DWzZtcr\nfTj+ni205apMTlKBW3UYR+lyLHQ9FoZiDXYXK8poKSV5+Tm0Vls/5Kb8mkhVVqv7\nLgYEmvEY7HPY+i1nEGZCa46ZXCOohJ0mBEtB9JVlpDIO+nN0hUMAYYdZ1KZWCMNf\n5J/aTZiShsorN2A38iSOhdd+mcRM4iNL3gsLu99XhKnRqKoHeH83lVdfu1XBeoQz\nz5V6gA3kbRvhDwoIlTBeMa5l4yRdJAfdpkbFzqiwSgNdhbxTHnYYorDzKfr2rEFM\ndsMU0DHdeAZf711+1CunuQIDAQABo4IBCjCCAQYwHQYDVR0OBBYEFLm33UrNww4M\nhp1d3+wcBGnFTpjfMIHWBgNVHSMEgc4wgcuAFLm33UrNww4Mhp1d3+wcBGnFTpjf\noYGnpIGkMIGhMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTERMA8G\nA1UEBxMIU2FuIEpvc2UxFTATBgNVBAoTDFpzY2FsZXIgSW5jLjEVMBMGA1UECxMM\nWnNjYWxlciBJbmMuMRgwFgYDVQQDEw9ac2NhbGVyIFJvb3QgQ0ExIjAgBgkqhkiG\n9w0BCQEWE3N1cHBvcnRAenNjYWxlci5jb22CCQDbvpgtibd7kzAMBgNVHRMEBTAD\nAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQAw0NdJh8w3NsJu4KHuVZUrmZgIohnTm0j+\nRTmYQ9IKA/pvxAcA6K1i/LO+Bt+tCX+C0yxqB8qzuo+4vAzoY5JEBhyhBhf1uK+P\n/WVWFZN/+hTgpSbZgzUEnWQG2gOVd24msex+0Sr7hyr9vn6OueH+jj+vCMiAm5+u\nkd7lLvJsBu3AO3jGWVLyPkS3i6Gf+rwAp1OsRrv3WnbkYcFf9xjuaf4z0hRCrLN2\nxFNjavxrHmsH8jPHVvgc1VD0Opja0l/BRVauTrUaoW6tE+wFG5rEcPGS80jjHK4S\npB5iDj2mUZH1T8lzYtuZy0ZPirxmtsk3135+CKNa2OCAhhFjE0xd\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIESzCCAzOgAwIBAgICAQEwDQYJKoZIhvcNAQELBQAwgaExCzAJBgNVBAYTAlVT\nMRMwEQYDVQQIEwpDYWxpZm9ybmlhMREwDwYDVQQHEwhTYW4gSm9zZTEVMBMGA1UE\nChMMWnNjYWxlciBJbmMuMRUwEwYDVQQLEwxac2NhbGVyIEluYy4xGDAWBgNVBAMT\nD1pzY2FsZXIgUm9vdCBDQTEiMCAGCSqGSIb3DQEJARYTc3VwcG9ydEB6c2NhbGVy\nLmNvbTAeFw0yMDA2MDUwNTMyNDRaFw00MTA2MjMwNTMyNDRaMIGuMQswCQYDVQQG\nEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEVMBMGA1UEChMMWnNjYWxlciBJbmMu\nMRUwEwYDVQQLEwxac2NhbGVyIEluYy4xODA2BgNVBAMTL1pzY2FsZXIgSW50ZXJt\nZWRpYXRlIFJvb3QgQ0EgKHpzY2FsZXJ0aHJlZS5uZXQpMSIwIAYJKoZIhvcNAQkB\nFhNzdXBwb3J0QHpzY2FsZXIuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIB\nCgKCAQEAmioqA+ZMX9KzDDO6VXfPWU4dQ3Knj68Y16L50vd6cAxY6CyBclodGxA1\nmwyIv+Q+kV1oaaoowMGjMDQVyCWFa3w7MaiJdx1x0XgtO1u6nEtA7hRaYnJb+/8J\nLRdXjXQpPNRuis7CE/jfpaUn4zikoBWk3GPQ3ZePX8PdQDtPd47Le5AXNd8rCpFR\nMOJSvZYYrlcEWqMbdBs5sSE3B2UKxQ00Qbj8eQHpvH1/aEa48KsY+9q4ZlB2xzS7\nAklK0NFwuebkhR9JTN59o9rxqVwGJhUbQGpUhMnG+g+4b1qrxRsyOFfludc9UjS5\nofjSsZk5ypGZf5W/npp6Ctz+Qc/gkwIDAQABo34wfDAdBgNVHQ4EFgQUB5R6G+iB\ndfUCJzsePyRCVDjsGdkwDAYDVR0TBAUwAwEB/zALBgNVHQ8EBAMCAf4wQAYDVR0f\nBDkwNzA1oDOgMYYvaHR0cDovL2dhdGV3YXkuenNjYWxlcnRocmVlLm5ldC9jcmwv\nenMzLWludC5jcmwwDQYJKoZIhvcNAQELBQADggEBAD4Jc1RkDa/0ktmwdWqEpTGa\nJuKuN8BY9J7yusclOKKXef8XcAH4Zb/D/9sOWc7PSQKZ0jbGcSmuUjkZZfHnpJ8s\nY3chfEdl4BbVYsg1zF+3b0LrD09+8JHYBYIzE1Rc0/WSQtt/wra1aBijDqZWme3t\n/qB7xTH7VyLg0bz5v178+tcbBWyT4YRydInl5rlOFCWheb9wnF0O4wqh2ZdObagf\nxURV25gYLODsE86fWm/GWSTMytp/Cp1+dVpZVqOx2GbTsxhtM+EmTTptu2ixmLMZ\niPwYIidlYicHBgfhnEv6O2ukM3LeD/IeqdCmhptBKgsWDuxj7t/nUgzaETHuJL4=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\n2dbWAFZtIJCBkzFB\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\nKqClq3gnEytH0g==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\nukxwysXvK5fMqjg0G1UVn2pOsgUKGEBzLOwBiq/4xbUja+Y=\n-----END CERTIFICATE-----\n\n\n-----BEGIN CERTIFICATE-----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\nIMLDPEm0C0fPfnNViYnAIx66tXi6cEvSu3cagXeHa8PpAw6O\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\nKuaoZ8ZJba4dWrcnuYhfAuZwg/Hcr8YbkzwjdAw2jg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIFHTCCAwWgAwIBAgIQGQAgWCt94IRNpVmNTEmCDDANBgkqhkiG9w0BAQsFADAh\nMR8wHQYDVQQDExZOQ1NEZXZOZXQgUHJvZCBSb290IENBMB4XDTI0MTAwNDA5MTQ0\nNFoXDTQ0MTAwNDA5MjQ0M1owITEfMB0GA1UEAxMWTkNTRGV2TmV0IFByb2QgUm9v\ndCBDQTCCAiIwDQYJKoZIhvcNAQEBBQADggIPADCCAgoCggIBAKeglq4tsgEQuy9u\n1SSFVR0YdjRBBrba95BFRNYYHya8zbvJrUTY3aGwftNGKfvj+PZtLmjwKZUdIIQb\nqXi6ysbC6MBKrREwUxT6j9ONcWvm+pV8kgrFS1+gEt7xSX4KzaIJbR7B2MkR91GV\nQ8rJgDUCYZbbmTEoZ3gZWu+ae8xDfyNcAF12KxyXpdCTwiQ3I84EGUoqW0VlbyNU\nuAc2XIAFB9onQX31gCZLShKE9i41czsi2lXjyXegkuuGfkC1nYbQws4ECXkXl397\nK2GdgJ1E8ePoed26qfYGmu6K4RmfnfY98b7j42n1lu+wwx+Edi//Pus/Sdk29YrX\nA5u5NTq4TVKPocpL1MeOhzc2XshHbKS14ZXdY6VcGWIaGsOB2lJ2b2PEyYytKJVc\nTlr2SUnIRr5Yxn7Dttju1myuOHfDu4AXoYswM5D9MGWT3+HWe2onERd6kICmSe0b\nzaAhH12ml9UUX4UMx0Mw6D4ew//xI2uw8pAv0VzU+r9UontVxuoWMek8zpAimxuY\nPT36oCJUOMkiIEg2ihohNY/+nZ6N3g8s53ldqAn1oGL6sv1SA7B729/yGLIngA6l\nUJ7g5QAtEmR8PcJB2hFRGs2o8eQzrpVZgxM89rikLIPRXCqudLajiIna1iY7TMcA\neESBn86We77wj212hn3G4j+k2j7RAgMBAAGjUTBPMAsGA1UdDwQEAwIBhjAPBgNV\nHRMBAf8EBTADAQH/MB0GA1UdDgQWBBSy94Kn5kkkja5ug0M0yltVMweYCTAQBgkr\nBgEEAYI3FQEEAwIBADANBgkqhkiG9w0BAQsFAAOCAgEACGws1+VsSNwRpy2+sAys\nPAnJ0LF+l0MaW3T3g5c2rExwwR4mYgH9EghWnarLNAO28yxhtemovXcmBWsIurK1\nX0wgYqFBMoizjxtjA4SrqDHqkSMWpsF7yGAMhc3x5MFsM2WCGD3mcjJRPTQmcRRL\nGcGmaUdgm2v+q3BwyRsZAiSgSnrjpPjnFuPI+RF9mOxF5mpsR5DFBCzYp2deptvF\nNnRf506h0nJbCUXbDeAxdacKqL5jO/06hO7OW/uYyc51GE1C5+SM1Wfe4e54KQQM\niXJM/2m7YNtHmJSPCvJzpeEKhMkXRwxmQeRNqFzvxyVBNQaqAmFd2Gij+boDfHBJ\n4KlF77+730RVZeIVL8cTBMizTFkAk7DUsDo+99+M5SNQTuxyQvj1WiUed518DjS5\nZ6dGNhZbNx2bgx0hi0a5C19SvtKa1OFRwCgiS0M6PgVnm59uA3FwHrLwlhhzmVTU\nsCxyTWh7lx1GEPOwXf0NdSn6kXs4X3MWoOAlDslo28a8hN50fkON4JaNcCIi0koQ\n+rCOs9M5G4ZNvQVrkBqccOWUewEn3NNeo+Yy5Nx4kmKn0nZ6bICb0ek/GaWcaGQZ\nEepzgY+Efq00LL8qXH4QWg+B/+rL1rBJndoI1JB0fmtUJSD7XGcim2bYEiE/eSaT\njvlvccMaCzx1UZGSJhZNxiQ=\n-----END CERTIFICATE-----\n\n\n-----BEGIN CERTIFICATE-----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\n-----END CERTIFICATE-----\n"
              },
              "ragflow_chat_api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "RAGFlow Chat API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "ragflow_chat_api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "ragflow_chat_base_url": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "RAGFlow Chat Base URL",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "ragflow_chat_base_url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://ragflow-ui.devnet.int/api/v1/chats_openai"
              },
              "ragflow_chat_id": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "RAGFlow Chat Id",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "ragflow_chat_id",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "149db760992811f0a66ac6bd5eda7c92"
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "# Role\nYou are a professional business analyst with more than 20-year experience in a world class software development company. Having technical user from the bank as the audience of your documentation. The bank is now requesting you to write a technical specification document on the cobol code they provide. Please provide information in a business formal, technical and professional style. Please write in a concise and informative tone. By referring to the knowledge base in the manual dataset, it gives you a better understanding of the cobol structure and definition. \n      Here is the knowledge base:\n      {knowledge}\n      The above is the knowledge base.\n\n# Task\nYour primary task is to analyze the COBOL code file in the path below running on HP non-stop tandem provided by the user and generate a comprehensive, structured Markdown technical document. User may ask you specific question regarding the cobol file, answer the question base on the understanding of the file.\nCOBOL code file to analyze in knowledge base: batch_SRD222S.txt\n\n\n# Constraints and Limitations\n* **Adhere to Original Text**: All explanations and analyses must strictly be based on the provided COBOL code; do not guess or add functionalities do not present in the code.\n* **Professional Terminology**: Use professional and accurate terminology while ensuring clarity.\n* **Language**: Conduct analysis and documentation writing in English.\n* **Format**: Strictly follow the defined Markdown output format below, without omitting any part.\n\n"
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 600
              },
              "use_responses_api": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Use Responses API",
                "dynamic": false,
                "info": "Whether to use the Responses API instead of the Chat API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "use_responses_api",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "selected_output": "model_output",
          "showNode": true,
          "type": "RAGFlowChatModel"
        },
        "dragging": false,
        "id": "RAGFlowChatModel-EfYmF",
        "measured": {
          "height": 629,
          "width": 320
        },
        "position": {
          "x": 2459.459411988535,
          "y": -80.98044368227517
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "VllmChatModel-rUKJT",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using VLLM.",
            "display_name": "VLLM Chat Model",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "vllm_ca_bundle",
              "vllm_chat_base_url",
              "vllm_chat_api_key",
              "timeout",
              "max_retries",
              "model_name",
              "temperature",
              "max_tokens",
              "json_mode",
              "use_responses_api",
              "model_kwargs"
            ],
            "frozen": false,
            "icon": "SunshineCoder",
            "last_updated": "2025-10-08T07:23:55.882Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import httpx\nimport ssl\n\nfrom typing import Any\nfrom pydantic.v1 import SecretStr\nfrom langchain_openai import ChatOpenAI\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    IntInput,\n    MultilineInput,\n    SecretStrInput,\n    SliderInput,\n    StrInput,\n)\nfrom langflow.components.sunshine_coder.constants import (\n    CA_BUNDLE,\n    VLLM_CHAT_BASE_URL,\n    VLLM_CHAT_MODEL_LIST,\n)\nfrom langflow.logging import logger\n\n\nclass VllmChatModelComponent(LCModelComponent):\n    name = \"VllmChatModel\"\n    display_name = \"VLLM Chat Model\"\n    description = \"Generates text using VLLM.\"\n    icon = \"SunshineCoder\"\n    inputs = [\n        *LCModelComponent._base_inputs,\n        MultilineInput(\n            name=\"vllm_ca_bundle\",\n            display_name=\"VLLM CA Bundle\",\n            info=\"Leave empty unless you're using a self-signed certificate. \"\n            \"Paste the entire certificate including the '-----BEGIN/END CERTIFICATE-----' lines. \"\n            \"Not sure? Just leave it blank!\",\n            value=CA_BUNDLE,\n            advanced=True,\n            dynamic=True,\n        ),\n        StrInput(\n            name=\"vllm_chat_base_url\",\n            display_name=\"VLLM Chat Base URL\",\n            value=VLLM_CHAT_BASE_URL,\n            advanced=True,\n        ),\n        SecretStrInput(\n            name=\"vllm_chat_api_key\",\n            display_name=\"VLLM Chat API Key\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            value=600,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            value=3,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=VLLM_CHAT_MODEL_LIST,\n            value=VLLM_CHAT_MODEL_LIST[0],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=262144),\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"use_responses_api\",\n            display_name=\"Use Responses API\",\n            info=\"Whether to use the Responses API instead of the Chat API.\",\n            advanced=True,\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            info=\"Additional keyword arguments to pass to the model.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        self.log(f\"Executing request with model: {self.model_name}\")\n        ssl_ctx = None\n        if self.vllm_ca_bundle:\n            try:\n                ssl_ctx = ssl.create_default_context()\n                ssl_ctx.load_verify_locations(cadata=self.vllm_ca_bundle)\n            except (ssl.SSLError, ValueError) as e:\n                logger.error(f\"Failed to load CA bundle: {e}\")\n                raise ValueError(f\"Invalid CA bundle: {e}\") from e\n        parameters = {\n            \"base_url\": self.vllm_chat_base_url,\n            \"api_key\": (\n                SecretStr(self.vllm_chat_api_key).get_secret_value()\n                if self.vllm_chat_api_key\n                else None\n            ),\n            \"timeout\": self.timeout,\n            \"max_retries\": self.max_retries,\n            \"model_name\": self.model_name,\n            \"temperature\": self.temperature,\n            \"max_tokens\": self.max_tokens or None,\n            \"use_responses_api\": self.use_responses_api or None,\n            \"model_kwargs\": self.model_kwargs or {},\n        }\n        output = ChatOpenAI(\n            http_client=httpx.Client(verify=ssl_ctx) if self.vllm_ca_bundle else None,\n            http_async_client=httpx.AsyncClient(verify=ssl_ctx) if self.vllm_ca_bundle else None,\n            **parameters\n        )\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(\n        self, build_config: dict, field_value: Any, field_name: str | None = None\n    ) -> dict:\n        build_config[\"temperature\"][\"show\"] = True\n        if \"system_message\" in build_config:\n            build_config[\"system_message\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 3
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 262144,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "external_options": {},
                "info": "",
                "name": "model_name",
                "options": [
                  "qwen3-coder-30b-a3b",
                  "qwen3-30b-a3b-thinking",
                  "xmainframe-instruct-10.5b"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "qwen3-30b-a3b-thinking"
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Work as a Judge LLM"
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.5
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 600
              },
              "use_responses_api": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Use Responses API",
                "dynamic": false,
                "info": "Whether to use the Responses API instead of the Chat API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "use_responses_api",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "vllm_ca_bundle": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "VLLM CA Bundle",
                "dynamic": true,
                "info": "Leave empty unless you're using a self-signed certificate. Paste the entire certificate including the '-----BEGIN/END CERTIFICATE-----' lines. Not sure? Just leave it blank!",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "vllm_ca_bundle",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "-----BEGIN CERTIFICATE-----\nMIIFEzCCAvugAwIBAgIQHNtXzZext4JPNifVibRoXzANBgkqhkiG9w0BAQsFADAc\nMRowGAYDVQQDExFOQ1NEZXZOZXQgUm9vdCBDQTAeFw0yMDA0MDIwNjQ5MjBaFw0z\nNTA0MDIwNjU5MTlaMBwxGjAYBgNVBAMTEU5DU0Rldk5ldCBSb290IENBMIICIjAN\nBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAywoxwa5oCujD63Dg+XR2Lre7Nfd/\nNohA4eG5oTbbC3Ng6h95m6QfnyzzrZYcftW8aqRhakIDQITYp9QXR6fJ9DvHxWO9\n7Jb/8TPER7xHPPwiKocPjCNeWPETiWjpNg9YyAzOAwLWJJRNpLzynvdVsD4el6ZD\n43J2iUlohMhE0qGL56PwNgt8Z4BHcr81Ymm8mgpZyaq0CspnzdUQxhZYPsTBqvnh\nzRktfZlNu6C4u9xrGClKNH1Q1H9L8YUoKFf5Y/ePJtNYviAINqvYyDqiba2SnFSC\n4KELQZpLb2SqfEgWLI4T8mSrbAMV17ybsbWxrFrY34dTYA1vKIVQm2ea9sB73Pat\no0uX7gPyZiAneXRXdtwLTBnDz5+PowzE/jwVxth4ZlHq14nODLvrfpjMxmXUDlhO\nuWfpvNiMkWitK5Q6vrPe04V1v7IwNywRb1AqZciPdznOkP79Mv70lUqNid2goYws\ncIOL3sRcDedMuxEtWKIyfyqC38MqgLpjKEfU4ozxrE2nvf2qPrAf4n8KBRy9KDf2\n7BeUr6mJULofseohMh2n3RIljcP02nMVdOy6p9N93AIQwL996Oe0mOikkYU+rFtM\naLHOeCmw7tbASoVymT+ja1NGoO99S7p1UwehF5//pV1PXUQmO5Z3F6fGWebLV6F2\nArnGzR6CXTkdjcECAwEAAaNRME8wCwYDVR0PBAQDAgGGMA8GA1UdEwEB/wQFMAMB\nAf8wHQYDVR0OBBYEFDpqUad1Arn/92XUwq2uqs1hbYtpMBAGCSsGAQQBgjcVAQQD\nAgEAMA0GCSqGSIb3DQEBCwUAA4ICAQACXcOTV7NeAQdvbAM9DO9ef+peFm1oCzJj\nh66VW8wtXknTDykprciB9JRE2ac5fx9xOfIl/gdzVXuddYoVr9JJdD3mKDij0uqS\nkD1BhNxTpc9tD3U5lPcRcjbSXmKGICM+dGG9IUt8Gs0p/NuzYho0P2jDnar8ZFhL\n/BPAFdVifjUlFLRjEE3gET11pSnyaeF6zYrBY6rQVjm3Hk+q/TioAn3P57WCWzzt\nLx2t8WGB8QxZd/A1aBC7TXkOJTOidJp15/98fImyOpu096u9WfRPyrWDCzeUFBkc\n9WeS52P+qlpQksUnLq1c9XJfqGJZiBvf+XeuCLP9S3LXb0ShKyha0xwf3sIos4Hi\ngj7RP30KZRJXXBV9w4RicI/kzCScZhSkvn8EJ2t7qaVJA6v8QVmIQ18R/9inG0TJ\ntRuw7Yfwc+EAdzDp2e4Fijm6wa8OcKx9FGNDKLR6W2o/iGGOrK+5N4L/ZMxXWXtF\nYsJh6dFmWGMmckM0kRXnfIhvQkLv49+lD2np+MzCVeRxvGdEq2/zYjMljyjaTaqA\nYPPrPKH+VqKGXlXHnMM/9UrYw8gj28BRrKfAYbLL38BSOTbsvYa1QqgTvF7u1PDS\nGcLEjC6llllje/0GAo25einsDGvsyUbvn4/gigLYYvE4a1G6oo1Lg4YwhQw5W/s+\nCKGHxKUDLg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIE0zCCA7ugAwIBAgIJANu+mC2Jt3uTMA0GCSqGSIb3DQEBCwUAMIGhMQswCQYD\nVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTERMA8GA1UEBxMIU2FuIEpvc2Ux\nFTATBgNVBAoTDFpzY2FsZXIgSW5jLjEVMBMGA1UECxMMWnNjYWxlciBJbmMuMRgw\nFgYDVQQDEw9ac2NhbGVyIFJvb3QgQ0ExIjAgBgkqhkiG9w0BCQEWE3N1cHBvcnRA\nenNjYWxlci5jb20wHhcNMTQxMjE5MDAyNzU1WhcNNDIwNTA2MDAyNzU1WjCBoTEL\nMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExETAPBgNVBAcTCFNhbiBK\nb3NlMRUwEwYDVQQKEwxac2NhbGVyIEluYy4xFTATBgNVBAsTDFpzY2FsZXIgSW5j\nLjEYMBYGA1UEAxMPWnNjYWxlciBSb290IENBMSIwIAYJKoZIhvcNAQkBFhNzdXBw\nb3J0QHpzY2FsZXIuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA\nqT7STSxZRTgEFFf6doHajSc1vk5jmzmM6BWuOo044EsaTc9eVEV/HjH/1DWzZtcr\nfTj+ni205apMTlKBW3UYR+lyLHQ9FoZiDXYXK8poKSV5+Tm0Vls/5Kb8mkhVVqv7\nLgYEmvEY7HPY+i1nEGZCa46ZXCOohJ0mBEtB9JVlpDIO+nN0hUMAYYdZ1KZWCMNf\n5J/aTZiShsorN2A38iSOhdd+mcRM4iNL3gsLu99XhKnRqKoHeH83lVdfu1XBeoQz\nz5V6gA3kbRvhDwoIlTBeMa5l4yRdJAfdpkbFzqiwSgNdhbxTHnYYorDzKfr2rEFM\ndsMU0DHdeAZf711+1CunuQIDAQABo4IBCjCCAQYwHQYDVR0OBBYEFLm33UrNww4M\nhp1d3+wcBGnFTpjfMIHWBgNVHSMEgc4wgcuAFLm33UrNww4Mhp1d3+wcBGnFTpjf\noYGnpIGkMIGhMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTERMA8G\nA1UEBxMIU2FuIEpvc2UxFTATBgNVBAoTDFpzY2FsZXIgSW5jLjEVMBMGA1UECxMM\nWnNjYWxlciBJbmMuMRgwFgYDVQQDEw9ac2NhbGVyIFJvb3QgQ0ExIjAgBgkqhkiG\n9w0BCQEWE3N1cHBvcnRAenNjYWxlci5jb22CCQDbvpgtibd7kzAMBgNVHRMEBTAD\nAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQAw0NdJh8w3NsJu4KHuVZUrmZgIohnTm0j+\nRTmYQ9IKA/pvxAcA6K1i/LO+Bt+tCX+C0yxqB8qzuo+4vAzoY5JEBhyhBhf1uK+P\n/WVWFZN/+hTgpSbZgzUEnWQG2gOVd24msex+0Sr7hyr9vn6OueH+jj+vCMiAm5+u\nkd7lLvJsBu3AO3jGWVLyPkS3i6Gf+rwAp1OsRrv3WnbkYcFf9xjuaf4z0hRCrLN2\nxFNjavxrHmsH8jPHVvgc1VD0Opja0l/BRVauTrUaoW6tE+wFG5rEcPGS80jjHK4S\npB5iDj2mUZH1T8lzYtuZy0ZPirxmtsk3135+CKNa2OCAhhFjE0xd\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIESzCCAzOgAwIBAgICAQEwDQYJKoZIhvcNAQELBQAwgaExCzAJBgNVBAYTAlVT\nMRMwEQYDVQQIEwpDYWxpZm9ybmlhMREwDwYDVQQHEwhTYW4gSm9zZTEVMBMGA1UE\nChMMWnNjYWxlciBJbmMuMRUwEwYDVQQLEwxac2NhbGVyIEluYy4xGDAWBgNVBAMT\nD1pzY2FsZXIgUm9vdCBDQTEiMCAGCSqGSIb3DQEJARYTc3VwcG9ydEB6c2NhbGVy\nLmNvbTAeFw0yMDA2MDUwNTMyNDRaFw00MTA2MjMwNTMyNDRaMIGuMQswCQYDVQQG\nEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEVMBMGA1UEChMMWnNjYWxlciBJbmMu\nMRUwEwYDVQQLEwxac2NhbGVyIEluYy4xODA2BgNVBAMTL1pzY2FsZXIgSW50ZXJt\nZWRpYXRlIFJvb3QgQ0EgKHpzY2FsZXJ0aHJlZS5uZXQpMSIwIAYJKoZIhvcNAQkB\nFhNzdXBwb3J0QHpzY2FsZXIuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIB\nCgKCAQEAmioqA+ZMX9KzDDO6VXfPWU4dQ3Knj68Y16L50vd6cAxY6CyBclodGxA1\nmwyIv+Q+kV1oaaoowMGjMDQVyCWFa3w7MaiJdx1x0XgtO1u6nEtA7hRaYnJb+/8J\nLRdXjXQpPNRuis7CE/jfpaUn4zikoBWk3GPQ3ZePX8PdQDtPd47Le5AXNd8rCpFR\nMOJSvZYYrlcEWqMbdBs5sSE3B2UKxQ00Qbj8eQHpvH1/aEa48KsY+9q4ZlB2xzS7\nAklK0NFwuebkhR9JTN59o9rxqVwGJhUbQGpUhMnG+g+4b1qrxRsyOFfludc9UjS5\nofjSsZk5ypGZf5W/npp6Ctz+Qc/gkwIDAQABo34wfDAdBgNVHQ4EFgQUB5R6G+iB\ndfUCJzsePyRCVDjsGdkwDAYDVR0TBAUwAwEB/zALBgNVHQ8EBAMCAf4wQAYDVR0f\nBDkwNzA1oDOgMYYvaHR0cDovL2dhdGV3YXkuenNjYWxlcnRocmVlLm5ldC9jcmwv\nenMzLWludC5jcmwwDQYJKoZIhvcNAQELBQADggEBAD4Jc1RkDa/0ktmwdWqEpTGa\nJuKuN8BY9J7yusclOKKXef8XcAH4Zb/D/9sOWc7PSQKZ0jbGcSmuUjkZZfHnpJ8s\nY3chfEdl4BbVYsg1zF+3b0LrD09+8JHYBYIzE1Rc0/WSQtt/wra1aBijDqZWme3t\n/qB7xTH7VyLg0bz5v178+tcbBWyT4YRydInl5rlOFCWheb9wnF0O4wqh2ZdObagf\nxURV25gYLODsE86fWm/GWSTMytp/Cp1+dVpZVqOx2GbTsxhtM+EmTTptu2ixmLMZ\niPwYIidlYicHBgfhnEv6O2ukM3LeD/IeqdCmhptBKgsWDuxj7t/nUgzaETHuJL4=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\n2dbWAFZtIJCBkzFB\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\nKqClq3gnEytH0g==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIIXzCCBkegAwIBAgITFQABZlxERa/3Pu7yWAAAAAFmXDANBgkqhkiG9w0BAQsF\nADBMMRMwEQYKCZImiZPyLGQBGRYDaW50MRYwFAYKCZImiZPyLGQBGRYGZGV2bmV0\nMR0wGwYDVQQDExROQ1NEZXZOZXQgSXNzdWluZyBDQTAeFw0yNDA3MDQwMzQxMTda\nFw0yNTA0MDIwOTAxMzdaMIGrMQswCQYDVQQGEwJTRzESMBAGA1UECBMJU2luZ2Fw\nb3JlMRIwEAYDVQQHEwlTaW5nYXBvcmUxFDASBgNVBAoTC05DUyBQdGUgTHRkMRsw\nGQYDVQQLExJBQVA0IGlDb25uZWN0IEphdmExFTATBgNVBAMMDCouZGV2bmV0Lmlu\ndDEqMCgGCSqGSIb3DQEJARYbaWNvbm5lY3Qtc3VwcG9ydEBuY3MuY29tLmNuMIIB\nIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA1HRDg9huVU8KdK268AxfHL29\nn3wnNT/aTyOoYG66QWCeZaLhco1O/xA4rfU4L3UhEssX2KooAyjuX/Np9r3N3AXP\nfEUWO+V6OKk3JcVC5MZX4Cvmc5gnboObRvGEZIl7bivBlWN7BCeYtnUqfjHsEsm5\nMgvQxz1WCuID3oggpaeRgPPHLRwAsEdrF+mpqSS8h4BeigU/vA6iwAqU0j35I6YI\nlWizz/Ow6CyD/s6WnmHzMaxKyN2nFp7uLnieIdkJUp1GgNwrfrMVQsNQtmYFSwzx\nVWrHcVwRr9wOoFcqNSsxumgLhNKvTO5yD1PLnbR6xIDYjknQndljTisztLPhAQID\nAQABo4ID2DCCA9QwggEKBgNVHREEggEBMIH+ghVjbnByZGFwcDAxLmRldm5ldC5p\nbnSCFWNucHJkYXBwMDIuZGV2bmV0LmludIIVY25wcmRhcHAwMy5kZXZuZXQuaW50\nghdjbnByZGJhdGNoMDEuZGV2bmV0LmludIIYY25wcmRhcHBsbG0wMS5kZXZuZXQu\naW50ghhjbnByZGFwcGxsbTAyLmRldm5ldC5pbnSCGGNucHJkYXBwbGxtMDMuZGV2\nbmV0LmludIIYY25wcmRhcHBsbG0wNC5kZXZuZXQuaW50ghpjbnByZGJhdGNobGxt\nMDEuZGV2bmV0LmludIIaY25wcmRiYXRjaGxsbTAyLmRldm5ldC5pbnQwHQYDVR0O\nBBYEFDzuKUi1wWTXObjhJw+7JSULyrkWMB8GA1UdIwQYMBaAFDZ5/U4jJJ6tSQk+\nPrYZ7eMMANbKMIIBIAYDVR0fBIIBFzCCARMwggEPoIIBC6CCAQeGgcVsZGFwOi8v\nL0NOPU5DU0Rldk5ldCUyMElzc3VpbmclMjBDQSxDTj12bXN1YmNhYXpkZXYwMSxD\nTj1DRFAsQ049UHVibGljJTIwS2V5JTIwU2VydmljZXMsQ049U2VydmljZXMsQ049\nQ29uZmlndXJhdGlvbixEQz1kZXZuZXQsREM9aW50P2NlcnRpZmljYXRlUmV2b2Nh\ndGlvbkxpc3Q/YmFzZT9vYmplY3RDbGFzcz1jUkxEaXN0cmlidXRpb25Qb2ludIY9\naHR0cDovL2NybC5kZXZuZXQuaW50L0NlcnRFbnJvbGwvTkNTRGV2TmV0JTIwSXNz\ndWluZyUyMENBLmNybDCCARYGCCsGAQUFBwEBBIIBCDCCAQQwgbYGCCsGAQUFBzAC\nhoGpbGRhcDovLy9DTj1OQ1NEZXZOZXQlMjBJc3N1aW5nJTIwQ0EsQ049QUlBLENO\nPVB1YmxpYyUyMEtleSUyMFNlcnZpY2VzLENOPVNlcnZpY2VzLENOPUNvbmZpZ3Vy\nYXRpb24sREM9ZGV2bmV0LERDPWludD9jQUNlcnRpZmljYXRlP2Jhc2U/b2JqZWN0\nQ2xhc3M9Y2VydGlmaWNhdGlvbkF1dGhvcml0eTBJBggrBgEFBQcwAoY9aHR0cDov\nL2NybC5kZXZuZXQuaW50L0NlcnRFbnJvbGwvTkNTRGV2TmV0JTIwSXNzdWluZyUy\nMENBLmNydDAhBgkrBgEEAYI3FAIEFB4SAFcAZQBiAFMAZQByAHYAZQByMA4GA1Ud\nDwEB/wQEAwIFoDATBgNVHSUEDDAKBggrBgEFBQcDATANBgkqhkiG9w0BAQsFAAOC\nAgEAFnWyFQO0Vp3ZYXNTInq2AHiGjkPpdiVJFj8X+7qhhHhjWybaE+c9tmxf+yvT\n/8ThLqKNbptXVC3YMU45tITOHDrTWXGVL63PYuGrAU2tkxiSEnQFf45vQbjzovtQ\nm3d/wLWVPbOkDA2bmUqUl9k6D+R6Tiyeqsg+epBIPt+O9FcjC1RXx6Fh3xDbKURo\nIlDm6oH3rCosXr3r5aWozJNwibi5LlKe64PkRHKp7gBstkhTxuD0A1E2poDzsewM\nlmO2mXp/lDEO3q/X8BFxI79VUPOypI++kLlrluoFYJLTrfs1CAtdjMboA01eTkgO\nVVIQFoVdLOqw2QpO2zuDAnPnds22nZOzb6/ZnuXol7Qu+YeAztX4KZoj7Jv0vQlq\niu80Knj/onGZDvtKdttL16vOuVclfkMEvaBHb83f/xw9MgyzMEpfVodaP67U+Has\nl8Pm2A5uJyjOJnufQWEFNEUbwMy+E6PBp9aSM0sfaznLHCYaSuktkjuuMzblaYGh\ndsvDfAGfaN6hDgWHa+Jo5Gljtpssz2SiTAa0PoHHo0dmqG7acSgYKXOdIcHemy/m\n3/acwfQDTFcnYr//9DHkoDymImUQ+VmRxDh0j/sB4yewd/oXis9m2MDa0t7VylVu\nukxwysXvK5fMqjg0G1UVn2pOsgUKGEBzLOwBiq/4xbUja+Y=\n-----END CERTIFICATE-----\n\n\n-----BEGIN CERTIFICATE-----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\nIMLDPEm0C0fPfnNViYnAIx66tXi6cEvSu3cagXeHa8PpAw6O\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\nKuaoZ8ZJba4dWrcnuYhfAuZwg/Hcr8YbkzwjdAw2jg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIFHTCCAwWgAwIBAgIQGQAgWCt94IRNpVmNTEmCDDANBgkqhkiG9w0BAQsFADAh\nMR8wHQYDVQQDExZOQ1NEZXZOZXQgUHJvZCBSb290IENBMB4XDTI0MTAwNDA5MTQ0\nNFoXDTQ0MTAwNDA5MjQ0M1owITEfMB0GA1UEAxMWTkNTRGV2TmV0IFByb2QgUm9v\ndCBDQTCCAiIwDQYJKoZIhvcNAQEBBQADggIPADCCAgoCggIBAKeglq4tsgEQuy9u\n1SSFVR0YdjRBBrba95BFRNYYHya8zbvJrUTY3aGwftNGKfvj+PZtLmjwKZUdIIQb\nqXi6ysbC6MBKrREwUxT6j9ONcWvm+pV8kgrFS1+gEt7xSX4KzaIJbR7B2MkR91GV\nQ8rJgDUCYZbbmTEoZ3gZWu+ae8xDfyNcAF12KxyXpdCTwiQ3I84EGUoqW0VlbyNU\nuAc2XIAFB9onQX31gCZLShKE9i41czsi2lXjyXegkuuGfkC1nYbQws4ECXkXl397\nK2GdgJ1E8ePoed26qfYGmu6K4RmfnfY98b7j42n1lu+wwx+Edi//Pus/Sdk29YrX\nA5u5NTq4TVKPocpL1MeOhzc2XshHbKS14ZXdY6VcGWIaGsOB2lJ2b2PEyYytKJVc\nTlr2SUnIRr5Yxn7Dttju1myuOHfDu4AXoYswM5D9MGWT3+HWe2onERd6kICmSe0b\nzaAhH12ml9UUX4UMx0Mw6D4ew//xI2uw8pAv0VzU+r9UontVxuoWMek8zpAimxuY\nPT36oCJUOMkiIEg2ihohNY/+nZ6N3g8s53ldqAn1oGL6sv1SA7B729/yGLIngA6l\nUJ7g5QAtEmR8PcJB2hFRGs2o8eQzrpVZgxM89rikLIPRXCqudLajiIna1iY7TMcA\neESBn86We77wj212hn3G4j+k2j7RAgMBAAGjUTBPMAsGA1UdDwQEAwIBhjAPBgNV\nHRMBAf8EBTADAQH/MB0GA1UdDgQWBBSy94Kn5kkkja5ug0M0yltVMweYCTAQBgkr\nBgEEAYI3FQEEAwIBADANBgkqhkiG9w0BAQsFAAOCAgEACGws1+VsSNwRpy2+sAys\nPAnJ0LF+l0MaW3T3g5c2rExwwR4mYgH9EghWnarLNAO28yxhtemovXcmBWsIurK1\nX0wgYqFBMoizjxtjA4SrqDHqkSMWpsF7yGAMhc3x5MFsM2WCGD3mcjJRPTQmcRRL\nGcGmaUdgm2v+q3BwyRsZAiSgSnrjpPjnFuPI+RF9mOxF5mpsR5DFBCzYp2deptvF\nNnRf506h0nJbCUXbDeAxdacKqL5jO/06hO7OW/uYyc51GE1C5+SM1Wfe4e54KQQM\niXJM/2m7YNtHmJSPCvJzpeEKhMkXRwxmQeRNqFzvxyVBNQaqAmFd2Gij+boDfHBJ\n4KlF77+730RVZeIVL8cTBMizTFkAk7DUsDo+99+M5SNQTuxyQvj1WiUed518DjS5\nZ6dGNhZbNx2bgx0hi0a5C19SvtKa1OFRwCgiS0M6PgVnm59uA3FwHrLwlhhzmVTU\nsCxyTWh7lx1GEPOwXf0NdSn6kXs4X3MWoOAlDslo28a8hN50fkON4JaNcCIi0koQ\n+rCOs9M5G4ZNvQVrkBqccOWUewEn3NNeo+Yy5Nx4kmKn0nZ6bICb0ek/GaWcaGQZ\nEepzgY+Efq00LL8qXH4QWg+B/+rL1rBJndoI1JB0fmtUJSD7XGcim2bYEiE/eSaT\njvlvccMaCzx1UZGSJhZNxiQ=\n-----END CERTIFICATE-----\n\n\n-----BEGIN CERTIFICATE-----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\n-----END CERTIFICATE-----\n"
              },
              "vllm_chat_api_key": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "VLLM Chat API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "vllm_chat_api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "vllm_chat_base_url": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "VLLM Chat Base URL",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "vllm_chat_base_url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://genaillm.devnet.int/v1"
              }
            },
            "tool_mode": false
          },
          "selected_output": "model_output",
          "showNode": true,
          "type": "VllmChatModel"
        },
        "dragging": false,
        "id": "VllmChatModel-rUKJT",
        "measured": {
          "height": 462,
          "width": 320
        },
        "position": {
          "x": -2600.153526316574,
          "y": -62.828984804369895
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-YICqp",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "The system Prompt",
            "display_name": "Text Input",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "# Role\nYou are a professional business analyst with more than 20-year experience in a world class software development company. Having technical user from the bank as the audience of your documentation. The bank is now requesting you to write a technical specification document on the cobol code they provide. Please provide information in a business formal, technical and professional style. Please write in a concise and informative tone. By referring to the knowledge base in the manual dataset, it gives you a better understanding of the cobol structure and definition. \n      Here is the knowledge base:\n      {knowledge}\n      The above is the knowledge base.\n\n# Task\nYour primary task is to analyze the COBOL code file in the path below running on HP non-stop tandem provided by the user and generate a comprehensive, structured Markdown technical document. User may ask you specific question regarding the cobol file, answer the question base on the understanding of the file.\n\n# Constraints and Limitations\n* **Adhere to Original Text**: All explanations and analyses must strictly be based on the provided COBOL code; do not guess or add functionalities do not present in the code.\n* **Professional Terminology**: Use professional and accurate terminology while ensuring clarity.\n* **Language**: Conduct analysis and documentation writing in English.\n* **Format**: Strictly follow the defined Markdown output format below, without omitting any part.\n\n\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-YICqp",
        "measured": {
          "height": 215,
          "width": 320
        },
        "position": {
          "x": -1589.2547572948774,
          "y": 799.0513074739406
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-WcjW2",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": true,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "hidden": null,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        message = Message(text=combined_text)\n        self.status = message\n        # raise ValueError(message)\n        return message\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{file_path}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-WcjW2",
        "measured": {
          "height": 332,
          "width": 320
        },
        "position": {
          "x": -1743.8520042143543,
          "y": 1663.1781683928646
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TypeConverterComponent-1RMFZ",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert between different types (Message, Data, DataFrame)",
            "display_name": "Type Convert",
            "documentation": "https://docs.langflow.org/components-processing#type-convert",
            "edited": false,
            "field_order": [
              "input_data",
              "output_type"
            ],
            "frozen": false,
            "icon": "repeat",
            "last_updated": "2025-10-03T07:36:11.569Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data Output",
                "group_outputs": false,
                "hidden": null,
                "method": "convert_to_data",
                "name": "data_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, Output, TabInput\nfrom langflow.schema import Data, DataFrame, Message\n\n\ndef convert_to_message(v) -> Message:\n    \"\"\"Convert input to Message type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Message: Converted Message object\n    \"\"\"\n    return v if isinstance(v, Message) else v.to_message()\n\n\ndef convert_to_data(v: DataFrame | Data | Message | dict) -> Data:\n    \"\"\"Convert input to Data type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Data: Converted Data object\n    \"\"\"\n    if isinstance(v, dict):\n        return Data(v)\n    if isinstance(v, Message):\n        return v.to_data()\n    return v if isinstance(v, Data) else v.to_data()\n\n\ndef convert_to_dataframe(v: DataFrame | Data | Message | dict) -> DataFrame:\n    \"\"\"Convert input to DataFrame type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        DataFrame: Converted DataFrame object\n    \"\"\"\n    if isinstance(v, dict):\n        return DataFrame([v])\n    return v if isinstance(v, DataFrame) else v.to_dataframe()\n\n\nclass TypeConverterComponent(Component):\n    display_name = \"Type Convert\"\n    description = \"Convert between different types (Message, Data, DataFrame)\"\n    documentation: str = \"https://docs.langflow.org/components-processing#type-convert\"\n    icon = \"repeat\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Input\",\n            input_types=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Accept Message, Data or DataFrame as input\",\n            required=True,\n        ),\n        TabInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Select the desired output data type\",\n            real_time_refresh=True,\n            value=\"Message\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message Output\",\n            name=\"message_output\",\n            method=\"convert_to_message\",\n        )\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"output_type\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n\n            # Add only the selected output type\n            if field_value == \"Message\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Message Output\",\n                        name=\"message_output\",\n                        method=\"convert_to_message\",\n                    ).to_dict()\n                )\n            elif field_value == \"Data\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Data Output\",\n                        name=\"data_output\",\n                        method=\"convert_to_data\",\n                    ).to_dict()\n                )\n            elif field_value == \"DataFrame\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"DataFrame Output\",\n                        name=\"dataframe_output\",\n                        method=\"convert_to_dataframe\",\n                    ).to_dict()\n                )\n\n        return frontend_node\n\n    def convert_to_message(self) -> Message:\n        \"\"\"Convert input to Message type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_message(input_value)\n        self.status = result\n        return result\n\n    def convert_to_data(self) -> Data:\n        \"\"\"Convert input to Data type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_data(input_value)\n        self.status = result\n        return result\n\n    def convert_to_dataframe(self) -> DataFrame:\n        \"\"\"Convert input to DataFrame type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_dataframe(input_value)\n        self.status = result\n        return result\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Accept Message, Data or DataFrame as input",
                "input_types": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_type": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Output Type",
                "dynamic": false,
                "info": "Select the desired output data type",
                "name": "output_type",
                "options": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Data"
              }
            },
            "tool_mode": false
          },
          "selected_output": "message_output",
          "showNode": true,
          "type": "TypeConverterComponent"
        },
        "dragging": false,
        "id": "TypeConverterComponent-1RMFZ",
        "measured": {
          "height": 273,
          "width": 320
        },
        "position": {
          "x": 4202.070687236965,
          "y": 2070.174184328992
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Memory-D3mVi",
          "node": {
            "base_classes": [
              "DataFrame",
              "Message"
            ],
            "beta": false,
            "category": "helpers",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Stores or retrieves stored chat messages from Langflow tables or an external memory.",
            "display_name": "Message History",
            "documentation": "https://docs.langflow.org/components-helpers#message-history",
            "edited": false,
            "field_order": [
              "mode",
              "message",
              "memory",
              "sender_type",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "frozen": false,
            "icon": "message-square-more",
            "key": "Memory",
            "last_updated": "2025-10-22T04:00:15.486Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Stored Messages",
                "group_outputs": false,
                "hidden": true,
                "method": "store_message",
                "name": "stored_messages",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.1676812955549333,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any, cast\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.inputs.inputs import DropdownInput, HandleInput, IntInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.memory import aget_messages, astore_message\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\nfrom langflow.utils.component_utils import set_current_fields, set_field_display\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Message History\"\n    description = \"Stores or retrieves stored chat messages from Langflow tables or an external memory.\"\n    documentation: str = \"https://docs.langflow.org/components-helpers#message-history\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n    default_keys = [\"mode\", \"memory\", \"session_id\"]\n    mode_config = {\n        \"Store\": [\"message\", \"memory\", \"sender\", \"sender_name\", \"session_id\"],\n        \"Retrieve\": [\"n_messages\", \"order\", \"template\", \"memory\", \"session_id\"],\n    }\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Retrieve\", \"Store\"],\n            value=\"Retrieve\",\n            info=\"Operation mode: Store messages or Retrieve messages.\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The chat message to be stored.\",\n            tool_mode=True,\n            dynamic=True,\n            show=False,\n        ),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"Memory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender_type\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender\",\n            display_name=\"Sender\",\n            info=\"The sender of the message. Might be Machine or User. \"\n            \"If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            value=\"\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n            tool_mode=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Message\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True),\n        Output(display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True),\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"mode\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n            if field_value == \"Store\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Stored Messages\",\n                        name=\"stored_messages\",\n                        method=\"store_message\",\n                        hidden=True,\n                        dynamic=True,\n                    )\n                ]\n            if field_value == \"Retrieve\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Messages\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True\n                    ),\n                    Output(\n                        display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True\n                    ),\n                ]\n        return frontend_node\n\n    async def store_message(self) -> Message:\n        message = Message(text=self.message) if isinstance(self.message, str) else self.message\n\n        message.session_id = self.session_id or message.session_id\n        message.sender = self.sender or message.sender or MESSAGE_SENDER_AI\n        message.sender_name = self.sender_name or message.sender_name or MESSAGE_SENDER_NAME_AI\n\n        stored_messages: list[Message] = []\n\n        if self.memory:\n            self.memory.session_id = message.session_id\n            lc_message = message.to_lc_message()\n            await self.memory.aadd_messages([lc_message])\n\n            stored_messages = await self.memory.aget_messages() or []\n\n            stored_messages = [Message.from_lc_message(m) for m in stored_messages] if stored_messages else []\n\n            if message.sender:\n                stored_messages = [m for m in stored_messages if m.sender == message.sender]\n        else:\n            await astore_message(message, flow_id=self.graph.flow_id)\n            stored_messages = (\n                await aget_messages(\n                    session_id=message.session_id, sender_name=message.sender_name, sender=message.sender\n                )\n                or []\n            )\n\n        if not stored_messages:\n            msg = \"No messages were stored. Please ensure that the session ID and sender are properly set.\"\n            raise ValueError(msg)\n\n        stored_message = stored_messages[0]\n        self.status = stored_message\n        return stored_message\n\n    async def retrieve_messages(self) -> Data:\n        sender_type = self.sender_type\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender_type == \"Machine and User\":\n            sender_type = None\n\n        if self.memory and not hasattr(self.memory, \"aget_messages\"):\n            memory_name = type(self.memory).__name__\n            err_msg = f\"External Memory object ({memory_name}) must have 'aget_messages' method.\"\n            raise AttributeError(err_msg)\n        # Check if n_messages is None or 0\n        if n_messages == 0:\n            stored = []\n        elif self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = await self.memory.aget_messages()\n            # langchain memories are supposed to return messages in ascending order\n\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages first\n\n            if order == \"DESC\":\n                stored = stored[::-1]  # Then reverse if needed\n\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender_type:\n                expected_type = MESSAGE_SENDER_AI if sender_type == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            # For internal memory, we always fetch the last N messages by ordering by DESC\n            stored = await aget_messages(\n                sender=sender_type,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=10000,\n                order=order,\n            )\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages\n\n        # self.status = stored\n        return cast(\"Data\", stored)\n\n    async def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, await self.retrieve_messages())\n        # self.status = stored_text\n        return Message(text=stored_text)\n\n    async def retrieve_messages_dataframe(self) -> DataFrame:\n        \"\"\"Convert the retrieved messages into a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the message data.\n        \"\"\"\n        messages = await self.retrieve_messages()\n        return DataFrame(messages)\n\n    def update_build_config(\n        self,\n        build_config: dotdict,\n        field_value: Any,  # noqa: ARG002\n        field_name: str | None = None,  # noqa: ARG002\n    ) -> dotdict:\n        return set_current_fields(\n            build_config=build_config,\n            action_fields=self.mode_config,\n            selected_action=build_config[\"mode\"][\"value\"],\n            default_fields=self.default_keys,\n            func=set_field_display,\n        )\n"
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "message": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": true,
                "info": "The chat message to be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Operation mode: Store messages or Retrieve messages.",
                "name": "mode",
                "options": [
                  "Retrieve",
                  "Store"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Store"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "external_options": {},
                "info": "Order of the messages.",
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": true,
                "show": false,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Sender",
                "dynamic": false,
                "info": "The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Qwen3"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Qwen3"
              },
              "sender_type": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Filter by sender type.",
                "name": "sender_type",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              }
            },
            "tool_mode": false
          },
          "selected_output": "messages_text",
          "showNode": true,
          "type": "Memory"
        },
        "dragging": false,
        "id": "Memory-D3mVi",
        "measured": {
          "height": 704,
          "width": 320
        },
        "position": {
          "x": -632.772232638715,
          "y": 605.0130890162312
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-4g5OK",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/components-io#chat-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-4g5OK",
        "measured": {
          "height": 58,
          "width": 192
        },
        "position": {
          "x": -2308.6738814026385,
          "y": 2147.344523595623
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "FileBuilder-rVIvz",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Builds files or ZIP archives, uploads them to 'My Files', and cleans up.",
            "display_name": "File Builder",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input",
              "output_folder",
              "file_extension",
              "api_key"
            ],
            "frozen": false,
            "icon": "SunshineCoder",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "File Path",
                "group_outputs": false,
                "hidden": null,
                "method": "build_output",
                "name": "result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "Langflow API Key",
                "dynamic": false,
                "info": "Langflow API key for authentication when saving the file.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\r\nimport zipfile\r\nfrom collections.abc import AsyncIterator, Iterator\r\nfrom pathlib import Path\r\n\r\nfrom langflow.services.database.models.user.model import User\r\nimport orjson\r\nimport pandas as pd\r\nfrom fastapi import UploadFile\r\nfrom fastapi.encoders import jsonable_encoder\r\n\r\nfrom langflow.api.v2.files import upload_user_file\r\nfrom langflow.custom import Component\r\nfrom langflow.io import HandleInput, StrInput, SecretStrInput\r\nfrom langflow.schema import Data, DataFrame, Message\r\nfrom langflow.services.auth.utils import create_user_longterm_token, get_current_user\r\nfrom langflow.services.database.models.user.crud import get_user_by_id\r\nfrom langflow.services.deps import get_session, get_settings_service, get_storage_service\r\nfrom langflow.template.field.base import Output\r\n\r\n\r\nclass FileBuilderComponent(Component):\r\n    display_name = \"File Builder\"\r\n    description = \"Builds files or ZIP archives, uploads them to 'My Files', and cleans up.\"\r\n    icon = \"SunshineCoder\"\r\n    name = \"FileBuilder\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"input\",\r\n            display_name=\"Input\",\r\n            info=\"The data source for file creation.\",\r\n            dynamic=True,\r\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\r\n            required=True,\r\n        ),\r\n        # StrInput(\r\n        #     name=\"file_name\",\r\n        #     display_name=\"File Name\",\r\n        #     info=\"Base name for the output file or ZIP archive. Can be ignored if input 'Data' provides a 'file_path'.\",\r\n        #     dynamic=True,\r\n        #     input_types=[\"Message\"],\r\n        #     required=True,\r\n        # ),\r\n        StrInput(\r\n            name=\"output_folder\",\r\n            display_name=\"Output Folder\",\r\n            info=\"Folder path to save the file before upload. Must exist or will be created.\",\r\n            value=\"/app/data\",  # Default if not connected\r\n            required=False,\r\n        ),\r\n        StrInput(\r\n            name=\"file_extension\",\r\n            display_name=\"File Extension\",\r\n            info=\"Used for 'Message' type or as a fallback for 'Data' type. Ignored for 'DataFrame' input.\",\r\n            value=\"txt\",\r\n            advanced=True,\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"Langflow API Key\",\r\n            info=\"Langflow API key for authentication when saving the file.\",\r\n            required=False,\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [Output(display_name=\"File Path\", name=\"result\", method=\"build_output\")]\r\n\r\n    async def build_output(self) -> Message:\r\n        \"\"\"Orchestrates file creation based on the input type.\"\"\"\r\n        input_type = self._get_input_type()\r\n\r\n        if input_type == \"DataFrame\":\r\n            return await self._build_from_dataframe()\r\n        elif input_type == \"Data\":\r\n            return await self._build_from_data()\r\n        elif input_type == \"Message\":\r\n            return await self._build_from_message()\r\n        else:\r\n            raise ValueError(f\"Unsupported input type: {input_type}\")\r\n\r\n    async def _build_from_dataframe(self) -> Message:\r\n        \"\"\"Builds a ZIP archive from a DataFrame, uploads it, and cleans up.\"\"\"\r\n        df: DataFrame = self.input\r\n        if \"file_path\" not in df.columns or \"text\" not in df.columns:\r\n            raise ValueError(\"DataFrame must contain 'file_path' and 'text' columns.\")\r\n        if not self.file_name:\r\n            raise ValueError(\"A 'File Name' is required to name the output ZIP archive.\")\r\n\r\n        final_path = Path(self.file_name).with_suffix(\".zip\")\r\n        try:\r\n            if not final_path.parent.exists():\r\n                final_path.parent.mkdir(parents=True, exist_ok=True)\r\n\r\n            with zipfile.ZipFile(final_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\r\n                for _, row in df.iterrows():\r\n                    internal_path = str(row[\"file_path\"])\r\n                    content = str(row[\"text\"])\r\n                    zf.writestr(internal_path, content.encode(\"utf-8\"))\r\n\r\n            await self._upload_file(final_path)\r\n            return self._create_success_message(final_path, \"ZIP archive built\")\r\n        finally:\r\n            # Clean up the temporary local file\r\n            final_path.unlink(missing_ok=True)\r\n\r\n    async def _build_from_data(self) -> Message:\r\n        \"\"\"Builds a single file from a Data object, uploads it, and cleans up.\"\"\"\r\n        data_dict = self.input.data\r\n        if isinstance(data_dict, dict) and \"file_path\" in data_dict:\r\n            final_path = Path(data_dict[\"file_path\"])\r\n            if \"text\" not in data_dict:\r\n                raise ValueError(\"Data with 'file_path' must also contain a 'text' key for the content.\")\r\n            content = str(data_dict[\"text\"])\r\n        else:\r\n            if not self.file_name or not self.file_extension:\r\n                raise ValueError(\"If 'Data' does not contain 'file_path', 'File Name' and 'File Extension' are required.\")\r\n            ext = self.file_extension.lstrip(\".\")\r\n            final_path = Path(self.file_name).with_suffix(f\".{ext}\")\r\n            content = orjson.dumps(jsonable_encoder(data_dict), option=orjson.OPT_INDENT_2).decode(\"utf-8\")\r\n        \r\n        try:\r\n            if not final_path.parent.exists():\r\n                final_path.parent.mkdir(parents=True, exist_ok=True)\r\n            final_path.write_text(content, encoding=\"utf-8\")\r\n            await self._upload_file(final_path)\r\n            return self._create_success_message(final_path, \"File created\")\r\n        finally:\r\n            # Clean up the temporary local file\r\n            final_path.unlink(missing_ok=True)\r\n\r\n    async def _build_from_message(self) -> Message:\r\n        message: Message = self.input\r\n        content = \"\"\r\n        if isinstance(message.text, AsyncIterator):\r\n            async for item in message.text:\r\n                content += str(item)\r\n        elif isinstance(message.text, Iterator):\r\n            content = \"\".join(str(item) for item in message.text)\r\n        else:\r\n            content = str(message.text)\r\n        \r\n        lines = content.splitlines()\r\n            \r\n        if len(lines) >= 3:\r\n            second_line = lines[2].strip()\r\n            # Expected format: * **Program ID**: CS00000F\r\n            import re\r\n            match = re.search(r\"\\*\\s+\\*\\*Program ID\\*\\*:\\s*(\\w+)\", second_line)\r\n            \r\n            if match:\r\n                program_id_from_content = match.group(1)\r\n                program_id_from_content = \"Summary_\" + program_id_from_content\r\n            else:\r\n                raise ValueError(f\"Filename not found in {second_line}\")\r\n                    \r\n        \"\"\"Builds a single file from a Message, uploads it, and cleans up.\"\"\"\r\n        if not self.file_extension:\r\n            raise ValueError(\"'File Extension' are required for 'Message' input.\")\r\n        \r\n        ext = self.file_extension.lstrip(\".\")\r\n        # raise ValueError(self.file_name.text)\r\n        # final_path = Path(program_id_from_content).with_suffix(f\".{ext}\")\r\n        output_dir = Path(self.output_folder or \".\")\r\n        final_path = output_dir / f\"{program_id_from_content}.{ext}\"\r\n        \r\n        try:\r\n            if not final_path.parent.exists():\r\n                final_path.parent.mkdir(parents=True, exist_ok=True)\r\n\r\n            \r\n            \r\n            \r\n            # file_name_str = program_id_from_content\r\n            # expected_file_prefix = file_name_str.removesuffix(\"_Summary\")\r\n\r\n            # if program_id_from_content == expected_file_prefix:\r\n                # raise ValueError(\"Same filename\")\r\n            final_path.write_text(content, encoding=\"utf-8\")\r\n            await self._upload_file(final_path)\r\n            return self._create_success_message(final_path, \"Message saved\")\r\n        finally:\r\n            # Clean up the temporary local file\r\n            final_path.unlink(missing_ok=True)\r\n\r\n    def _get_input_type(self) -> str:\r\n        \"\"\"Determines the input type.\"\"\"\r\n        if isinstance(self.input, DataFrame):\r\n            return \"DataFrame\"\r\n        if isinstance(self.input, Message):\r\n            return \"Message\"\r\n        if isinstance(self.input, Data):\r\n            return \"Data\"\r\n        raise ValueError(f\"Unsupported input type: {type(self.input)}\")\r\n\r\n    async def _upload_file(self, file_path: Path) -> None:\r\n        \"\"\"Uploads the saved file using the upload_user_file service.\"\"\"\r\n        if not file_path.exists():\r\n            raise FileNotFoundError(f\"File not found: {file_path}\")\r\n\r\n        with file_path.open(\"rb\") as f:\r\n            async for db in get_session():\r\n                current_user: User | None = None\r\n                if self.api_key:\r\n                    current_user = await get_current_user(\r\n                        token=\"\",\r\n                        query_param=self.api_key,\r\n                        header_param=\"\",\r\n                        db=db,\r\n                    )\r\n                else:\r\n                    user_id, _ = await create_user_longterm_token(db)\r\n                    current_user = await get_user_by_id(db, user_id)\r\n\r\n                # Fail if the user is not found\r\n                if not current_user:\r\n                    msg = \"User not found. Please provide a valid API key or ensure the user exists.\"\r\n                    raise ValueError(msg)\r\n                await upload_user_file(\r\n                    file=UploadFile(filename=file_path.name, file=f, size=file_path.stat().st_size),\r\n                    session=db,\r\n                    current_user=current_user,\r\n                    storage_service=get_storage_service(),\r\n                    settings_service=get_settings_service(),\r\n                )\r\n    \r\n    def _create_success_message(self, path: Path, action: str) -> Message:\r\n        \"\"\"Formats a standardized success message for uploaded files.\"\"\"\r\n        return Message(text=f\"Success: {action} and uploaded to My Files as '{path.name}'.\")\r\n"
              },
              "file_extension": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "File Extension",
                "dynamic": false,
                "info": "Used for 'Message' type or as a fallback for 'Data' type. Ignored for 'DataFrame' input.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "file_extension",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "md"
              },
              "input": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": true,
                "info": "The data source for file creation.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_folder": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Output Folder",
                "dynamic": false,
                "info": "Folder path to save the file before upload. Must exist or will be created.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_folder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "/data/projects/cobol-test/Output"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "FileBuilder"
        },
        "dragging": false,
        "id": "FileBuilder-rVIvz",
        "measured": {
          "height": 267,
          "width": 320
        },
        "position": {
          "x": 3359.7526724754694,
          "y": 1383.9469785329563
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SaveToFile-Zd2Bl",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Save data to a local file in the selected format.",
            "display_name": "Save File",
            "documentation": "https://docs.langflow.org/components-processing#save-file",
            "edited": false,
            "field_order": [
              "input",
              "file_name",
              "file_format"
            ],
            "frozen": false,
            "icon": "save",
            "key": "SaveToFile",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "File Path",
                "group_outputs": false,
                "method": "save_to_file",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.12027401062119145,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom collections.abc import AsyncIterator, Iterator\nfrom pathlib import Path\n\nimport orjson\nimport pandas as pd\nfrom fastapi import UploadFile\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.api.v2.files import upload_user_file\nfrom langflow.custom import Component\nfrom langflow.io import DropdownInput, HandleInput, StrInput\nfrom langflow.schema import Data, DataFrame, Message\nfrom langflow.services.database.models.user.crud import get_user_by_id\nfrom langflow.services.deps import get_settings_service, get_storage_service, session_scope\nfrom langflow.template.field.base import Output\n\n\nclass SaveToFileComponent(Component):\n    display_name = \"Save File\"\n    description = \"Save data to a local file in the selected format.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#save-file\"\n    icon = \"save\"\n    name = \"SaveToFile\"\n\n    # File format options for different types\n    DATA_FORMAT_CHOICES = [\"csv\", \"excel\", \"json\", \"markdown\"]\n    MESSAGE_FORMAT_CHOICES = [\"txt\", \"json\", \"markdown\"]\n\n    inputs = [\n        HandleInput(\n            name=\"input\",\n            display_name=\"Input\",\n            info=\"The input to save.\",\n            dynamic=True,\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        StrInput(\n            name=\"file_name\",\n            display_name=\"File Name\",\n            info=\"Name file will be saved as (without extension).\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"file_format\",\n            display_name=\"File Format\",\n            options=list(dict.fromkeys(DATA_FORMAT_CHOICES + MESSAGE_FORMAT_CHOICES)),\n            info=\"Select the file format to save the input. If not provided, the default format will be used.\",\n            value=\"\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [Output(display_name=\"File Path\", name=\"message\", method=\"save_to_file\")]\n\n    async def save_to_file(self) -> Message:\n        \"\"\"Save the input to a file and upload it, returning a confirmation message.\"\"\"\n        # Validate inputs\n        if not self.file_name:\n            msg = \"File name must be provided.\"\n            raise ValueError(msg)\n        if not self._get_input_type():\n            msg = \"Input type is not set.\"\n            raise ValueError(msg)\n\n        # Validate file format based on input type\n        file_format = self.file_format or self._get_default_format()\n        allowed_formats = (\n            self.MESSAGE_FORMAT_CHOICES if self._get_input_type() == \"Message\" else self.DATA_FORMAT_CHOICES\n        )\n        if file_format not in allowed_formats:\n            msg = f\"Invalid file format '{file_format}' for {self._get_input_type()}. Allowed: {allowed_formats}\"\n            raise ValueError(msg)\n\n        # Prepare file path\n        file_path = Path(self.file_name).expanduser()\n        if not file_path.parent.exists():\n            file_path.parent.mkdir(parents=True, exist_ok=True)\n        file_path = self._adjust_file_path_with_format(file_path, file_format)\n\n        # Save the input to file based on type\n        if self._get_input_type() == \"DataFrame\":\n            confirmation = self._save_dataframe(self.input, file_path, file_format)\n        elif self._get_input_type() == \"Data\":\n            confirmation = self._save_data(self.input, file_path, file_format)\n        elif self._get_input_type() == \"Message\":\n            confirmation = await self._save_message(self.input, file_path, file_format)\n        else:\n            msg = f\"Unsupported input type: {self._get_input_type()}\"\n            raise ValueError(msg)\n\n        # Upload the saved file\n        await self._upload_file(file_path)\n\n        # Return the final file path and confirmation message\n        final_path = Path.cwd() / file_path if not file_path.is_absolute() else file_path\n\n        return Message(text=f\"{confirmation} at {final_path}\")\n\n    def _get_input_type(self) -> str:\n        \"\"\"Determine the input type based on the provided input.\"\"\"\n        # Use exact type checking (type() is) instead of isinstance() to avoid inheritance issues.\n        # Since Message inherits from Data, isinstance(message, Data) would return True for Message objects,\n        # causing Message inputs to be incorrectly identified as Data type.\n        if type(self.input) is DataFrame:\n            return \"DataFrame\"\n        if type(self.input) is Message:\n            return \"Message\"\n        if type(self.input) is Data:\n            return \"Data\"\n        msg = f\"Unsupported input type: {type(self.input)}\"\n        raise ValueError(msg)\n\n    def _get_default_format(self) -> str:\n        \"\"\"Return the default file format based on input type.\"\"\"\n        if self._get_input_type() == \"DataFrame\":\n            return \"csv\"\n        if self._get_input_type() == \"Data\":\n            return \"json\"\n        if self._get_input_type() == \"Message\":\n            return \"json\"\n        return \"json\"  # Fallback\n\n    def _adjust_file_path_with_format(self, path: Path, fmt: str) -> Path:\n        \"\"\"Adjust the file path to include the correct extension.\"\"\"\n        file_extension = path.suffix.lower().lstrip(\".\")\n        if fmt == \"excel\":\n            return Path(f\"{path}.xlsx\").expanduser() if file_extension not in [\"xlsx\", \"xls\"] else path\n        return Path(f\"{path}.{fmt}\").expanduser() if file_extension != fmt else path\n\n    async def _upload_file(self, file_path: Path) -> None:\n        \"\"\"Upload the saved file using the upload_user_file service.\"\"\"\n        if not file_path.exists():\n            msg = f\"File not found: {file_path}\"\n            raise FileNotFoundError(msg)\n\n        with file_path.open(\"rb\") as f:\n            async with session_scope() as db:\n                if not self.user_id:\n                    msg = \"User ID is required for file saving.\"\n                    raise ValueError(msg)\n                current_user = await get_user_by_id(db, self.user_id)\n\n                await upload_user_file(\n                    file=UploadFile(filename=file_path.name, file=f, size=file_path.stat().st_size),\n                    session=db,\n                    current_user=current_user,\n                    storage_service=get_storage_service(),\n                    settings_service=get_settings_service(),\n                )\n\n    def _save_dataframe(self, dataframe: DataFrame, path: Path, fmt: str) -> str:\n        \"\"\"Save a DataFrame to the specified file format.\"\"\"\n        if fmt == \"csv\":\n            dataframe.to_csv(path, index=False)\n        elif fmt == \"excel\":\n            dataframe.to_excel(path, index=False, engine=\"openpyxl\")\n        elif fmt == \"json\":\n            dataframe.to_json(path, orient=\"records\", indent=2)\n        elif fmt == \"markdown\":\n            path.write_text(dataframe.to_markdown(index=False), encoding=\"utf-8\")\n        else:\n            msg = f\"Unsupported DataFrame format: {fmt}\"\n            raise ValueError(msg)\n        return f\"DataFrame saved successfully as '{path}'\"\n\n    def _save_data(self, data: Data, path: Path, fmt: str) -> str:\n        \"\"\"Save a Data object to the specified file format.\"\"\"\n        if fmt == \"csv\":\n            pd.DataFrame(data.data).to_csv(path, index=False)\n        elif fmt == \"excel\":\n            pd.DataFrame(data.data).to_excel(path, index=False, engine=\"openpyxl\")\n        elif fmt == \"json\":\n            path.write_text(\n                orjson.dumps(jsonable_encoder(data.data), option=orjson.OPT_INDENT_2).decode(\"utf-8\"), encoding=\"utf-8\"\n            )\n        elif fmt == \"markdown\":\n            path.write_text(pd.DataFrame(data.data).to_markdown(index=False), encoding=\"utf-8\")\n        else:\n            msg = f\"Unsupported Data format: {fmt}\"\n            raise ValueError(msg)\n        return f\"Data saved successfully as '{path}'\"\n\n    async def _save_message(self, message: Message, path: Path, fmt: str) -> str:\n        \"\"\"Save a Message to the specified file format, handling async iterators.\"\"\"\n        content = \"\"\n        if message.text is None:\n            content = \"\"\n        elif isinstance(message.text, AsyncIterator):\n            async for item in message.text:\n                content += str(item) + \" \"\n            content = content.strip()\n        elif isinstance(message.text, Iterator):\n            content = \" \".join(str(item) for item in message.text)\n        else:\n            content = str(message.text)\n\n        if fmt == \"txt\":\n            path.write_text(content, encoding=\"utf-8\")\n        elif fmt == \"json\":\n            path.write_text(json.dumps({\"message\": content}, indent=2), encoding=\"utf-8\")\n        elif fmt == \"markdown\":\n            path.write_text(f\"**Message:**\\n\\n{content}\", encoding=\"utf-8\")\n        else:\n            msg = f\"Unsupported Message format: {fmt}\"\n            raise ValueError(msg)\n        return f\"Message saved successfully as '{path}'\"\n"
              },
              "file_format": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "File Format",
                "dynamic": false,
                "external_options": {},
                "info": "Select the file format to save the input. If not provided, the default format will be used.",
                "name": "file_format",
                "options": [
                  "csv",
                  "excel",
                  "json",
                  "markdown",
                  "txt"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "file_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "File Name",
                "dynamic": false,
                "info": "Name file will be saved as (without extension).",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "file_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "input": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": true,
                "info": "The input to save.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SaveToFile"
        },
        "dragging": false,
        "id": "SaveToFile-Zd2Bl",
        "measured": {
          "height": 344,
          "width": 320
        },
        "position": {
          "x": 4878.133527957021,
          "y": 3102.05834452267
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LoopPlusComponent-cRenT",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Iterates over a list of Data objects, outputting one item at a time and aggregating results from loop inputs.",
            "display_name": "Loop Plus",
            "documentation": "https://docs.langflow.org/components-logic#loop",
            "edited": false,
            "field_order": [
              "data"
            ],
            "frozen": false,
            "icon": "SunshineCoder",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": true,
                "cache": true,
                "display_name": "Item",
                "group_outputs": true,
                "method": "item_output",
                "name": "item",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Done",
                "group_outputs": true,
                "method": "done_output",
                "name": "done",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.template.field.base import Output\nimport copy\n\nclass LoopPlusComponent(Component):\n    display_name = \"Loop Plus\"\n    description = (\n        \"Iterates over a list of Data objects, outputting one item at a time and aggregating results from loop inputs.\"\n    )\n    documentation: str = \"https://docs.langflow.org/components-logic#loop\"\n    icon = \"SunshineCoder\"\n\n    inputs = [\n        HandleInput(\n            name=\"data\",\n            display_name=\"Inputs\",\n            info=\"The initial list of Data objects or DataFrame to iterate over.\",\n            input_types=[\"Data\", \"DataInput\", \"DataFrame\"],\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Item\", name=\"item\", method=\"item_output\", allows_loop=True, group_outputs=True),\n        Output(display_name=\"Done\", name=\"done\", method=\"done_output\", group_outputs=True),\n    ]\n\n    def initialize_data(self) -> None:\n        if self.ctx.get(f\"{self._id}_initialized\", False):\n            return\n\n        data_list = self._validate_data(self.data)\n        self.update_ctx(\n            {\n                f\"{self._id}_data\": data_list,\n                f\"{self._id}_loop_inputs\": [],\n                f\"{self._id}_initialized\": True,\n            }\n        )\n\n    def _validate_data(self, data):\n        if isinstance(data, DataFrame):\n            return data.to_data_list()\n        if isinstance(data, Data):\n            return [data]\n        if isinstance(data, list) and all(isinstance(item, Data) for item in data):\n            return data\n        msg = \"The 'data' input must be a DataFrame, a list of Data objects, or a single Data object.\"\n        raise TypeError(msg)\n\n    def is_loop_done(self):\n        \"\"\" The loop is only truly done when we have collected a result for every item. \"\"\"\n        data = self.ctx.get(f\"{self._id}_data\", [])\n        results = self.ctx.get(f\"{self._id}_loop_inputs\", [])\n        return len(results) >= len(data)\n\n    def item_output(self) -> Data:\n        \"\"\"\n        Outputs the next item based on how many results we have collected so far.\n        This synchronizes the output with the data flow.\n        \"\"\"\n        self.initialize_data()\n\n        # Always collect the incoming result first.\n        if self.item:\n            self.ctx.get(f\"{self._id}_loop_inputs\", []).append(self.item)\n\n        if self.is_loop_done():\n            self.stop(\"item\")\n            return Data()\n\n        # The index of the item to output next is the current number of collected results.\n        next_item_index = len(self.ctx.get(f\"{self._id}_loop_inputs\", []))\n        data_list = self.ctx.get(f\"{self._id}_data\", [])\n\n        if next_item_index < len(data_list):\n            item_to_output = data_list[next_item_index]\n            self.update_dependency()\n            return item_to_output\n        else:\n            # Should not happen if is_loop_done() is checked first, but as a safeguard:\n            self.stop(\"item\")\n            return Data()\n\n    def update_dependency(self):\n        item_dependency_id = self.get_incoming_edge_by_target_param(\"item\")\n        if item_dependency_id and item_dependency_id not in self.graph.run_manager.run_predecessors[self._id]:\n            self.graph.run_manager.run_predecessors[self._id].append(item_dependency_id)\n\n    def done_output(self) -> DataFrame:\n        \"\"\"\n        Once all results are collected, this method performs the final, one-time aggregation.\n        \"\"\"\n        self.initialize_data()\n\n        if self.is_loop_done():\n            self.stop(\"item\")\n            self.start(\"done\")\n\n            original_items = self.ctx.get(f\"{self._id}_data\", [])\n            results = self.ctx.get(f\"{self._id}_loop_inputs\", [])\n\n            final_list = []\n            for i, original_item in enumerate(original_items):\n                merged_item = copy.deepcopy(original_item)\n                if i < len(results):\n                    processed_item = results[i][0] if isinstance(results[i], list) else results[i]\n                    if isinstance(processed_item, Data):\n                        merged_item.data.update(processed_item.data)\n                final_list.append(merged_item)\n\n            return DataFrame(final_list)\n\n        self.stop(\"done\")\n        return DataFrame([])\n"
              },
              "data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "The initial list of Data objects or DataFrame to iterate over.",
                "input_types": [
                  "Data",
                  "DataInput",
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "LoopPlusComponent"
        },
        "dragging": false,
        "id": "LoopPlusComponent-cRenT",
        "measured": {
          "height": 243,
          "width": 320
        },
        "position": {
          "x": -2275.5184924514515,
          "y": 1577.3929464137188
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CreateList-qjl02",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "category": "helpers",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Creates a list of texts.",
            "display_name": "Create List",
            "documentation": "",
            "edited": false,
            "field_order": [
              "texts"
            ],
            "frozen": false,
            "icon": "list",
            "key": "CreateList",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "group_outputs": false,
                "method": "create_list",
                "name": "list",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "method": "as_dataframe",
                "name": "dataframe",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.054511020721633226,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import StrInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.template.field.base import Output\n\n\nclass CreateListComponent(Component):\n    display_name = \"Create List\"\n    description = \"Creates a list of texts.\"\n    icon = \"list\"\n    name = \"CreateList\"\n    legacy = True\n\n    inputs = [\n        StrInput(\n            name=\"texts\",\n            display_name=\"Texts\",\n            info=\"Enter one or more texts.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data List\", name=\"list\", method=\"create_list\"),\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"as_dataframe\"),\n    ]\n\n    def create_list(self) -> list[Data]:\n        data = [Data(text=text) for text in self.texts]\n        self.status = data\n        return data\n\n    def as_dataframe(self) -> DataFrame:\n        \"\"\"Convert the list of Data objects into a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the list data.\n        \"\"\"\n        return DataFrame(self.create_list())\n"
              },
              "texts": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Texts",
                "dynamic": false,
                "info": "Enter one or more texts.",
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "texts",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "By analyzing {file_name} in knowledge base, provide the Program Overview, write no less than 300 words in this session. Generate the Program Overview one time only, do not repeat.   ## 1. Program Overview  * **Program ID**: `[Extracted from IDENTIFICATION DIVISION]` * **Function Description**: A concise summary of the program's main business purpose. * **Main Processes **: List out all the processes in the cobol program, by looking into the PROCEDURE DIVISION.",
                  "By analyzing {file_name} in knowledge base, provide the Flowchart. Use Mermaid syntax to visualize the main execution flow of `PROCEDURE DIVISION`.  Please strictly generate the document in the following Markdown structure:  ## 2. Flowchart ```mermaid graph TD     A[Start] --> B[Read Input File];     B --> C[End of File?];     C -- Yes --> D[Close Files];     C -- No --> E[Process Record];     E --> F[Write to Output File];     F --> B;     D --> G[End]; ```",
                  "By analyzing {file_name} in knowledge base, provide the Input/Output of the code in below md format  ## 3. Input/Output * **Input**:     * `[Input File Name 1]`: [Briefly describe the purpose and key fields of this file].     * `[Input File Name 2]`: ... \t... * **Output**:     * `[Output File Name 1]`: [Briefly describe the purpose and generation method of this file].     * `[Output File Name 2]`: ... \t...",
                  "By analyzing {file_name} in knowledge base, provide the Program Structure Analysis of the code in below md format  ## 4. Program Structure Analysis * **`IDENTIFICATION DIVISION`**: Metadata information of the program, such as author, date, etc. * **`ENVIRONMENT DIVISION`**: Describes the program's runtime environment, especially `FILE-CONTROL` related to files. * **`DATA DIVISION`**:     * **`FILE SECTION`**: Defines input/output files (FD) used by the program and their record layouts.     * **`WORKING-STORAGE SECTION`**: Describes key variables, flags, counters, and data structures used internally in the program. * **`PROCEDURE DIVISION`**: The core logic of the program, describing major paragraphs and their functions.",
                  "By analyzing {file_name} in knowledge base,  First, list out all the functions by looking for the PERFORM (`perform`) in `PROCEDURE DIVISION` in logical order and provide the line no for that function.  Do not miss out any `perform` in the `PROCEDURE DIVISION`.  If the function is calling another sub-function, please list out all the sub-function being called in the main function. List all the sub-functions being called as a normal function after all the main function. Second, provide the mermaid flowchart and detailed steps for each function. For both flowcharts and steps, it has to be as detailed as possible to capture all detailed logic of the function.  Detailed validation rules, default values, error handling must be clearly stated in the steps. The steps have to be in sync with the flowchart.  Write no less than 150 words for each function. Do not need to generate other section such as overview, flowchart, input/output, Program Structure Analysis. Only need to generate the Detailed Core Logic part. provide the Detailed Core Logic of the code in below md format.  ## 5. Detailed Core Logic  * **Function List**:     * `[Function 1]`: From Line [150] to line [200]. [Function 1] is calling [Sub-function 1]     * `[Function 2]`: From Line [205] to line [249]. \t* `[Sub-function 1]`: From Line [833] to line [892]. [Sub-function 1] is calling [Sub-function 2] \t* `[Sub-function 2]`: From Line [916] to line [990]. \t... \t * **`[Function 1]`**:  \t```mermaid \tgraph TD \t\tflowchart for Function 1 \t```     * [Step 1, describe the first step of Function 1 in detail] \t* [Step 2, describe the second step of Function 1 in detail] \t...  * **`[Function 2]`**:  \t```mermaid \tgraph TD \t\tflowchart for Function 2 \t```     * [Step 1, describe the first step of Function 2 in detail] \t* [Step 2, describe the second step of Function 2 in detail] \t... ...",
                  "By analyzing {file_name} in knowledge base, provide the Dependencies of the code in below md format, list out all the copybooks and called program, do not miss out one of it. For Copybooks, please look for the `COPY` statements in the code. For Called Program, please look for the `CALL` statements in the code.  ## 6. Dependencies   * **Copybooks**:       * `[COPY 'COPYBOOK1.CPY']`: [Briefly explain the purpose of this copybook, e.g., record definitions]. \t  * `[COPY 'COPYBOOK2.CPY']`: [Briefly explain the purpose of this copybook, e.g., record definitions]. \t  ...   * **Called Programs**:       * `[CALL 'SUBPROG1']`: [Briefly explain the purpose of calling this subroutine]. \t  * `[CALL 'SUBPROG2']`: [Briefly explain the purpose of calling this subroutine]. \t  ..."
                ]
              }
            },
            "tool_mode": false
          },
          "selected_output": "dataframe",
          "showNode": true,
          "type": "CreateList"
        },
        "dragging": false,
        "id": "CreateList-qjl02",
        "measured": {
          "height": 449,
          "width": 320
        },
        "position": {
          "x": -631.7964075371433,
          "y": 3969.888903886059
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-J4S7M",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "last_updated": "2025-10-21T06:24:08.857Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "hidden": null,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Clean Data",
                "dynamic": false,
                "info": "Enable to clean the data by removing empty rows and lines in each cell of the DataFrame/ Data object.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-J4S7M",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 180.74005333612877,
          "y": 3987.2617751114653
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "VariablePromptComponent-gbzH7",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Prompt with variable inputs and message output.",
            "display_name": "Variable Prompt",
            "documentation": "",
            "edited": true,
            "field_order": [
              "template",
              "file_name"
            ],
            "frozen": false,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\r\nfrom langflow.io import MessageTextInput, Output\r\nfrom langflow.schema.message import Message\r\n\r\n\r\nclass VariablePromptComponent(Component):\r\n    display_name = \"Variable Prompt\"\r\n    description = \"Prompt with variable inputs and message output.\"\r\n    inputs = [\r\n        MessageTextInput(name=\"template\", display_name=\"Template\"),\r\n        MessageTextInput(name=\"file_name\", display_name=\"File Name\"),\r\n    ]\r\n    outputs = [\r\n        Output(name=\"prompt\", display_name=\"Prompt\", method=\"build_prompt\"),\r\n    ]\r\n\r\n    async def build_prompt(self) -> Message:\r\n        template_message = self._attributes.get(\"template\")\r\n        file_name_message = self._attributes.get(\"file_name\")\r\n\r\n        # Convert inputs to Message objects if needed\r\n        if isinstance(template_message, dict):\r\n            prompt = Message.from_dict(template_message)\r\n        elif isinstance(template_message, Message):\r\n            prompt = template_message\r\n        else:\r\n            prompt = Message(text=template_message or \"\")\r\n\r\n        if isinstance(file_name_message, dict):\r\n            file_name_msg = Message.from_dict(file_name_message)\r\n        elif isinstance(file_name_message, Message):\r\n            file_name_msg = file_name_message\r\n        else:\r\n            file_name_msg = Message(text=file_name_message or \"\")\r\n\r\n        # Extract the actual file_name text to substitute\r\n        file_name_text = file_name_msg.text.strip()\r\n\r\n        # Substitute the variable in the template\r\n        rendered_text = prompt.text.format(file_name=file_name_text)\r\n\r\n        # Return the rendered prompt as a Message\r\n        return Message(text=rendered_text)\r\n"
              },
              "file_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "File Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "file_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "VariablePromptComponent"
        },
        "dragging": false,
        "id": "VariablePromptComponent-gbzH7",
        "measured": {
          "height": 289,
          "width": 320
        },
        "position": {
          "x": 641.3374518409049,
          "y": 4034.905131365213
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-F1CeB",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "Text Input",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "SampleFile_000M"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-F1CeB",
        "measured": {
          "height": 215,
          "width": 320
        },
        "position": {
          "x": 441.22037496476173,
          "y": 3664.0894332055177
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TypeConverterComponent-U7VX1",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert between different types (Message, Data, DataFrame)",
            "display_name": "Type Convert",
            "documentation": "https://docs.langflow.org/components-processing#type-convert",
            "edited": false,
            "field_order": [
              "input_data",
              "output_type"
            ],
            "frozen": false,
            "icon": "repeat",
            "key": "TypeConverterComponent",
            "last_updated": "2025-10-21T06:44:39.602Z",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data Output",
                "group_outputs": false,
                "hidden": null,
                "method": "convert_to_data",
                "name": "data_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.008834292878014125,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, Output, TabInput\nfrom langflow.schema import Data, DataFrame, Message\n\n\ndef convert_to_message(v) -> Message:\n    \"\"\"Convert input to Message type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Message: Converted Message object\n    \"\"\"\n    return v if isinstance(v, Message) else v.to_message()\n\n\ndef convert_to_data(v: DataFrame | Data | Message | dict) -> Data:\n    \"\"\"Convert input to Data type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Data: Converted Data object\n    \"\"\"\n    if isinstance(v, dict):\n        return Data(v)\n    if isinstance(v, Message):\n        return v.to_data()\n    return v if isinstance(v, Data) else v.to_data()\n\n\ndef convert_to_dataframe(v: DataFrame | Data | Message | dict) -> DataFrame:\n    \"\"\"Convert input to DataFrame type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        DataFrame: Converted DataFrame object\n    \"\"\"\n    if isinstance(v, dict):\n        return DataFrame([v])\n    return v if isinstance(v, DataFrame) else v.to_dataframe()\n\n\nclass TypeConverterComponent(Component):\n    display_name = \"Type Convert\"\n    description = \"Convert between different types (Message, Data, DataFrame)\"\n    documentation: str = \"https://docs.langflow.org/components-processing#type-convert\"\n    icon = \"repeat\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Input\",\n            input_types=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Accept Message, Data or DataFrame as input\",\n            required=True,\n        ),\n        TabInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Select the desired output data type\",\n            real_time_refresh=True,\n            value=\"Message\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message Output\",\n            name=\"message_output\",\n            method=\"convert_to_message\",\n        )\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"output_type\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n\n            # Add only the selected output type\n            if field_value == \"Message\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Message Output\",\n                        name=\"message_output\",\n                        method=\"convert_to_message\",\n                    ).to_dict()\n                )\n            elif field_value == \"Data\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Data Output\",\n                        name=\"data_output\",\n                        method=\"convert_to_data\",\n                    ).to_dict()\n                )\n            elif field_value == \"DataFrame\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"DataFrame Output\",\n                        name=\"dataframe_output\",\n                        method=\"convert_to_dataframe\",\n                    ).to_dict()\n                )\n\n        return frontend_node\n\n    def convert_to_message(self) -> Message:\n        \"\"\"Convert input to Message type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_message(input_value)\n        self.status = result\n        return result\n\n    def convert_to_data(self) -> Data:\n        \"\"\"Convert input to Data type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_data(input_value)\n        self.status = result\n        return result\n\n    def convert_to_dataframe(self) -> DataFrame:\n        \"\"\"Convert input to DataFrame type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_dataframe(input_value)\n        self.status = result\n        return result\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Accept Message, Data or DataFrame as input",
                "input_types": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_type": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Output Type",
                "dynamic": false,
                "info": "Select the desired output data type",
                "name": "output_type",
                "options": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Data"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TypeConverterComponent"
        },
        "dragging": false,
        "id": "TypeConverterComponent-U7VX1",
        "measured": {
          "height": 273,
          "width": 320
        },
        "position": {
          "x": 1174.2340096077296,
          "y": 4053.4875307671414
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DataFrameOperations-iendh",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Perform various operations on a DataFrame.",
            "display_name": "DataFrame Operations",
            "documentation": "https://docs.langflow.org/components-processing#dataframe-operations",
            "edited": false,
            "field_order": [
              "df",
              "operation",
              "column_name",
              "filter_value",
              "filter_operator",
              "ascending",
              "new_column_name",
              "new_column_value",
              "columns_to_select",
              "num_rows",
              "replace_value",
              "replacement_value"
            ],
            "frozen": false,
            "icon": "table",
            "key": "DataFrameOperations",
            "last_updated": "2026-02-02T03:24:48.884Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "loop_types": null,
                "method": "perform_operation",
                "name": "output",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_frontend_node_flow_id": {
                "value": "ce767eeb-d198-4f14-b5a1-2ec08b22b1ec"
              },
              "_frontend_node_folder_id": {
                "value": "ad4db6bf-94a7-4138-978a-b55a38dc9cf4"
              },
              "_type": "Component",
              "ascending": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Sort Ascending",
                "dynamic": true,
                "info": "Whether to sort in ascending order.",
                "list": false,
                "list_add_label": "Add More",
                "name": "ascending",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import pandas as pd\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs import SortableListInput\nfrom langflow.io import (\n    BoolInput,\n    DataFrameInput,\n    DropdownInput,\n    IntInput,\n    MessageTextInput,\n    Output,\n    StrInput,\n)\nfrom langflow.logging import logger\nfrom langflow.schema.dataframe import DataFrame\n\n\nclass DataFrameOperationsComponent(Component):\n    display_name = \"DataFrame Operations\"\n    description = \"Perform various operations on a DataFrame.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#dataframe-operations\"\n    icon = \"table\"\n    name = \"DataFrameOperations\"\n\n    OPERATION_CHOICES = [\n        \"Add Column\",\n        \"Drop Column\",\n        \"Filter\",\n        \"Head\",\n        \"Rename Column\",\n        \"Replace Value\",\n        \"Select Columns\",\n        \"Sort\",\n        \"Tail\",\n        \"Drop Duplicates\",\n    ]\n\n    inputs = [\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The input DataFrame to operate on.\",\n            required=True,\n        ),\n        SortableListInput(\n            name=\"operation\",\n            display_name=\"Operation\",\n            placeholder=\"Select Operation\",\n            info=\"Select the DataFrame operation to perform.\",\n            options=[\n                {\"name\": \"Add Column\", \"icon\": \"plus\"},\n                {\"name\": \"Drop Column\", \"icon\": \"minus\"},\n                {\"name\": \"Filter\", \"icon\": \"filter\"},\n                {\"name\": \"Head\", \"icon\": \"arrow-up\"},\n                {\"name\": \"Rename Column\", \"icon\": \"pencil\"},\n                {\"name\": \"Replace Value\", \"icon\": \"replace\"},\n                {\"name\": \"Select Columns\", \"icon\": \"columns\"},\n                {\"name\": \"Sort\", \"icon\": \"arrow-up-down\"},\n                {\"name\": \"Tail\", \"icon\": \"arrow-down\"},\n                {\"name\": \"Drop Duplicates\", \"icon\": \"copy-x\"},\n            ],\n            real_time_refresh=True,\n            limit=1,\n        ),\n        StrInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=\"The column name to use for the operation.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"filter_value\",\n            display_name=\"Filter Value\",\n            info=\"The value to filter rows by.\",\n            dynamic=True,\n            show=False,\n        ),\n        DropdownInput(\n            name=\"filter_operator\",\n            display_name=\"Filter Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"greater than\", \"less than\"],\n            value=\"equals\",\n            info=\"The operator to apply for filtering rows.\",\n            advanced=False,\n            dynamic=True,\n            show=False,\n        ),\n        BoolInput(\n            name=\"ascending\",\n            display_name=\"Sort Ascending\",\n            info=\"Whether to sort in ascending order.\",\n            dynamic=True,\n            show=False,\n            value=True,\n        ),\n        StrInput(\n            name=\"new_column_name\",\n            display_name=\"New Column Name\",\n            info=\"The new column name when renaming or adding a column.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"new_column_value\",\n            display_name=\"New Column Value\",\n            info=\"The value to populate the new column with.\",\n            dynamic=True,\n            show=False,\n        ),\n        StrInput(\n            name=\"columns_to_select\",\n            display_name=\"Columns to Select\",\n            dynamic=True,\n            is_list=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"num_rows\",\n            display_name=\"Number of Rows\",\n            info=\"Number of rows to return (for head/tail).\",\n            dynamic=True,\n            show=False,\n            value=5,\n        ),\n        MessageTextInput(\n            name=\"replace_value\",\n            display_name=\"Value to Replace\",\n            info=\"The value to replace in the column.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"replacement_value\",\n            display_name=\"Replacement Value\",\n            info=\"The value to replace with.\",\n            dynamic=True,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"DataFrame\",\n            name=\"output\",\n            method=\"perform_operation\",\n            info=\"The resulting DataFrame after the operation.\",\n        )\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        dynamic_fields = [\n            \"column_name\",\n            \"filter_value\",\n            \"filter_operator\",\n            \"ascending\",\n            \"new_column_name\",\n            \"new_column_value\",\n            \"columns_to_select\",\n            \"num_rows\",\n            \"replace_value\",\n            \"replacement_value\",\n        ]\n        for field in dynamic_fields:\n            build_config[field][\"show\"] = False\n\n        if field_name == \"operation\":\n            # Handle SortableListInput format\n            if isinstance(field_value, list):\n                operation_name = field_value[0].get(\"name\", \"\") if field_value else \"\"\n            else:\n                operation_name = field_value or \"\"\n\n            # If no operation selected, all dynamic fields stay hidden (already set to False above)\n            if not operation_name:\n                return build_config\n\n            if operation_name == \"Filter\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"filter_value\"][\"show\"] = True\n                build_config[\"filter_operator\"][\"show\"] = True\n            elif operation_name == \"Sort\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"ascending\"][\"show\"] = True\n            elif operation_name == \"Drop Column\":\n                build_config[\"column_name\"][\"show\"] = True\n            elif operation_name == \"Rename Column\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"new_column_name\"][\"show\"] = True\n            elif operation_name == \"Add Column\":\n                build_config[\"new_column_name\"][\"show\"] = True\n                build_config[\"new_column_value\"][\"show\"] = True\n            elif operation_name == \"Select Columns\":\n                build_config[\"columns_to_select\"][\"show\"] = True\n            elif operation_name in {\"Head\", \"Tail\"}:\n                build_config[\"num_rows\"][\"show\"] = True\n            elif operation_name == \"Replace Value\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"replace_value\"][\"show\"] = True\n                build_config[\"replacement_value\"][\"show\"] = True\n            elif operation_name == \"Drop Duplicates\":\n                build_config[\"column_name\"][\"show\"] = True\n\n        return build_config\n\n    def perform_operation(self) -> DataFrame:\n        df_copy = self.df.copy()\n\n        # Handle SortableListInput format for operation\n        operation_input = getattr(self, \"operation\", [])\n        if isinstance(operation_input, list) and len(operation_input) > 0:\n            op = operation_input[0].get(\"name\", \"\")\n        else:\n            op = \"\"\n\n        # If no operation selected, return original DataFrame\n        if not op:\n            return df_copy\n\n        if op == \"Filter\":\n            return self.filter_rows_by_value(df_copy)\n        if op == \"Sort\":\n            return self.sort_by_column(df_copy)\n        if op == \"Drop Column\":\n            return self.drop_column(df_copy)\n        if op == \"Rename Column\":\n            return self.rename_column(df_copy)\n        if op == \"Add Column\":\n            return self.add_column(df_copy)\n        if op == \"Select Columns\":\n            return self.select_columns(df_copy)\n        if op == \"Head\":\n            return self.head(df_copy)\n        if op == \"Tail\":\n            return self.tail(df_copy)\n        if op == \"Replace Value\":\n            return self.replace_values(df_copy)\n        if op == \"Drop Duplicates\":\n            return self.drop_duplicates(df_copy)\n        msg = f\"Unsupported operation: {op}\"\n        logger.error(msg)\n        raise ValueError(msg)\n\n    def filter_rows_by_value(self, df: DataFrame) -> DataFrame:\n        column = df[self.column_name]\n        filter_value = self.filter_value\n\n        # Handle regular DropdownInput format (just a string value)\n        operator = getattr(self, \"filter_operator\", \"equals\")  # Default to equals for backward compatibility\n\n        if operator == \"equals\":\n            mask = column == filter_value\n        elif operator == \"not equals\":\n            mask = column != filter_value\n        elif operator == \"contains\":\n            mask = column.astype(str).str.contains(str(filter_value), na=False)\n        elif operator == \"starts with\":\n            mask = column.astype(str).str.startswith(str(filter_value), na=False)\n        elif operator == \"ends with\":\n            mask = column.astype(str).str.endswith(str(filter_value), na=False)\n        elif operator == \"greater than\":\n            try:\n                # Try to convert filter_value to numeric for comparison\n                numeric_value = pd.to_numeric(filter_value)\n                mask = column > numeric_value\n            except (ValueError, TypeError):\n                # If conversion fails, compare as strings\n                mask = column.astype(str) > str(filter_value)\n        elif operator == \"less than\":\n            try:\n                # Try to convert filter_value to numeric for comparison\n                numeric_value = pd.to_numeric(filter_value)\n                mask = column < numeric_value\n            except (ValueError, TypeError):\n                # If conversion fails, compare as strings\n                mask = column.astype(str) < str(filter_value)\n        else:\n            mask = column == filter_value  # Fallback to equals\n\n        return DataFrame(df[mask])\n\n    def sort_by_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.sort_values(by=self.column_name, ascending=self.ascending))\n\n    def drop_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.drop(columns=[self.column_name]))\n\n    def rename_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.rename(columns={self.column_name: self.new_column_name}))\n\n    def add_column(self, df: DataFrame) -> DataFrame:\n        df[self.new_column_name] = [self.new_column_value] * len(df)\n        return DataFrame(df)\n\n    def select_columns(self, df: DataFrame) -> DataFrame:\n        columns = [col.strip() for col in self.columns_to_select]\n        return DataFrame(df[columns])\n\n    def head(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.head(self.num_rows))\n\n    def tail(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.tail(self.num_rows))\n\n    def replace_values(self, df: DataFrame) -> DataFrame:\n        df[self.column_name] = df[self.column_name].replace(self.replace_value, self.replacement_value)\n        return DataFrame(df)\n\n    def drop_duplicates(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.drop_duplicates(subset=self.column_name))\n"
              },
              "column_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": true,
                "info": "The column name to use for the operation.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "columns_to_select": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Columns to Select",
                "dynamic": true,
                "info": "",
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "columns_to_select",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "text"
                ]
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The input DataFrame to operate on.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "filter_operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Filter Operator",
                "dynamic": true,
                "external_options": {},
                "info": "The operator to apply for filtering rows.",
                "name": "filter_operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "greater than",
                  "less than"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "equals"
              },
              "filter_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Filter Value",
                "dynamic": true,
                "info": "The value to filter rows by.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "filter_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "new_column_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "New Column Name",
                "dynamic": true,
                "info": "The new column name when renaming or adding a column.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "new_column_name",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "new_column_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "New Column Value",
                "dynamic": true,
                "info": "The value to populate the new column with.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "new_column_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "num_rows": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Rows",
                "dynamic": true,
                "info": "Number of rows to return (for head/tail).",
                "list": false,
                "list_add_label": "Add More",
                "name": "num_rows",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "operation": {
                "_input_type": "SortableListInput",
                "advanced": false,
                "display_name": "Operation",
                "dynamic": false,
                "info": "Select the DataFrame operation to perform.",
                "limit": 1,
                "name": "operation",
                "options": [
                  {
                    "icon": "plus",
                    "name": "Add Column"
                  },
                  {
                    "icon": "minus",
                    "name": "Drop Column"
                  },
                  {
                    "icon": "filter",
                    "name": "Filter"
                  },
                  {
                    "icon": "arrow-up",
                    "name": "Head"
                  },
                  {
                    "icon": "pencil",
                    "name": "Rename Column"
                  },
                  {
                    "icon": "replace",
                    "name": "Replace Value"
                  },
                  {
                    "icon": "columns",
                    "name": "Select Columns"
                  },
                  {
                    "icon": "arrow-up-down",
                    "name": "Sort"
                  },
                  {
                    "icon": "arrow-down",
                    "name": "Tail"
                  },
                  {
                    "icon": "copy-x",
                    "name": "Drop Duplicates"
                  }
                ],
                "placeholder": "Select Operation",
                "real_time_refresh": true,
                "required": false,
                "search_category": [],
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "sortableList",
                "value": [
                  {
                    "chosen": false,
                    "icon": "columns",
                    "name": "Select Columns",
                    "selected": false
                  }
                ]
              },
              "replace_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Value to Replace",
                "dynamic": true,
                "info": "The value to replace in the column.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "replace_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "replacement_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Replacement Value",
                "dynamic": true,
                "info": "The value to replace with.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "replacement_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DataFrameOperations"
        },
        "dragging": false,
        "id": "DataFrameOperations-iendh",
        "measured": {
          "height": 329,
          "width": 320
        },
        "position": {
          "x": -162.37430271572407,
          "y": 4505.152441284567
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LoopPlusComponent-sR9vl",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Iterates over a list of Data objects, outputting one item at a time and aggregating results from loop inputs.",
            "display_name": "Loop Plus",
            "documentation": "https://docs.langflow.org/components-logic#loop",
            "edited": false,
            "field_order": [
              "data"
            ],
            "frozen": false,
            "icon": "SunshineCoder",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": true,
                "cache": true,
                "display_name": "Item",
                "group_outputs": true,
                "method": "item_output",
                "name": "item",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Done",
                "group_outputs": true,
                "method": "done_output",
                "name": "done",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.template.field.base import Output\nimport copy\n\nclass LoopPlusComponent(Component):\n    display_name = \"Loop Plus\"\n    description = (\n        \"Iterates over a list of Data objects, outputting one item at a time and aggregating results from loop inputs.\"\n    )\n    documentation: str = \"https://docs.langflow.org/components-logic#loop\"\n    icon = \"SunshineCoder\"\n\n    inputs = [\n        HandleInput(\n            name=\"data\",\n            display_name=\"Inputs\",\n            info=\"The initial list of Data objects or DataFrame to iterate over.\",\n            input_types=[\"Data\", \"DataInput\", \"DataFrame\"],\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Item\", name=\"item\", method=\"item_output\", allows_loop=True, group_outputs=True),\n        Output(display_name=\"Done\", name=\"done\", method=\"done_output\", group_outputs=True),\n    ]\n\n    def initialize_data(self) -> None:\n        if self.ctx.get(f\"{self._id}_initialized\", False):\n            return\n\n        data_list = self._validate_data(self.data)\n        self.update_ctx(\n            {\n                f\"{self._id}_data\": data_list,\n                f\"{self._id}_loop_inputs\": [],\n                f\"{self._id}_initialized\": True,\n            }\n        )\n\n    def _validate_data(self, data):\n        if isinstance(data, DataFrame):\n            return data.to_data_list()\n        if isinstance(data, Data):\n            return [data]\n        if isinstance(data, list) and all(isinstance(item, Data) for item in data):\n            return data\n        msg = \"The 'data' input must be a DataFrame, a list of Data objects, or a single Data object.\"\n        raise TypeError(msg)\n\n    def is_loop_done(self):\n        \"\"\" The loop is only truly done when we have collected a result for every item. \"\"\"\n        data = self.ctx.get(f\"{self._id}_data\", [])\n        results = self.ctx.get(f\"{self._id}_loop_inputs\", [])\n        return len(results) >= len(data)\n\n    def item_output(self) -> Data:\n        \"\"\"\n        Outputs the next item based on how many results we have collected so far.\n        This synchronizes the output with the data flow.\n        \"\"\"\n        self.initialize_data()\n\n        # Always collect the incoming result first.\n        if self.item:\n            self.ctx.get(f\"{self._id}_loop_inputs\", []).append(self.item)\n\n        if self.is_loop_done():\n            self.stop(\"item\")\n            return Data()\n\n        # The index of the item to output next is the current number of collected results.\n        next_item_index = len(self.ctx.get(f\"{self._id}_loop_inputs\", []))\n        data_list = self.ctx.get(f\"{self._id}_data\", [])\n\n        if next_item_index < len(data_list):\n            item_to_output = data_list[next_item_index]\n            self.update_dependency()\n            return item_to_output\n        else:\n            # Should not happen if is_loop_done() is checked first, but as a safeguard:\n            self.stop(\"item\")\n            return Data()\n\n    def update_dependency(self):\n        item_dependency_id = self.get_incoming_edge_by_target_param(\"item\")\n        if item_dependency_id and item_dependency_id not in self.graph.run_manager.run_predecessors[self._id]:\n            self.graph.run_manager.run_predecessors[self._id].append(item_dependency_id)\n\n    def done_output(self) -> DataFrame:\n        \"\"\"\n        Once all results are collected, this method performs the final, one-time aggregation.\n        \"\"\"\n        self.initialize_data()\n\n        if self.is_loop_done():\n            self.stop(\"item\")\n            self.start(\"done\")\n\n            original_items = self.ctx.get(f\"{self._id}_data\", [])\n            results = self.ctx.get(f\"{self._id}_loop_inputs\", [])\n\n            final_list = []\n            for i, original_item in enumerate(original_items):\n                merged_item = copy.deepcopy(original_item)\n                if i < len(results):\n                    processed_item = results[i][0] if isinstance(results[i], list) else results[i]\n                    if isinstance(processed_item, Data):\n                        merged_item.data.update(processed_item.data)\n                final_list.append(merged_item)\n\n            return DataFrame(final_list)\n\n        self.stop(\"done\")\n        return DataFrame([])\n"
              },
              "data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "The initial list of Data objects or DataFrame to iterate over.",
                "input_types": [
                  "Data",
                  "DataInput",
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "LoopPlusComponent"
        },
        "dragging": false,
        "id": "LoopPlusComponent-sR9vl",
        "measured": {
          "height": 243,
          "width": 320
        },
        "position": {
          "x": -242.33588715106157,
          "y": 4036.953895106918
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DataToDataFrame-Ia8Sq",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert each field into row in dataframe",
            "display_name": "Data → DataFrame",
            "documentation": "",
            "edited": true,
            "field_order": [
              "data_list"
            ],
            "frozen": false,
            "icon": "table",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "hidden": null,
                "method": "build_dataframe",
                "name": "dataframe",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations",
              "processing.TypeConverterComponent"
            ],
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import DataInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\n\n\nclass DataToDataFrameComponent(Component):\n    display_name = \"Data → DataFrame\"\n    description = (\n        \"Converts one or multiple Data objects into a DataFrame. \"\n        \"Each Data object corresponds to one row. Fields from `.data` become columns, \"\n        \"and the `.text` (if present) is placed in a 'text' column.\"\n    )\n    icon = \"table\"\n    name = \"DataToDataFrame\"\n    legacy = True\n    replacement = [\"processing.DataOperations\", \"processing.TypeConverterComponent\"]\n\n    inputs = [\n        DataInput(\n            name=\"data_list\",\n            display_name=\"Data or Data List\",\n            info=\"One or multiple Data objects to transform into a DataFrame.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"DataFrame\",\n            name=\"dataframe\",\n            method=\"build_dataframe\",\n            info=\"A DataFrame built from each Data object's fields plus a 'text' column.\",\n        ),\n    ]\n\n    def build_dataframe(self) -> DataFrame:\n        \"\"\"Builds a DataFrame from Data objects by combining their fields.\n\n        For each Data object:\n          - Merge item.data (dictionary) as columns\n          - If item.text is present, add 'text' column\n\n        Returns a DataFrame with one row per Data object.\n        \"\"\"\n        data_input = self.data_list\n\n        # If user passed a single Data, it might come in as a single object rather than a list\n        if not isinstance(data_input, list):\n            data_input = [data_input]\n\n        rows = []\n        # raise TypeError(data_input[0].data)\n        # for item in data_input:\n        #     if not isinstance(item, Data):\n        #         msg = f\"Expected Data objects, got {type(item)} instead.\"\n        #         raise TypeError(msg)\n\n        #     # Start with a copy of item.data or an empty dict\n        #     row_dict = dict(item.data) if item.data else {}\n \n\n        #     # If the Data object has text, store it under 'text' col\n        #     text_val = item.get_text()\n        #     if text_val:\n        #         row_dict[\"text\"] = text_val\n\n        #     rows.append(row_dict)\n        \n        for idx, item in data_input[0].data.items():\n            # raise TypeError(type(idx))\n            rows.append({\"key\":idx, \"text\":item})\n            # rows.append({\"key\":idx, \"text\":item})\n                \n        # Build a DataFrame from these row dictionaries\n        df_result = DataFrame(rows)\n        self.status = df_result  # store in self.status for logs\n        return df_result\n"
              },
              "data_list": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data or Data List",
                "dynamic": false,
                "info": "One or multiple Data objects to transform into a DataFrame.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data_list",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "dataframe",
          "showNode": true,
          "type": "DataToDataFrame"
        },
        "dragging": false,
        "id": "DataToDataFrame-Ia8Sq",
        "measured": {
          "height": 247,
          "width": 320
        },
        "position": {
          "x": -2004.7819187017462,
          "y": 4068.4610705869354
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CombineText-X7Dk0",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
            "display_name": "Combine Text",
            "documentation": "",
            "edited": false,
            "field_order": [
              "text1",
              "text2",
              "delimiter"
            ],
            "frozen": false,
            "icon": "merge",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Combined Text",
                "group_outputs": false,
                "method": "combine_texts",
                "name": "combined_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations"
            ],
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n    legacy: bool = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2])\n        self.status = combined\n        return Message(text=combined)\n"
              },
              "delimiter": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Delimiter",
                "dynamic": false,
                "info": "A string used to separate the two text inputs. Defaults to a whitespace.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "delimiter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": " \\n\\n"
              },
              "text1": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "First Text",
                "dynamic": false,
                "info": "The first text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text1",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text2": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Second Text",
                "dynamic": false,
                "info": "The second text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text2",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CombineText"
        },
        "dragging": false,
        "id": "CombineText-X7Dk0",
        "measured": {
          "height": 400,
          "width": 320
        },
        "position": {
          "x": -687.4817184746835,
          "y": -243.0344248386795
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "RAGFlowChatModel-y0w1w",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using RAGFlow.",
            "display_name": "RAGFlow Chat Model",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "ragflow_ca_bundle",
              "ragflow_chat_base_url",
              "ragflow_chat_id",
              "ragflow_chat_api_key",
              "timeout",
              "max_retries",
              "model_name",
              "temperature",
              "max_tokens",
              "json_mode",
              "use_responses_api",
              "model_kwargs"
            ],
            "frozen": false,
            "icon": "SunshineCoder",
            "last_updated": "2025-11-05T08:51:22.702Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import httpx\nimport ssl\n\nfrom typing import Any\nfrom pydantic.v1 import SecretStr\nfrom langchain_openai import ChatOpenAI\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    IntInput,\n    MessageInput,\n    MultilineInput,\n    SecretStrInput,\n    SliderInput,\n    StrInput,\n)\nfrom langflow.components.sunshine_coder.constants import (\n    CA_BUNDLE,\n    RAGFLOW_CHAT_BASE_URL,\n    RAGFLOW_CHAT_MODEL_LIST,\n)\nfrom langflow.logging import logger\nfrom langflow.inputs import MessageTextInput\n\n\nclass RAGFlowChatModelComponent(LCModelComponent):\n    name = \"RAGFlowChatModel\"\n    display_name = \"RAGFlow Chat Model\"\n    description = \"Generates text using RAGFlow.\"\n    icon = \"SunshineCoder\"\n    inputs = [\n        *LCModelComponent._base_inputs,\n        MultilineInput(\n            name=\"ragflow_ca_bundle\",\n            display_name=\"RAGFlow CA Bundle\",\n            info=\"Leave empty unless you're using a self-signed certificate. \"\n            \"Paste the entire certificate including the '-----BEGIN/END CERTIFICATE-----' lines. \"\n            \"Not sure? Just leave it blank!\",\n            value=CA_BUNDLE,\n            advanced=True,\n            dynamic=True,\n        ),\n        StrInput(\n            name=\"ragflow_chat_base_url\",\n            display_name=\"RAGFlow Chat Base URL\",\n            value=RAGFLOW_CHAT_BASE_URL,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"ragflow_chat_id\",\n            display_name=\"RAGFlow Chat Id\",\n            required=True\n        ),\n        MessageTextInput(\n            name=\"ragflow_chat_api_key\",\n            display_name=\"RAGFlow Chat API Key\",\n            required=True\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            value=600,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            value=3,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=RAGFLOW_CHAT_MODEL_LIST,\n            value=RAGFLOW_CHAT_MODEL_LIST[0],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=262144),\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"use_responses_api\",\n            display_name=\"Use Responses API\",\n            info=\"Whether to use the Responses API instead of the Chat API.\",\n            advanced=True,\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            info=\"Additional keyword arguments to pass to the model.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        self.log(f\"Executing request with model: {self.model_name}\")\n        ssl_ctx = None\n        if self.ragflow_ca_bundle:\n            try:\n                ssl_ctx = ssl.create_default_context()\n                ssl_ctx.load_verify_locations(cadata=self.ragflow_ca_bundle)\n            except (ssl.SSLError, ValueError) as e:\n                logger.error(f\"Failed to load CA bundle: {e}\")\n                raise ValueError(f\"Invalid CA bundle: {e}\") from e\n        parameters = {\n            \"base_url\": self.ragflow_chat_base_url + \"/\" + self.ragflow_chat_id,\n            \"api_key\": (\n                SecretStr(self.ragflow_chat_api_key).get_secret_value()\n                if self.ragflow_chat_api_key\n                else None\n            ),\n            \"timeout\": self.timeout,\n            \"max_retries\": self.max_retries,\n            \"model_name\": self.model_name,\n            \"temperature\": self.temperature,\n            \"max_tokens\": self.max_tokens or None,\n            \"use_responses_api\": self.use_responses_api or None,\n            \"model_kwargs\": self.model_kwargs or {},\n        }\n        output = ChatOpenAI(\n            http_client=httpx.Client(verify=ssl_ctx) if self.ragflow_ca_bundle else None,\n            http_async_client=httpx.AsyncClient(verify=ssl_ctx) if self.ragflow_ca_bundle else None,\n            **parameters\n        )\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(\n        self, build_config: dict, field_value: Any, field_name: str | None = None\n    ) -> dict:\n        build_config[\"temperature\"][\"show\"] = True\n        if \"system_message\" in build_config:\n            build_config[\"system_message\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 262144,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "external_options": {},
                "info": "",
                "name": "model_name",
                "options": [
                  "qwen3-coder-30b-a3b",
                  "qwen3-30b-a3b-thinking",
                  "qwen3-vl-30b-a3b-thinking"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "qwen3-30b-a3b-thinking"
              },
              "ragflow_ca_bundle": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "RAGFlow CA Bundle",
                "dynamic": true,
                "info": "Leave empty unless you're using a self-signed certificate. Paste the entire certificate including the '-----BEGIN/END CERTIFICATE-----' lines. Not sure? Just leave it blank!",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "ragflow_ca_bundle",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "-----BEGIN CERTIFICATE-----\nMIIFEzCCAvugAwIBAgIQHNtXzZext4JPNifVibRoXzANBgkqhkiG9w0BAQsFADAc\nMRowGAYDVQQDExFOQ1NEZXZOZXQgUm9vdCBDQTAeFw0yMDA0MDIwNjQ5MjBaFw0z\nNTA0MDIwNjU5MTlaMBwxGjAYBgNVBAMTEU5DU0Rldk5ldCBSb290IENBMIICIjAN\nBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAywoxwa5oCujD63Dg+XR2Lre7Nfd/\nNohA4eG5oTbbC3Ng6h95m6QfnyzzrZYcftW8aqRhakIDQITYp9QXR6fJ9DvHxWO9\n7Jb/8TPER7xHPPwiKocPjCNeWPETiWjpNg9YyAzOAwLWJJRNpLzynvdVsD4el6ZD\n43J2iUlohMhE0qGL56PwNgt8Z4BHcr81Ymm8mgpZyaq0CspnzdUQxhZYPsTBqvnh\nzRktfZlNu6C4u9xrGClKNH1Q1H9L8YUoKFf5Y/ePJtNYviAINqvYyDqiba2SnFSC\n4KELQZpLb2SqfEgWLI4T8mSrbAMV17ybsbWxrFrY34dTYA1vKIVQm2ea9sB73Pat\no0uX7gPyZiAneXRXdtwLTBnDz5+PowzE/jwVxth4ZlHq14nODLvrfpjMxmXUDlhO\nuWfpvNiMkWitK5Q6vrPe04V1v7IwNywRb1AqZciPdznOkP79Mv70lUqNid2goYws\ncIOL3sRcDedMuxEtWKIyfyqC38MqgLpjKEfU4ozxrE2nvf2qPrAf4n8KBRy9KDf2\n7BeUr6mJULofseohMh2n3RIljcP02nMVdOy6p9N93AIQwL996Oe0mOikkYU+rFtM\naLHOeCmw7tbASoVymT+ja1NGoO99S7p1UwehF5//pV1PXUQmO5Z3F6fGWebLV6F2\nArnGzR6CXTkdjcECAwEAAaNRME8wCwYDVR0PBAQDAgGGMA8GA1UdEwEB/wQFMAMB\nAf8wHQYDVR0OBBYEFDpqUad1Arn/92XUwq2uqs1hbYtpMBAGCSsGAQQBgjcVAQQD\nAgEAMA0GCSqGSIb3DQEBCwUAA4ICAQACXcOTV7NeAQdvbAM9DO9ef+peFm1oCzJj\nh66VW8wtXknTDykprciB9JRE2ac5fx9xOfIl/gdzVXuddYoVr9JJdD3mKDij0uqS\nkD1BhNxTpc9tD3U5lPcRcjbSXmKGICM+dGG9IUt8Gs0p/NuzYho0P2jDnar8ZFhL\n/BPAFdVifjUlFLRjEE3gET11pSnyaeF6zYrBY6rQVjm3Hk+q/TioAn3P57WCWzzt\nLx2t8WGB8QxZd/A1aBC7TXkOJTOidJp15/98fImyOpu096u9WfRPyrWDCzeUFBkc\n9WeS52P+qlpQksUnLq1c9XJfqGJZiBvf+XeuCLP9S3LXb0ShKyha0xwf3sIos4Hi\ngj7RP30KZRJXXBV9w4RicI/kzCScZhSkvn8EJ2t7qaVJA6v8QVmIQ18R/9inG0TJ\ntRuw7Yfwc+EAdzDp2e4Fijm6wa8OcKx9FGNDKLR6W2o/iGGOrK+5N4L/ZMxXWXtF\nYsJh6dFmWGMmckM0kRXnfIhvQkLv49+lD2np+MzCVeRxvGdEq2/zYjMljyjaTaqA\nYPPrPKH+VqKGXlXHnMM/9UrYw8gj28BRrKfAYbLL38BSOTbsvYa1QqgTvF7u1PDS\nGcLEjC6llllje/0GAo25einsDGvsyUbvn4/gigLYYvE4a1G6oo1Lg4YwhQw5W/s+\nCKGHxKUDLg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIE0zCCA7ugAwIBAgIJANu+mC2Jt3uTMA0GCSqGSIb3DQEBCwUAMIGhMQswCQYD\nVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTERMA8GA1UEBxMIU2FuIEpvc2Ux\nFTATBgNVBAoTDFpzY2FsZXIgSW5jLjEVMBMGA1UECxMMWnNjYWxlciBJbmMuMRgw\nFgYDVQQDEw9ac2NhbGVyIFJvb3QgQ0ExIjAgBgkqhkiG9w0BCQEWE3N1cHBvcnRA\nenNjYWxlci5jb20wHhcNMTQxMjE5MDAyNzU1WhcNNDIwNTA2MDAyNzU1WjCBoTEL\nMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExETAPBgNVBAcTCFNhbiBK\nb3NlMRUwEwYDVQQKEwxac2NhbGVyIEluYy4xFTATBgNVBAsTDFpzY2FsZXIgSW5j\nLjEYMBYGA1UEAxMPWnNjYWxlciBSb290IENBMSIwIAYJKoZIhvcNAQkBFhNzdXBw\nb3J0QHpzY2FsZXIuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA\nqT7STSxZRTgEFFf6doHajSc1vk5jmzmM6BWuOo044EsaTc9eVEV/HjH/1DWzZtcr\nfTj+ni205apMTlKBW3UYR+lyLHQ9FoZiDXYXK8poKSV5+Tm0Vls/5Kb8mkhVVqv7\nLgYEmvEY7HPY+i1nEGZCa46ZXCOohJ0mBEtB9JVlpDIO+nN0hUMAYYdZ1KZWCMNf\n5J/aTZiShsorN2A38iSOhdd+mcRM4iNL3gsLu99XhKnRqKoHeH83lVdfu1XBeoQz\nz5V6gA3kbRvhDwoIlTBeMa5l4yRdJAfdpkbFzqiwSgNdhbxTHnYYorDzKfr2rEFM\ndsMU0DHdeAZf711+1CunuQIDAQABo4IBCjCCAQYwHQYDVR0OBBYEFLm33UrNww4M\nhp1d3+wcBGnFTpjfMIHWBgNVHSMEgc4wgcuAFLm33UrNww4Mhp1d3+wcBGnFTpjf\noYGnpIGkMIGhMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTERMA8G\nA1UEBxMIU2FuIEpvc2UxFTATBgNVBAoTDFpzY2FsZXIgSW5jLjEVMBMGA1UECxMM\nWnNjYWxlciBJbmMuMRgwFgYDVQQDEw9ac2NhbGVyIFJvb3QgQ0ExIjAgBgkqhkiG\n9w0BCQEWE3N1cHBvcnRAenNjYWxlci5jb22CCQDbvpgtibd7kzAMBgNVHRMEBTAD\nAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQAw0NdJh8w3NsJu4KHuVZUrmZgIohnTm0j+\nRTmYQ9IKA/pvxAcA6K1i/LO+Bt+tCX+C0yxqB8qzuo+4vAzoY5JEBhyhBhf1uK+P\n/WVWFZN/+hTgpSbZgzUEnWQG2gOVd24msex+0Sr7hyr9vn6OueH+jj+vCMiAm5+u\nkd7lLvJsBu3AO3jGWVLyPkS3i6Gf+rwAp1OsRrv3WnbkYcFf9xjuaf4z0hRCrLN2\nxFNjavxrHmsH8jPHVvgc1VD0Opja0l/BRVauTrUaoW6tE+wFG5rEcPGS80jjHK4S\npB5iDj2mUZH1T8lzYtuZy0ZPirxmtsk3135+CKNa2OCAhhFjE0xd\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIESzCCAzOgAwIBAgICAQEwDQYJKoZIhvcNAQELBQAwgaExCzAJBgNVBAYTAlVT\nMRMwEQYDVQQIEwpDYWxpZm9ybmlhMREwDwYDVQQHEwhTYW4gSm9zZTEVMBMGA1UE\nChMMWnNjYWxlciBJbmMuMRUwEwYDVQQLEwxac2NhbGVyIEluYy4xGDAWBgNVBAMT\nD1pzY2FsZXIgUm9vdCBDQTEiMCAGCSqGSIb3DQEJARYTc3VwcG9ydEB6c2NhbGVy\nLmNvbTAeFw0yMDA2MDUwNTMyNDRaFw00MTA2MjMwNTMyNDRaMIGuMQswCQYDVQQG\nEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEVMBMGA1UEChMMWnNjYWxlciBJbmMu\nMRUwEwYDVQQLEwxac2NhbGVyIEluYy4xODA2BgNVBAMTL1pzY2FsZXIgSW50ZXJt\nZWRpYXRlIFJvb3QgQ0EgKHpzY2FsZXJ0aHJlZS5uZXQpMSIwIAYJKoZIhvcNAQkB\nFhNzdXBwb3J0QHpzY2FsZXIuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIB\nCgKCAQEAmioqA+ZMX9KzDDO6VXfPWU4dQ3Knj68Y16L50vd6cAxY6CyBclodGxA1\nmwyIv+Q+kV1oaaoowMGjMDQVyCWFa3w7MaiJdx1x0XgtO1u6nEtA7hRaYnJb+/8J\nLRdXjXQpPNRuis7CE/jfpaUn4zikoBWk3GPQ3ZePX8PdQDtPd47Le5AXNd8rCpFR\nMOJSvZYYrlcEWqMbdBs5sSE3B2UKxQ00Qbj8eQHpvH1/aEa48KsY+9q4ZlB2xzS7\nAklK0NFwuebkhR9JTN59o9rxqVwGJhUbQGpUhMnG+g+4b1qrxRsyOFfludc9UjS5\nofjSsZk5ypGZf5W/npp6Ctz+Qc/gkwIDAQABo34wfDAdBgNVHQ4EFgQUB5R6G+iB\ndfUCJzsePyRCVDjsGdkwDAYDVR0TBAUwAwEB/zALBgNVHQ8EBAMCAf4wQAYDVR0f\nBDkwNzA1oDOgMYYvaHR0cDovL2dhdGV3YXkuenNjYWxlcnRocmVlLm5ldC9jcmwv\nenMzLWludC5jcmwwDQYJKoZIhvcNAQELBQADggEBAD4Jc1RkDa/0ktmwdWqEpTGa\nJuKuN8BY9J7yusclOKKXef8XcAH4Zb/D/9sOWc7PSQKZ0jbGcSmuUjkZZfHnpJ8s\nY3chfEdl4BbVYsg1zF+3b0LrD09+8JHYBYIzE1Rc0/WSQtt/wra1aBijDqZWme3t\n/qB7xTH7VyLg0bz5v178+tcbBWyT4YRydInl5rlOFCWheb9wnF0O4wqh2ZdObagf\nxURV25gYLODsE86fWm/GWSTMytp/Cp1+dVpZVqOx2GbTsxhtM+EmTTptu2ixmLMZ\niPwYIidlYicHBgfhnEv6O2ukM3LeD/IeqdCmhptBKgsWDuxj7t/nUgzaETHuJL4=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\n2dbWAFZtIJCBkzFB\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\nKqClq3gnEytH0g==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\nukxwysXvK5fMqjg0G1UVn2pOsgUKGEBzLOwBiq/4xbUja+Y=\n-----END CERTIFICATE-----\n\n\n-----BEGIN CERTIFICATE-----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\nIMLDPEm0C0fPfnNViYnAIx66tXi6cEvSu3cagXeHa8PpAw6O\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\nKuaoZ8ZJba4dWrcnuYhfAuZwg/Hcr8YbkzwjdAw2jg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIFHTCCAwWgAwIBAgIQGQAgWCt94IRNpVmNTEmCDDANBgkqhkiG9w0BAQsFADAh\nMR8wHQYDVQQDExZOQ1NEZXZOZXQgUHJvZCBSb290IENBMB4XDTI0MTAwNDA5MTQ0\nNFoXDTQ0MTAwNDA5MjQ0M1owITEfMB0GA1UEAxMWTkNTRGV2TmV0IFByb2QgUm9v\ndCBDQTCCAiIwDQYJKoZIhvcNAQEBBQADggIPADCCAgoCggIBAKeglq4tsgEQuy9u\n1SSFVR0YdjRBBrba95BFRNYYHya8zbvJrUTY3aGwftNGKfvj+PZtLmjwKZUdIIQb\nqXi6ysbC6MBKrREwUxT6j9ONcWvm+pV8kgrFS1+gEt7xSX4KzaIJbR7B2MkR91GV\nQ8rJgDUCYZbbmTEoZ3gZWu+ae8xDfyNcAF12KxyXpdCTwiQ3I84EGUoqW0VlbyNU\nuAc2XIAFB9onQX31gCZLShKE9i41czsi2lXjyXegkuuGfkC1nYbQws4ECXkXl397\nK2GdgJ1E8ePoed26qfYGmu6K4RmfnfY98b7j42n1lu+wwx+Edi//Pus/Sdk29YrX\nA5u5NTq4TVKPocpL1MeOhzc2XshHbKS14ZXdY6VcGWIaGsOB2lJ2b2PEyYytKJVc\nTlr2SUnIRr5Yxn7Dttju1myuOHfDu4AXoYswM5D9MGWT3+HWe2onERd6kICmSe0b\nzaAhH12ml9UUX4UMx0Mw6D4ew//xI2uw8pAv0VzU+r9UontVxuoWMek8zpAimxuY\nPT36oCJUOMkiIEg2ihohNY/+nZ6N3g8s53ldqAn1oGL6sv1SA7B729/yGLIngA6l\nUJ7g5QAtEmR8PcJB2hFRGs2o8eQzrpVZgxM89rikLIPRXCqudLajiIna1iY7TMcA\neESBn86We77wj212hn3G4j+k2j7RAgMBAAGjUTBPMAsGA1UdDwQEAwIBhjAPBgNV\nHRMBAf8EBTADAQH/MB0GA1UdDgQWBBSy94Kn5kkkja5ug0M0yltVMweYCTAQBgkr\nBgEEAYI3FQEEAwIBADANBgkqhkiG9w0BAQsFAAOCAgEACGws1+VsSNwRpy2+sAys\nPAnJ0LF+l0MaW3T3g5c2rExwwR4mYgH9EghWnarLNAO28yxhtemovXcmBWsIurK1\nX0wgYqFBMoizjxtjA4SrqDHqkSMWpsF7yGAMhc3x5MFsM2WCGD3mcjJRPTQmcRRL\nGcGmaUdgm2v+q3BwyRsZAiSgSnrjpPjnFuPI+RF9mOxF5mpsR5DFBCzYp2deptvF\nNnRf506h0nJbCUXbDeAxdacKqL5jO/06hO7OW/uYyc51GE1C5+SM1Wfe4e54KQQM\niXJM/2m7YNtHmJSPCvJzpeEKhMkXRwxmQeRNqFzvxyVBNQaqAmFd2Gij+boDfHBJ\n4KlF77+730RVZeIVL8cTBMizTFkAk7DUsDo+99+M5SNQTuxyQvj1WiUed518DjS5\nZ6dGNhZbNx2bgx0hi0a5C19SvtKa1OFRwCgiS0M6PgVnm59uA3FwHrLwlhhzmVTU\nsCxyTWh7lx1GEPOwXf0NdSn6kXs4X3MWoOAlDslo28a8hN50fkON4JaNcCIi0koQ\n+rCOs9M5G4ZNvQVrkBqccOWUewEn3NNeo+Yy5Nx4kmKn0nZ6bICb0ek/GaWcaGQZ\nEepzgY+Efq00LL8qXH4QWg+B/+rL1rBJndoI1JB0fmtUJSD7XGcim2bYEiE/eSaT\njvlvccMaCzx1UZGSJhZNxiQ=\n-----END CERTIFICATE-----\n\n\n-----BEGIN CERTIFICATE-----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\n-----END CERTIFICATE-----\n"
              },
              "ragflow_chat_api_key": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "RAGFlow Chat API Key",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "ragflow_chat_api_key",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "ragflow_chat_base_url": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "RAGFlow Chat Base URL",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "ragflow_chat_base_url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://ragflow:9380/api/v1/chats_openai"
              },
              "ragflow_chat_id": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "RAGFlow Chat Id",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "ragflow_chat_id",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 600
              },
              "use_responses_api": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Use Responses API",
                "dynamic": false,
                "info": "Whether to use the Responses API instead of the Chat API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "use_responses_api",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "selected_output": "model_output",
          "showNode": true,
          "type": "RAGFlowChatModel"
        },
        "dragging": false,
        "id": "RAGFlowChatModel-y0w1w",
        "measured": {
          "height": 797,
          "width": 320
        },
        "position": {
          "x": -1108.7619492405393,
          "y": 969.1380113098874
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-BkcR6",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "Text Input",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextInput",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.00004500241402777085,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "By analyzing above cobol source code, provide the Program Overview, write no less than 300 words in this session. Generate the Program Overview one time only, do not repeat. \n\n## 1. Program Overview\n\n* **Program ID**: `[Extracted from IDENTIFICATION DIVISION]`\n* **Function Description**: A concise summary of the program's main business purpose.\n* **Main Processes **: List out all the processes in the cobol program, by looking into the PROCEDURE DIVISION."
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-BkcR6",
        "measured": {
          "height": 215,
          "width": 320
        },
        "position": {
          "x": -699.6891821807037,
          "y": -503.81857914527535
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CombineText-DkpBV",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
            "display_name": "Combine Text",
            "documentation": "",
            "edited": false,
            "field_order": [
              "text1",
              "text2",
              "delimiter"
            ],
            "frozen": false,
            "icon": "merge",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Combined Text",
                "group_outputs": false,
                "method": "combine_texts",
                "name": "combined_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations"
            ],
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n    legacy: bool = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2])\n        self.status = combined\n        return Message(text=combined)\n"
              },
              "delimiter": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Delimiter",
                "dynamic": false,
                "info": "A string used to separate the two text inputs. Defaults to a whitespace.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "delimiter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": " \\n\\n"
              },
              "text1": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "First Text",
                "dynamic": false,
                "info": "The first text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text1",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text2": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Second Text",
                "dynamic": false,
                "info": "The second text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text2",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CombineText"
        },
        "dragging": false,
        "id": "CombineText-DkpBV",
        "measured": {
          "height": 400,
          "width": 320
        },
        "position": {
          "x": -277.68917782199344,
          "y": -245.81857648047156
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-YwVrd",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "Text Input",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextInput",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.00004500241402777085,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "By analyzing the cobol source code above, provide the Flowchart. Use Mermaid syntax to visualize the main execution flow of `PROCEDURE DIVISION`. \nPlease strictly generate the document in the following Markdown structure:\n\n## 2. Flowchart\n```mermaid\ngraph TD\n    A[Start] --> B[Read Input File];\n    B --> C[End of File?];\n    C -- Yes --> D[Close Files];\n    C -- No --> E[Process Record];\n    E --> F[Write to Output File];\n    F --> B;\n    D --> G[End];\n```\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-YwVrd",
        "measured": {
          "height": 215,
          "width": 320
        },
        "position": {
          "x": -291.68917796659525,
          "y": -507.8185791865902
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CombineText-Qi7eN",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
            "display_name": "Combine Text",
            "documentation": "",
            "edited": false,
            "field_order": [
              "text1",
              "text2",
              "delimiter"
            ],
            "frozen": false,
            "icon": "merge",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Combined Text",
                "group_outputs": false,
                "method": "combine_texts",
                "name": "combined_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations"
            ],
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n    legacy: bool = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2])\n        self.status = combined\n        return Message(text=combined)\n"
              },
              "delimiter": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Delimiter",
                "dynamic": false,
                "info": "A string used to separate the two text inputs. Defaults to a whitespace.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "delimiter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": " \\n\\n"
              },
              "text1": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "First Text",
                "dynamic": false,
                "info": "The first text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text1",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text2": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Second Text",
                "dynamic": false,
                "info": "The second text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text2",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CombineText"
        },
        "dragging": false,
        "id": "CombineText-Qi7eN",
        "measured": {
          "height": 400,
          "width": 320
        },
        "position": {
          "x": 169.49937076733062,
          "y": -240.25029194567907
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-ePwtA",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "Text Input",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextInput",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.00004500241402777085,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "By analyzing the cobol source code above, provide the Input/Output of the code in below md format\n\n## 3. Input/Output\n* **Input**:\n    * `[Input File Name 1]`: [Briefly describe the purpose and key fields of this file].\n    * `[Input File Name 2]`: ...\n\t...\n* **Output**:\n    * `[Output File Name 1]`: [Briefly describe the purpose and generation method of this file].\n    * `[Output File Name 2]`: ...\n\t...\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-ePwtA",
        "measured": {
          "height": 215,
          "width": 320
        },
        "position": {
          "x": 170.9050987966255,
          "y": -512.4128512192674
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TransposeDataFrame-5XW4u",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Transpose a LangFlow DataFrame using DataFrame API.",
            "display_name": "Transpose DataFrame",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_df"
            ],
            "frozen": false,
            "icon": "table",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Transposed DataFrame",
                "group_outputs": false,
                "hidden": null,
                "method": "transpose_dataframe",
                "name": "transposed_df",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\r\nfrom langflow.io import DataInput, Output\r\nfrom langflow.schema.dataframe import DataFrame\r\nimport pandas as pd\r\n\r\n\r\nclass TransposeDataFrameComponent(Component):\r\n    display_name = \"Transpose DataFrame\"\r\n    description = \"Transpose a LangFlow DataFrame using DataFrame API.\"\r\n    icon = \"table\"\r\n    name = \"TransposeDataFrame\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"input_df\", display_name=\"Input DataFrame\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(name=\"transposed_df\", display_name=\"Transposed DataFrame\", method=\"transpose_dataframe\"),\r\n    ]\r\n\r\n    def transpose_dataframe(self) -> DataFrame:\r\n        # Get the input DataFrame object (LangFlow DataFrame instance)\r\n        input_df = self.input_df\r\n\r\n        if not isinstance(input_df, DataFrame):\r\n            raise TypeError(f\"Expected DataFrame, got {type(input_df)}\")\r\n\r\n        # Convert LangFlow DataFrame to pandas DataFrame\r\n        pandas_df = input_df.to_pandas()\r\n\r\n        # Transpose with pandas\r\n        transposed = pandas_df.transpose()\r\n\r\n        # Convert back to LangFlow DataFrame\r\n        transposed_df = DataFrame.from_pandas(transposed)\r\n\r\n        self.status = transposed_df\r\n        return transposed_df\r\n"
              },
              "input_df": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Input DataFrame",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_df",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TransposeDataFrame"
        },
        "dragging": false,
        "id": "TransposeDataFrame-5XW4u",
        "measured": {
          "height": 183,
          "width": 320
        },
        "position": {
          "x": 3902.389463653372,
          "y": 3183.5894800659557
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CombineText-GULRk",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
            "display_name": "Combine Text",
            "documentation": "",
            "edited": true,
            "field_order": [
              "text1",
              "text2",
              "text3",
              "text4",
              "text5",
              "text6",
              "delimiter"
            ],
            "frozen": false,
            "icon": "merge",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Combined Text",
                "group_outputs": false,
                "hidden": null,
                "method": "combine_texts",
                "name": "combined_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations"
            ],
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n    legacy: bool = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text3\",\n            display_name=\"Third Text\",\n            info=\"The third text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text4\",\n            display_name=\"4th Text\",\n            info=\"The 4th text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text5\",\n            display_name=\"5th Text\",\n            info=\"The 5th text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text6\",\n            display_name=\"6th Text\",\n            info=\"The 6th text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2, self.text3, self.text4, self.text5, self.text6])\n        self.status = combined\n        return Message(text=combined)\n"
              },
              "delimiter": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Delimiter",
                "dynamic": false,
                "info": "A string used to separate the two text inputs. Defaults to a whitespace.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "delimiter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": " \\n\\n"
              },
              "text1": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "First Text",
                "dynamic": false,
                "info": "The first text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text1",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text2": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Second Text",
                "dynamic": false,
                "info": "The second text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text2",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text3": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Third Text",
                "dynamic": false,
                "info": "The third text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text3",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text4": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "4th Text",
                "dynamic": false,
                "info": "The 4th text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text4",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text5": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "5th Text",
                "dynamic": false,
                "info": "The 5th text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text5",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text6": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "6th Text",
                "dynamic": false,
                "info": "The 6th text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text6",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CombineText"
        },
        "dragging": false,
        "id": "CombineText-GULRk",
        "measured": {
          "height": 803,
          "width": 320
        },
        "position": {
          "x": 2813.5524905605175,
          "y": 4271.743277256761
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Memory-Y2uuC",
          "node": {
            "base_classes": [
              "DataFrame",
              "Message"
            ],
            "beta": false,
            "category": "helpers",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Stores or retrieves stored chat messages from Langflow tables or an external memory.",
            "display_name": "Message History",
            "documentation": "https://docs.langflow.org/components-helpers#message-history",
            "edited": false,
            "field_order": [
              "mode",
              "message",
              "memory",
              "sender_type",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "frozen": false,
            "icon": "message-square-more",
            "key": "Memory",
            "last_updated": "2025-10-22T03:58:35.802Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Messages",
                "group_outputs": false,
                "hidden": null,
                "method": "retrieve_messages_as_text",
                "name": "messages_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Dataframe",
                "group_outputs": false,
                "hidden": null,
                "method": "retrieve_messages_dataframe",
                "name": "dataframe",
                "options": null,
                "required_inputs": null,
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.1676812955549333,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any, cast\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.inputs.inputs import DropdownInput, HandleInput, IntInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.memory import aget_messages, astore_message\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\nfrom langflow.utils.component_utils import set_current_fields, set_field_display\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Message History\"\n    description = \"Stores or retrieves stored chat messages from Langflow tables or an external memory.\"\n    documentation: str = \"https://docs.langflow.org/components-helpers#message-history\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n    default_keys = [\"mode\", \"memory\", \"session_id\"]\n    mode_config = {\n        \"Store\": [\"message\", \"memory\", \"sender\", \"sender_name\", \"session_id\"],\n        \"Retrieve\": [\"n_messages\", \"order\", \"template\", \"memory\", \"session_id\"],\n    }\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Retrieve\", \"Store\"],\n            value=\"Retrieve\",\n            info=\"Operation mode: Store messages or Retrieve messages.\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The chat message to be stored.\",\n            tool_mode=True,\n            dynamic=True,\n            show=False,\n        ),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"Memory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender_type\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender\",\n            display_name=\"Sender\",\n            info=\"The sender of the message. Might be Machine or User. \"\n            \"If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            value=\"\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n            tool_mode=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Message\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True),\n        Output(display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True),\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"mode\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n            if field_value == \"Store\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Stored Messages\",\n                        name=\"stored_messages\",\n                        method=\"store_message\",\n                        hidden=True,\n                        dynamic=True,\n                    )\n                ]\n            if field_value == \"Retrieve\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Messages\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True\n                    ),\n                    Output(\n                        display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True\n                    ),\n                ]\n        return frontend_node\n\n    async def store_message(self) -> Message:\n        message = Message(text=self.message) if isinstance(self.message, str) else self.message\n\n        message.session_id = self.session_id or message.session_id\n        message.sender = self.sender or message.sender or MESSAGE_SENDER_AI\n        message.sender_name = self.sender_name or message.sender_name or MESSAGE_SENDER_NAME_AI\n\n        stored_messages: list[Message] = []\n\n        if self.memory:\n            self.memory.session_id = message.session_id\n            lc_message = message.to_lc_message()\n            await self.memory.aadd_messages([lc_message])\n\n            stored_messages = await self.memory.aget_messages() or []\n\n            stored_messages = [Message.from_lc_message(m) for m in stored_messages] if stored_messages else []\n\n            if message.sender:\n                stored_messages = [m for m in stored_messages if m.sender == message.sender]\n        else:\n            await astore_message(message, flow_id=self.graph.flow_id)\n            stored_messages = (\n                await aget_messages(\n                    session_id=message.session_id, sender_name=message.sender_name, sender=message.sender\n                )\n                or []\n            )\n\n        if not stored_messages:\n            msg = \"No messages were stored. Please ensure that the session ID and sender are properly set.\"\n            raise ValueError(msg)\n\n        stored_message = stored_messages[0]\n        self.status = stored_message\n        return stored_message\n\n    async def retrieve_messages(self) -> Data:\n        sender_type = self.sender_type\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender_type == \"Machine and User\":\n            sender_type = None\n\n        if self.memory and not hasattr(self.memory, \"aget_messages\"):\n            memory_name = type(self.memory).__name__\n            err_msg = f\"External Memory object ({memory_name}) must have 'aget_messages' method.\"\n            raise AttributeError(err_msg)\n        # Check if n_messages is None or 0\n        if n_messages == 0:\n            stored = []\n        elif self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = await self.memory.aget_messages()\n            # langchain memories are supposed to return messages in ascending order\n\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages first\n\n            if order == \"DESC\":\n                stored = stored[::-1]  # Then reverse if needed\n\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender_type:\n                expected_type = MESSAGE_SENDER_AI if sender_type == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            # For internal memory, we always fetch the last N messages by ordering by DESC\n            stored = await aget_messages(\n                sender=sender_type,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=10000,\n                order=order,\n            )\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages\n\n        # self.status = stored\n        return cast(\"Data\", stored)\n\n    async def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, await self.retrieve_messages())\n        # self.status = stored_text\n        return Message(text=stored_text)\n\n    async def retrieve_messages_dataframe(self) -> DataFrame:\n        \"\"\"Convert the retrieved messages into a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the message data.\n        \"\"\"\n        messages = await self.retrieve_messages()\n        return DataFrame(messages)\n\n    def update_build_config(\n        self,\n        build_config: dotdict,\n        field_value: Any,  # noqa: ARG002\n        field_name: str | None = None,  # noqa: ARG002\n    ) -> dotdict:\n        return set_current_fields(\n            build_config=build_config,\n            action_fields=self.mode_config,\n            selected_action=build_config[\"mode\"][\"value\"],\n            default_fields=self.default_keys,\n            func=set_field_display,\n        )\n"
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "message": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": true,
                "info": "The chat message to be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": " "
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Operation mode: Store messages or Retrieve messages.",
                "name": "mode",
                "options": [
                  "Retrieve",
                  "Store"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Retrieve"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 6
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "external_options": {},
                "info": "Order of the messages.",
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Sender",
                "dynamic": false,
                "info": "The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender_type": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Filter by sender type.",
                "name": "sender_type",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              }
            },
            "tool_mode": false
          },
          "selected_output": "messages_text",
          "showNode": true,
          "type": "Memory"
        },
        "dragging": false,
        "id": "Memory-Y2uuC",
        "measured": {
          "height": 692,
          "width": 320
        },
        "position": {
          "x": -2763.2592638815713,
          "y": 698.5678026410861
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "BatchRunComponent-diRMN",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.",
            "display_name": "Batch Run",
            "documentation": "https://docs.langflow.org/components-processing#batch-run",
            "edited": false,
            "field_order": [
              "model",
              "system_message",
              "df",
              "column_name",
              "output_column_name",
              "enable_metadata"
            ],
            "frozen": false,
            "icon": "List",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "LLM Results",
                "group_outputs": false,
                "hidden": null,
                "method": "run_batch",
                "name": "batch_results",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, cast\n\nimport toml  # type: ignore[import-untyped]\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DataFrameInput, HandleInput, MessageTextInput, MultilineInput, Output\nfrom langflow.logging.logger import logger\nfrom langflow.schema.dataframe import DataFrame\n\nif TYPE_CHECKING:\n    from langchain_core.runnables import Runnable\n\n\nclass BatchRunComponent(Component):\n    display_name = \"Batch Run\"\n    description = \"Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#batch-run\"\n    icon = \"List\"\n\n    inputs = [\n        HandleInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Connect the 'Language Model' output from your LLM component here.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"Instructions\",\n            info=\"Multi-line system instruction for all rows in the DataFrame.\",\n            required=False,\n        ),\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The DataFrame whose column (specified by 'column_name') we'll treat as text messages.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=(\n                \"The name of the DataFrame column to treat as text messages. \"\n                \"If empty, all columns will be formatted in TOML.\"\n            ),\n            required=False,\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"output_column_name\",\n            display_name=\"Output Column Name\",\n            info=\"Name of the column where the model's response will be stored.\",\n            value=\"model_response\",\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_metadata\",\n            display_name=\"Enable Metadata\",\n            info=\"If True, add metadata to the output DataFrame.\",\n            value=False,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"LLM Results\",\n            name=\"batch_results\",\n            method=\"run_batch\",\n            info=\"A DataFrame with all original columns plus the model's response column.\",\n        ),\n    ]\n\n    def _format_row_as_toml(self, row: dict[str, Any]) -> str:\n        \"\"\"Convert a dictionary (row) into a TOML-formatted string.\"\"\"\n        formatted_dict = {str(col): {\"value\": str(val)} for col, val in row.items()}\n        return toml.dumps(formatted_dict)\n\n    def _create_base_row(\n        self, original_row: dict[str, Any], model_response: str = \"\", batch_index: int = -1\n    ) -> dict[str, Any]:\n        \"\"\"Create a base row with original columns and additional metadata.\"\"\"\n        row = original_row.copy()\n        row[self.output_column_name] = model_response\n        row[\"batch_index\"] = batch_index\n        return row\n\n    def _add_metadata(\n        self, row: dict[str, Any], *, success: bool = True, system_msg: str = \"\", error: str | None = None\n    ) -> None:\n        \"\"\"Add metadata to a row if enabled.\"\"\"\n        if not self.enable_metadata:\n            return\n\n        if success:\n            row[\"metadata\"] = {\n                \"has_system_message\": bool(system_msg),\n                \"input_length\": len(row.get(\"text_input\", \"\")),\n                \"response_length\": len(row[self.output_column_name]),\n                \"processing_status\": \"success\",\n            }\n        else:\n            row[\"metadata\"] = {\n                \"error\": error,\n                \"processing_status\": \"failed\",\n            }\n\n    async def run_batch(self) -> DataFrame:\n        \"\"\"Process each row in df[column_name] with the language model asynchronously.\n\n        Returns:\n            DataFrame: A new DataFrame containing:\n                - All original columns\n                - The model's response column (customizable name)\n                - 'batch_index' column for processing order\n                - 'metadata' (optional)\n\n        Raises:\n            ValueError: If the specified column is not found in the DataFrame\n            TypeError: If the model is not compatible or input types are wrong\n        \"\"\"\n        model: Runnable = self.model\n        system_msg = self.system_message or \"\"\n        df: DataFrame = self.df\n        col_name = self.column_name or \"\"\n\n        # Validate inputs first\n        if not isinstance(df, DataFrame):\n            msg = f\"Expected DataFrame input, got {type(df)}\"\n            raise TypeError(msg)\n\n        if col_name and col_name not in df.columns:\n            msg = f\"Column '{col_name}' not found in the DataFrame. Available columns: {', '.join(df.columns)}\"\n            raise ValueError(msg)\n\n        try:\n            # Determine text input for each row\n            if col_name:\n                user_texts = df[col_name].astype(str).tolist()\n            else:\n                user_texts = [\n                    self._format_row_as_toml(cast(\"dict[str, Any]\", row)) for row in df.to_dict(orient=\"records\")\n                ]\n\n            total_rows = len(user_texts)\n            await logger.ainfo(f\"Processing {total_rows} rows with batch run\")\n\n            # Prepare the batch of conversations\n            conversations = [\n                [{\"role\": \"system\", \"content\": system_msg}, {\"role\": \"user\", \"content\": text}]\n                if system_msg\n                else [{\"role\": \"user\", \"content\": text}]\n                for text in user_texts\n            ]\n\n            # Configure the model with project info and callbacks\n            model = model.with_config(\n                {\n                    \"run_name\": self.display_name,\n                    \"project_name\": self.get_project_name(),\n                    \"callbacks\": self.get_langchain_callbacks(),\n                }\n            )\n            # Process batches and track progress\n            responses_with_idx = list(\n                zip(\n                    range(len(conversations)),\n                    await model.abatch(list(conversations)),\n                    strict=True,\n                )\n            )\n\n            # Sort by index to maintain order\n            responses_with_idx.sort(key=lambda x: x[0])\n\n            # Build the final data with enhanced metadata\n            rows: list[dict[str, Any]] = []\n            for idx, (original_row, response) in enumerate(\n                zip(df.to_dict(orient=\"records\"), responses_with_idx, strict=False)\n            ):\n                response_text = response[1].content if hasattr(response[1], \"content\") else str(response[1])\n                row = self._create_base_row(\n                    cast(\"dict[str, Any]\", original_row), model_response=response_text, batch_index=idx\n                )\n                self._add_metadata(row, success=True, system_msg=system_msg)\n                rows.append(row)\n\n                # Log progress\n                if (idx + 1) % max(1, total_rows // 10) == 0:\n                    await logger.ainfo(f\"Processed {idx + 1}/{total_rows} rows\")\n\n            await logger.ainfo(\"Batch processing completed successfully\")\n            return DataFrame(rows)\n\n        except (KeyError, AttributeError) as e:\n            # Handle data structure and attribute access errors\n            await logger.aerror(f\"Data processing error: {e!s}\")\n            error_row = self._create_base_row(dict.fromkeys(df.columns, \"\"), model_response=\"\", batch_index=-1)\n            self._add_metadata(error_row, success=False, error=str(e))\n            return DataFrame([error_row])\n"
              },
              "column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": false,
                "info": "The name of the DataFrame column to treat as text messages. If empty, all columns will be formatted in TOML.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Query1"
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The DataFrame whose column (specified by 'column_name') we'll treat as text messages.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "enable_metadata": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Enable Metadata",
                "dynamic": false,
                "info": "If True, add metadata to the output DataFrame.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "enable_metadata",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Connect the 'Language Model' output from your LLM component here.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "model",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Output Column Name",
                "dynamic": false,
                "info": "Name of the column where the model's response will be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "model_response_1"
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Instructions",
                "dynamic": false,
                "info": "Multi-line system instruction for all rows in the DataFrame.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "BatchRunComponent"
        },
        "dragging": false,
        "id": "BatchRunComponent-diRMN",
        "measured": {
          "height": 488,
          "width": 320
        },
        "position": {
          "x": -639.4441668038548,
          "y": 1765.7453341117696
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "BatchRunComponent-cXI9j",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.",
            "display_name": "Batch Run",
            "documentation": "https://docs.langflow.org/components-processing#batch-run",
            "edited": false,
            "field_order": [
              "model",
              "system_message",
              "df",
              "column_name",
              "output_column_name",
              "enable_metadata"
            ],
            "frozen": false,
            "icon": "List",
            "key": "BatchRunComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "LLM Results",
                "group_outputs": false,
                "method": "run_batch",
                "name": "batch_results",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, cast\n\nimport toml  # type: ignore[import-untyped]\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DataFrameInput, HandleInput, MessageTextInput, MultilineInput, Output\nfrom langflow.logging.logger import logger\nfrom langflow.schema.dataframe import DataFrame\n\nif TYPE_CHECKING:\n    from langchain_core.runnables import Runnable\n\n\nclass BatchRunComponent(Component):\n    display_name = \"Batch Run\"\n    description = \"Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#batch-run\"\n    icon = \"List\"\n\n    inputs = [\n        HandleInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Connect the 'Language Model' output from your LLM component here.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"Instructions\",\n            info=\"Multi-line system instruction for all rows in the DataFrame.\",\n            required=False,\n        ),\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The DataFrame whose column (specified by 'column_name') we'll treat as text messages.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=(\n                \"The name of the DataFrame column to treat as text messages. \"\n                \"If empty, all columns will be formatted in TOML.\"\n            ),\n            required=False,\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"output_column_name\",\n            display_name=\"Output Column Name\",\n            info=\"Name of the column where the model's response will be stored.\",\n            value=\"model_response\",\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_metadata\",\n            display_name=\"Enable Metadata\",\n            info=\"If True, add metadata to the output DataFrame.\",\n            value=False,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"LLM Results\",\n            name=\"batch_results\",\n            method=\"run_batch\",\n            info=\"A DataFrame with all original columns plus the model's response column.\",\n        ),\n    ]\n\n    def _format_row_as_toml(self, row: dict[str, Any]) -> str:\n        \"\"\"Convert a dictionary (row) into a TOML-formatted string.\"\"\"\n        formatted_dict = {str(col): {\"value\": str(val)} for col, val in row.items()}\n        return toml.dumps(formatted_dict)\n\n    def _create_base_row(\n        self, original_row: dict[str, Any], model_response: str = \"\", batch_index: int = -1\n    ) -> dict[str, Any]:\n        \"\"\"Create a base row with original columns and additional metadata.\"\"\"\n        row = original_row.copy()\n        row[self.output_column_name] = model_response\n        row[\"batch_index\"] = batch_index\n        return row\n\n    def _add_metadata(\n        self, row: dict[str, Any], *, success: bool = True, system_msg: str = \"\", error: str | None = None\n    ) -> None:\n        \"\"\"Add metadata to a row if enabled.\"\"\"\n        if not self.enable_metadata:\n            return\n\n        if success:\n            row[\"metadata\"] = {\n                \"has_system_message\": bool(system_msg),\n                \"input_length\": len(row.get(\"text_input\", \"\")),\n                \"response_length\": len(row[self.output_column_name]),\n                \"processing_status\": \"success\",\n            }\n        else:\n            row[\"metadata\"] = {\n                \"error\": error,\n                \"processing_status\": \"failed\",\n            }\n\n    async def run_batch(self) -> DataFrame:\n        \"\"\"Process each row in df[column_name] with the language model asynchronously.\n\n        Returns:\n            DataFrame: A new DataFrame containing:\n                - All original columns\n                - The model's response column (customizable name)\n                - 'batch_index' column for processing order\n                - 'metadata' (optional)\n\n        Raises:\n            ValueError: If the specified column is not found in the DataFrame\n            TypeError: If the model is not compatible or input types are wrong\n        \"\"\"\n        model: Runnable = self.model\n        system_msg = self.system_message or \"\"\n        df: DataFrame = self.df\n        col_name = self.column_name or \"\"\n\n        # Validate inputs first\n        if not isinstance(df, DataFrame):\n            msg = f\"Expected DataFrame input, got {type(df)}\"\n            raise TypeError(msg)\n\n        if col_name and col_name not in df.columns:\n            msg = f\"Column '{col_name}' not found in the DataFrame. Available columns: {', '.join(df.columns)}\"\n            raise ValueError(msg)\n\n        try:\n            # Determine text input for each row\n            if col_name:\n                user_texts = df[col_name].astype(str).tolist()\n            else:\n                user_texts = [\n                    self._format_row_as_toml(cast(\"dict[str, Any]\", row)) for row in df.to_dict(orient=\"records\")\n                ]\n\n            total_rows = len(user_texts)\n            await logger.ainfo(f\"Processing {total_rows} rows with batch run\")\n\n            # Prepare the batch of conversations\n            conversations = [\n                [{\"role\": \"system\", \"content\": system_msg}, {\"role\": \"user\", \"content\": text}]\n                if system_msg\n                else [{\"role\": \"user\", \"content\": text}]\n                for text in user_texts\n            ]\n\n            # Configure the model with project info and callbacks\n            model = model.with_config(\n                {\n                    \"run_name\": self.display_name,\n                    \"project_name\": self.get_project_name(),\n                    \"callbacks\": self.get_langchain_callbacks(),\n                }\n            )\n            # Process batches and track progress\n            responses_with_idx = list(\n                zip(\n                    range(len(conversations)),\n                    await model.abatch(list(conversations)),\n                    strict=True,\n                )\n            )\n\n            # Sort by index to maintain order\n            responses_with_idx.sort(key=lambda x: x[0])\n\n            # Build the final data with enhanced metadata\n            rows: list[dict[str, Any]] = []\n            for idx, (original_row, response) in enumerate(\n                zip(df.to_dict(orient=\"records\"), responses_with_idx, strict=False)\n            ):\n                response_text = response[1].content if hasattr(response[1], \"content\") else str(response[1])\n                row = self._create_base_row(\n                    cast(\"dict[str, Any]\", original_row), model_response=response_text, batch_index=idx\n                )\n                self._add_metadata(row, success=True, system_msg=system_msg)\n                rows.append(row)\n\n                # Log progress\n                if (idx + 1) % max(1, total_rows // 10) == 0:\n                    await logger.ainfo(f\"Processed {idx + 1}/{total_rows} rows\")\n\n            await logger.ainfo(\"Batch processing completed successfully\")\n            return DataFrame(rows)\n\n        except (KeyError, AttributeError) as e:\n            # Handle data structure and attribute access errors\n            await logger.aerror(f\"Data processing error: {e!s}\")\n            error_row = self._create_base_row(dict.fromkeys(df.columns, \"\"), model_response=\"\", batch_index=-1)\n            self._add_metadata(error_row, success=False, error=str(e))\n            return DataFrame([error_row])\n"
              },
              "column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": false,
                "info": "The name of the DataFrame column to treat as text messages. If empty, all columns will be formatted in TOML.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Query2"
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The DataFrame whose column (specified by 'column_name') we'll treat as text messages.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "enable_metadata": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Enable Metadata",
                "dynamic": false,
                "info": "If True, add metadata to the output DataFrame.",
                "list": false,
                "list_add_label": "Add More",
                "name": "enable_metadata",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Connect the 'Language Model' output from your LLM component here.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "model",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Output Column Name",
                "dynamic": false,
                "info": "Name of the column where the model's response will be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "model_response_2"
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Instructions",
                "dynamic": false,
                "info": "Multi-line system instruction for all rows in the DataFrame.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "BatchRunComponent"
        },
        "dragging": false,
        "id": "BatchRunComponent-cXI9j",
        "measured": {
          "height": 488,
          "width": 320
        },
        "position": {
          "x": -243.15248251334347,
          "y": 1771.08626545292
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-kOe2b",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "hidden": null,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response_1}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-kOe2b",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 2195.5752199232074,
          "y": 3506.882278763237
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-4CD6T",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response_2}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-4CD6T",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 2203.186603478764,
          "y": 3899.872031962892
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "BatchRunComponent-8dWWo",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.",
            "display_name": "Batch Run",
            "documentation": "https://docs.langflow.org/components-processing#batch-run",
            "edited": false,
            "field_order": [
              "model",
              "system_message",
              "df",
              "column_name",
              "output_column_name",
              "enable_metadata"
            ],
            "frozen": false,
            "icon": "List",
            "key": "BatchRunComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "LLM Results",
                "group_outputs": false,
                "method": "run_batch",
                "name": "batch_results",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, cast\n\nimport toml  # type: ignore[import-untyped]\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DataFrameInput, HandleInput, MessageTextInput, MultilineInput, Output\nfrom langflow.logging.logger import logger\nfrom langflow.schema.dataframe import DataFrame\n\nif TYPE_CHECKING:\n    from langchain_core.runnables import Runnable\n\n\nclass BatchRunComponent(Component):\n    display_name = \"Batch Run\"\n    description = \"Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#batch-run\"\n    icon = \"List\"\n\n    inputs = [\n        HandleInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Connect the 'Language Model' output from your LLM component here.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"Instructions\",\n            info=\"Multi-line system instruction for all rows in the DataFrame.\",\n            required=False,\n        ),\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The DataFrame whose column (specified by 'column_name') we'll treat as text messages.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=(\n                \"The name of the DataFrame column to treat as text messages. \"\n                \"If empty, all columns will be formatted in TOML.\"\n            ),\n            required=False,\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"output_column_name\",\n            display_name=\"Output Column Name\",\n            info=\"Name of the column where the model's response will be stored.\",\n            value=\"model_response\",\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_metadata\",\n            display_name=\"Enable Metadata\",\n            info=\"If True, add metadata to the output DataFrame.\",\n            value=False,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"LLM Results\",\n            name=\"batch_results\",\n            method=\"run_batch\",\n            info=\"A DataFrame with all original columns plus the model's response column.\",\n        ),\n    ]\n\n    def _format_row_as_toml(self, row: dict[str, Any]) -> str:\n        \"\"\"Convert a dictionary (row) into a TOML-formatted string.\"\"\"\n        formatted_dict = {str(col): {\"value\": str(val)} for col, val in row.items()}\n        return toml.dumps(formatted_dict)\n\n    def _create_base_row(\n        self, original_row: dict[str, Any], model_response: str = \"\", batch_index: int = -1\n    ) -> dict[str, Any]:\n        \"\"\"Create a base row with original columns and additional metadata.\"\"\"\n        row = original_row.copy()\n        row[self.output_column_name] = model_response\n        row[\"batch_index\"] = batch_index\n        return row\n\n    def _add_metadata(\n        self, row: dict[str, Any], *, success: bool = True, system_msg: str = \"\", error: str | None = None\n    ) -> None:\n        \"\"\"Add metadata to a row if enabled.\"\"\"\n        if not self.enable_metadata:\n            return\n\n        if success:\n            row[\"metadata\"] = {\n                \"has_system_message\": bool(system_msg),\n                \"input_length\": len(row.get(\"text_input\", \"\")),\n                \"response_length\": len(row[self.output_column_name]),\n                \"processing_status\": \"success\",\n            }\n        else:\n            row[\"metadata\"] = {\n                \"error\": error,\n                \"processing_status\": \"failed\",\n            }\n\n    async def run_batch(self) -> DataFrame:\n        \"\"\"Process each row in df[column_name] with the language model asynchronously.\n\n        Returns:\n            DataFrame: A new DataFrame containing:\n                - All original columns\n                - The model's response column (customizable name)\n                - 'batch_index' column for processing order\n                - 'metadata' (optional)\n\n        Raises:\n            ValueError: If the specified column is not found in the DataFrame\n            TypeError: If the model is not compatible or input types are wrong\n        \"\"\"\n        model: Runnable = self.model\n        system_msg = self.system_message or \"\"\n        df: DataFrame = self.df\n        col_name = self.column_name or \"\"\n\n        # Validate inputs first\n        if not isinstance(df, DataFrame):\n            msg = f\"Expected DataFrame input, got {type(df)}\"\n            raise TypeError(msg)\n\n        if col_name and col_name not in df.columns:\n            msg = f\"Column '{col_name}' not found in the DataFrame. Available columns: {', '.join(df.columns)}\"\n            raise ValueError(msg)\n\n        try:\n            # Determine text input for each row\n            if col_name:\n                user_texts = df[col_name].astype(str).tolist()\n            else:\n                user_texts = [\n                    self._format_row_as_toml(cast(\"dict[str, Any]\", row)) for row in df.to_dict(orient=\"records\")\n                ]\n\n            total_rows = len(user_texts)\n            await logger.ainfo(f\"Processing {total_rows} rows with batch run\")\n\n            # Prepare the batch of conversations\n            conversations = [\n                [{\"role\": \"system\", \"content\": system_msg}, {\"role\": \"user\", \"content\": text}]\n                if system_msg\n                else [{\"role\": \"user\", \"content\": text}]\n                for text in user_texts\n            ]\n\n            # Configure the model with project info and callbacks\n            model = model.with_config(\n                {\n                    \"run_name\": self.display_name,\n                    \"project_name\": self.get_project_name(),\n                    \"callbacks\": self.get_langchain_callbacks(),\n                }\n            )\n            # Process batches and track progress\n            responses_with_idx = list(\n                zip(\n                    range(len(conversations)),\n                    await model.abatch(list(conversations)),\n                    strict=True,\n                )\n            )\n\n            # Sort by index to maintain order\n            responses_with_idx.sort(key=lambda x: x[0])\n\n            # Build the final data with enhanced metadata\n            rows: list[dict[str, Any]] = []\n            for idx, (original_row, response) in enumerate(\n                zip(df.to_dict(orient=\"records\"), responses_with_idx, strict=False)\n            ):\n                response_text = response[1].content if hasattr(response[1], \"content\") else str(response[1])\n                row = self._create_base_row(\n                    cast(\"dict[str, Any]\", original_row), model_response=response_text, batch_index=idx\n                )\n                self._add_metadata(row, success=True, system_msg=system_msg)\n                rows.append(row)\n\n                # Log progress\n                if (idx + 1) % max(1, total_rows // 10) == 0:\n                    await logger.ainfo(f\"Processed {idx + 1}/{total_rows} rows\")\n\n            await logger.ainfo(\"Batch processing completed successfully\")\n            return DataFrame(rows)\n\n        except (KeyError, AttributeError) as e:\n            # Handle data structure and attribute access errors\n            await logger.aerror(f\"Data processing error: {e!s}\")\n            error_row = self._create_base_row(dict.fromkeys(df.columns, \"\"), model_response=\"\", batch_index=-1)\n            self._add_metadata(error_row, success=False, error=str(e))\n            return DataFrame([error_row])\n"
              },
              "column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": false,
                "info": "The name of the DataFrame column to treat as text messages. If empty, all columns will be formatted in TOML.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Query3"
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The DataFrame whose column (specified by 'column_name') we'll treat as text messages.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "enable_metadata": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Enable Metadata",
                "dynamic": false,
                "info": "If True, add metadata to the output DataFrame.",
                "list": false,
                "list_add_label": "Add More",
                "name": "enable_metadata",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Connect the 'Language Model' output from your LLM component here.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "model",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Output Column Name",
                "dynamic": false,
                "info": "Name of the column where the model's response will be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "model_response_3"
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Instructions",
                "dynamic": false,
                "info": "Multi-line system instruction for all rows in the DataFrame.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "BatchRunComponent"
        },
        "dragging": false,
        "id": "BatchRunComponent-8dWWo",
        "measured": {
          "height": 488,
          "width": 320
        },
        "position": {
          "x": 158.21068858465526,
          "y": 1785.141740108842
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-8oF62",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response_3}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-8oF62",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 2220.0764893740024,
          "y": 4272.62119030678
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "BatchRunComponent-2we8A",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.",
            "display_name": "Batch Run",
            "documentation": "https://docs.langflow.org/components-processing#batch-run",
            "edited": false,
            "field_order": [
              "model",
              "system_message",
              "df",
              "column_name",
              "output_column_name",
              "enable_metadata"
            ],
            "frozen": false,
            "icon": "List",
            "key": "BatchRunComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "LLM Results",
                "group_outputs": false,
                "method": "run_batch",
                "name": "batch_results",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, cast\n\nimport toml  # type: ignore[import-untyped]\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DataFrameInput, HandleInput, MessageTextInput, MultilineInput, Output\nfrom langflow.logging.logger import logger\nfrom langflow.schema.dataframe import DataFrame\n\nif TYPE_CHECKING:\n    from langchain_core.runnables import Runnable\n\n\nclass BatchRunComponent(Component):\n    display_name = \"Batch Run\"\n    description = \"Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#batch-run\"\n    icon = \"List\"\n\n    inputs = [\n        HandleInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Connect the 'Language Model' output from your LLM component here.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"Instructions\",\n            info=\"Multi-line system instruction for all rows in the DataFrame.\",\n            required=False,\n        ),\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The DataFrame whose column (specified by 'column_name') we'll treat as text messages.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=(\n                \"The name of the DataFrame column to treat as text messages. \"\n                \"If empty, all columns will be formatted in TOML.\"\n            ),\n            required=False,\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"output_column_name\",\n            display_name=\"Output Column Name\",\n            info=\"Name of the column where the model's response will be stored.\",\n            value=\"model_response\",\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_metadata\",\n            display_name=\"Enable Metadata\",\n            info=\"If True, add metadata to the output DataFrame.\",\n            value=False,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"LLM Results\",\n            name=\"batch_results\",\n            method=\"run_batch\",\n            info=\"A DataFrame with all original columns plus the model's response column.\",\n        ),\n    ]\n\n    def _format_row_as_toml(self, row: dict[str, Any]) -> str:\n        \"\"\"Convert a dictionary (row) into a TOML-formatted string.\"\"\"\n        formatted_dict = {str(col): {\"value\": str(val)} for col, val in row.items()}\n        return toml.dumps(formatted_dict)\n\n    def _create_base_row(\n        self, original_row: dict[str, Any], model_response: str = \"\", batch_index: int = -1\n    ) -> dict[str, Any]:\n        \"\"\"Create a base row with original columns and additional metadata.\"\"\"\n        row = original_row.copy()\n        row[self.output_column_name] = model_response\n        row[\"batch_index\"] = batch_index\n        return row\n\n    def _add_metadata(\n        self, row: dict[str, Any], *, success: bool = True, system_msg: str = \"\", error: str | None = None\n    ) -> None:\n        \"\"\"Add metadata to a row if enabled.\"\"\"\n        if not self.enable_metadata:\n            return\n\n        if success:\n            row[\"metadata\"] = {\n                \"has_system_message\": bool(system_msg),\n                \"input_length\": len(row.get(\"text_input\", \"\")),\n                \"response_length\": len(row[self.output_column_name]),\n                \"processing_status\": \"success\",\n            }\n        else:\n            row[\"metadata\"] = {\n                \"error\": error,\n                \"processing_status\": \"failed\",\n            }\n\n    async def run_batch(self) -> DataFrame:\n        \"\"\"Process each row in df[column_name] with the language model asynchronously.\n\n        Returns:\n            DataFrame: A new DataFrame containing:\n                - All original columns\n                - The model's response column (customizable name)\n                - 'batch_index' column for processing order\n                - 'metadata' (optional)\n\n        Raises:\n            ValueError: If the specified column is not found in the DataFrame\n            TypeError: If the model is not compatible or input types are wrong\n        \"\"\"\n        model: Runnable = self.model\n        system_msg = self.system_message or \"\"\n        df: DataFrame = self.df\n        col_name = self.column_name or \"\"\n\n        # Validate inputs first\n        if not isinstance(df, DataFrame):\n            msg = f\"Expected DataFrame input, got {type(df)}\"\n            raise TypeError(msg)\n\n        if col_name and col_name not in df.columns:\n            msg = f\"Column '{col_name}' not found in the DataFrame. Available columns: {', '.join(df.columns)}\"\n            raise ValueError(msg)\n\n        try:\n            # Determine text input for each row\n            if col_name:\n                user_texts = df[col_name].astype(str).tolist()\n            else:\n                user_texts = [\n                    self._format_row_as_toml(cast(\"dict[str, Any]\", row)) for row in df.to_dict(orient=\"records\")\n                ]\n\n            total_rows = len(user_texts)\n            await logger.ainfo(f\"Processing {total_rows} rows with batch run\")\n\n            # Prepare the batch of conversations\n            conversations = [\n                [{\"role\": \"system\", \"content\": system_msg}, {\"role\": \"user\", \"content\": text}]\n                if system_msg\n                else [{\"role\": \"user\", \"content\": text}]\n                for text in user_texts\n            ]\n\n            # Configure the model with project info and callbacks\n            model = model.with_config(\n                {\n                    \"run_name\": self.display_name,\n                    \"project_name\": self.get_project_name(),\n                    \"callbacks\": self.get_langchain_callbacks(),\n                }\n            )\n            # Process batches and track progress\n            responses_with_idx = list(\n                zip(\n                    range(len(conversations)),\n                    await model.abatch(list(conversations)),\n                    strict=True,\n                )\n            )\n\n            # Sort by index to maintain order\n            responses_with_idx.sort(key=lambda x: x[0])\n\n            # Build the final data with enhanced metadata\n            rows: list[dict[str, Any]] = []\n            for idx, (original_row, response) in enumerate(\n                zip(df.to_dict(orient=\"records\"), responses_with_idx, strict=False)\n            ):\n                response_text = response[1].content if hasattr(response[1], \"content\") else str(response[1])\n                row = self._create_base_row(\n                    cast(\"dict[str, Any]\", original_row), model_response=response_text, batch_index=idx\n                )\n                self._add_metadata(row, success=True, system_msg=system_msg)\n                rows.append(row)\n\n                # Log progress\n                if (idx + 1) % max(1, total_rows // 10) == 0:\n                    await logger.ainfo(f\"Processed {idx + 1}/{total_rows} rows\")\n\n            await logger.ainfo(\"Batch processing completed successfully\")\n            return DataFrame(rows)\n\n        except (KeyError, AttributeError) as e:\n            # Handle data structure and attribute access errors\n            await logger.aerror(f\"Data processing error: {e!s}\")\n            error_row = self._create_base_row(dict.fromkeys(df.columns, \"\"), model_response=\"\", batch_index=-1)\n            self._add_metadata(error_row, success=False, error=str(e))\n            return DataFrame([error_row])\n"
              },
              "column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": false,
                "info": "The name of the DataFrame column to treat as text messages. If empty, all columns will be formatted in TOML.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Query4"
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The DataFrame whose column (specified by 'column_name') we'll treat as text messages.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "enable_metadata": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Enable Metadata",
                "dynamic": false,
                "info": "If True, add metadata to the output DataFrame.",
                "list": false,
                "list_add_label": "Add More",
                "name": "enable_metadata",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Connect the 'Language Model' output from your LLM component here.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "model",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Output Column Name",
                "dynamic": false,
                "info": "Name of the column where the model's response will be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "model_response_4"
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Instructions",
                "dynamic": false,
                "info": "Multi-line system instruction for all rows in the DataFrame.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "BatchRunComponent"
        },
        "dragging": false,
        "id": "BatchRunComponent-2we8A",
        "measured": {
          "height": 488,
          "width": 320
        },
        "position": {
          "x": 560.0447208794843,
          "y": 1792.1300553456804
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "BatchRunComponent-5KjJT",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.",
            "display_name": "Batch Run",
            "documentation": "https://docs.langflow.org/components-processing#batch-run",
            "edited": false,
            "field_order": [
              "model",
              "system_message",
              "df",
              "column_name",
              "output_column_name",
              "enable_metadata"
            ],
            "frozen": false,
            "icon": "List",
            "key": "BatchRunComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "LLM Results",
                "group_outputs": false,
                "method": "run_batch",
                "name": "batch_results",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, cast\n\nimport toml  # type: ignore[import-untyped]\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DataFrameInput, HandleInput, MessageTextInput, MultilineInput, Output\nfrom langflow.logging.logger import logger\nfrom langflow.schema.dataframe import DataFrame\n\nif TYPE_CHECKING:\n    from langchain_core.runnables import Runnable\n\n\nclass BatchRunComponent(Component):\n    display_name = \"Batch Run\"\n    description = \"Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#batch-run\"\n    icon = \"List\"\n\n    inputs = [\n        HandleInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Connect the 'Language Model' output from your LLM component here.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"Instructions\",\n            info=\"Multi-line system instruction for all rows in the DataFrame.\",\n            required=False,\n        ),\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The DataFrame whose column (specified by 'column_name') we'll treat as text messages.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=(\n                \"The name of the DataFrame column to treat as text messages. \"\n                \"If empty, all columns will be formatted in TOML.\"\n            ),\n            required=False,\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"output_column_name\",\n            display_name=\"Output Column Name\",\n            info=\"Name of the column where the model's response will be stored.\",\n            value=\"model_response\",\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_metadata\",\n            display_name=\"Enable Metadata\",\n            info=\"If True, add metadata to the output DataFrame.\",\n            value=False,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"LLM Results\",\n            name=\"batch_results\",\n            method=\"run_batch\",\n            info=\"A DataFrame with all original columns plus the model's response column.\",\n        ),\n    ]\n\n    def _format_row_as_toml(self, row: dict[str, Any]) -> str:\n        \"\"\"Convert a dictionary (row) into a TOML-formatted string.\"\"\"\n        formatted_dict = {str(col): {\"value\": str(val)} for col, val in row.items()}\n        return toml.dumps(formatted_dict)\n\n    def _create_base_row(\n        self, original_row: dict[str, Any], model_response: str = \"\", batch_index: int = -1\n    ) -> dict[str, Any]:\n        \"\"\"Create a base row with original columns and additional metadata.\"\"\"\n        row = original_row.copy()\n        row[self.output_column_name] = model_response\n        row[\"batch_index\"] = batch_index\n        return row\n\n    def _add_metadata(\n        self, row: dict[str, Any], *, success: bool = True, system_msg: str = \"\", error: str | None = None\n    ) -> None:\n        \"\"\"Add metadata to a row if enabled.\"\"\"\n        if not self.enable_metadata:\n            return\n\n        if success:\n            row[\"metadata\"] = {\n                \"has_system_message\": bool(system_msg),\n                \"input_length\": len(row.get(\"text_input\", \"\")),\n                \"response_length\": len(row[self.output_column_name]),\n                \"processing_status\": \"success\",\n            }\n        else:\n            row[\"metadata\"] = {\n                \"error\": error,\n                \"processing_status\": \"failed\",\n            }\n\n    async def run_batch(self) -> DataFrame:\n        \"\"\"Process each row in df[column_name] with the language model asynchronously.\n\n        Returns:\n            DataFrame: A new DataFrame containing:\n                - All original columns\n                - The model's response column (customizable name)\n                - 'batch_index' column for processing order\n                - 'metadata' (optional)\n\n        Raises:\n            ValueError: If the specified column is not found in the DataFrame\n            TypeError: If the model is not compatible or input types are wrong\n        \"\"\"\n        model: Runnable = self.model\n        system_msg = self.system_message or \"\"\n        df: DataFrame = self.df\n        col_name = self.column_name or \"\"\n\n        # Validate inputs first\n        if not isinstance(df, DataFrame):\n            msg = f\"Expected DataFrame input, got {type(df)}\"\n            raise TypeError(msg)\n\n        if col_name and col_name not in df.columns:\n            msg = f\"Column '{col_name}' not found in the DataFrame. Available columns: {', '.join(df.columns)}\"\n            raise ValueError(msg)\n\n        try:\n            # Determine text input for each row\n            if col_name:\n                user_texts = df[col_name].astype(str).tolist()\n            else:\n                user_texts = [\n                    self._format_row_as_toml(cast(\"dict[str, Any]\", row)) for row in df.to_dict(orient=\"records\")\n                ]\n\n            total_rows = len(user_texts)\n            await logger.ainfo(f\"Processing {total_rows} rows with batch run\")\n\n            # Prepare the batch of conversations\n            conversations = [\n                [{\"role\": \"system\", \"content\": system_msg}, {\"role\": \"user\", \"content\": text}]\n                if system_msg\n                else [{\"role\": \"user\", \"content\": text}]\n                for text in user_texts\n            ]\n\n            # Configure the model with project info and callbacks\n            model = model.with_config(\n                {\n                    \"run_name\": self.display_name,\n                    \"project_name\": self.get_project_name(),\n                    \"callbacks\": self.get_langchain_callbacks(),\n                }\n            )\n            # Process batches and track progress\n            responses_with_idx = list(\n                zip(\n                    range(len(conversations)),\n                    await model.abatch(list(conversations)),\n                    strict=True,\n                )\n            )\n\n            # Sort by index to maintain order\n            responses_with_idx.sort(key=lambda x: x[0])\n\n            # Build the final data with enhanced metadata\n            rows: list[dict[str, Any]] = []\n            for idx, (original_row, response) in enumerate(\n                zip(df.to_dict(orient=\"records\"), responses_with_idx, strict=False)\n            ):\n                response_text = response[1].content if hasattr(response[1], \"content\") else str(response[1])\n                row = self._create_base_row(\n                    cast(\"dict[str, Any]\", original_row), model_response=response_text, batch_index=idx\n                )\n                self._add_metadata(row, success=True, system_msg=system_msg)\n                rows.append(row)\n\n                # Log progress\n                if (idx + 1) % max(1, total_rows // 10) == 0:\n                    await logger.ainfo(f\"Processed {idx + 1}/{total_rows} rows\")\n\n            await logger.ainfo(\"Batch processing completed successfully\")\n            return DataFrame(rows)\n\n        except (KeyError, AttributeError) as e:\n            # Handle data structure and attribute access errors\n            await logger.aerror(f\"Data processing error: {e!s}\")\n            error_row = self._create_base_row(dict.fromkeys(df.columns, \"\"), model_response=\"\", batch_index=-1)\n            self._add_metadata(error_row, success=False, error=str(e))\n            return DataFrame([error_row])\n"
              },
              "column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": false,
                "info": "The name of the DataFrame column to treat as text messages. If empty, all columns will be formatted in TOML.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Query5"
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The DataFrame whose column (specified by 'column_name') we'll treat as text messages.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "enable_metadata": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Enable Metadata",
                "dynamic": false,
                "info": "If True, add metadata to the output DataFrame.",
                "list": false,
                "list_add_label": "Add More",
                "name": "enable_metadata",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Connect the 'Language Model' output from your LLM component here.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "model",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Output Column Name",
                "dynamic": false,
                "info": "Name of the column where the model's response will be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "model_response_5"
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Instructions",
                "dynamic": false,
                "info": "Multi-line system instruction for all rows in the DataFrame.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "BatchRunComponent"
        },
        "dragging": false,
        "id": "BatchRunComponent-5KjJT",
        "measured": {
          "height": 488,
          "width": 320
        },
        "position": {
          "x": 957.1329202936993,
          "y": 1807.5827018554853
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "BatchRunComponent-qweGM",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.",
            "display_name": "Batch Run",
            "documentation": "https://docs.langflow.org/components-processing#batch-run",
            "edited": false,
            "field_order": [
              "model",
              "system_message",
              "df",
              "column_name",
              "output_column_name",
              "enable_metadata"
            ],
            "frozen": false,
            "icon": "List",
            "key": "BatchRunComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "LLM Results",
                "group_outputs": false,
                "method": "run_batch",
                "name": "batch_results",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, cast\n\nimport toml  # type: ignore[import-untyped]\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DataFrameInput, HandleInput, MessageTextInput, MultilineInput, Output\nfrom langflow.logging.logger import logger\nfrom langflow.schema.dataframe import DataFrame\n\nif TYPE_CHECKING:\n    from langchain_core.runnables import Runnable\n\n\nclass BatchRunComponent(Component):\n    display_name = \"Batch Run\"\n    description = \"Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#batch-run\"\n    icon = \"List\"\n\n    inputs = [\n        HandleInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Connect the 'Language Model' output from your LLM component here.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"Instructions\",\n            info=\"Multi-line system instruction for all rows in the DataFrame.\",\n            required=False,\n        ),\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The DataFrame whose column (specified by 'column_name') we'll treat as text messages.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=(\n                \"The name of the DataFrame column to treat as text messages. \"\n                \"If empty, all columns will be formatted in TOML.\"\n            ),\n            required=False,\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"output_column_name\",\n            display_name=\"Output Column Name\",\n            info=\"Name of the column where the model's response will be stored.\",\n            value=\"model_response\",\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_metadata\",\n            display_name=\"Enable Metadata\",\n            info=\"If True, add metadata to the output DataFrame.\",\n            value=False,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"LLM Results\",\n            name=\"batch_results\",\n            method=\"run_batch\",\n            info=\"A DataFrame with all original columns plus the model's response column.\",\n        ),\n    ]\n\n    def _format_row_as_toml(self, row: dict[str, Any]) -> str:\n        \"\"\"Convert a dictionary (row) into a TOML-formatted string.\"\"\"\n        formatted_dict = {str(col): {\"value\": str(val)} for col, val in row.items()}\n        return toml.dumps(formatted_dict)\n\n    def _create_base_row(\n        self, original_row: dict[str, Any], model_response: str = \"\", batch_index: int = -1\n    ) -> dict[str, Any]:\n        \"\"\"Create a base row with original columns and additional metadata.\"\"\"\n        row = original_row.copy()\n        row[self.output_column_name] = model_response\n        row[\"batch_index\"] = batch_index\n        return row\n\n    def _add_metadata(\n        self, row: dict[str, Any], *, success: bool = True, system_msg: str = \"\", error: str | None = None\n    ) -> None:\n        \"\"\"Add metadata to a row if enabled.\"\"\"\n        if not self.enable_metadata:\n            return\n\n        if success:\n            row[\"metadata\"] = {\n                \"has_system_message\": bool(system_msg),\n                \"input_length\": len(row.get(\"text_input\", \"\")),\n                \"response_length\": len(row[self.output_column_name]),\n                \"processing_status\": \"success\",\n            }\n        else:\n            row[\"metadata\"] = {\n                \"error\": error,\n                \"processing_status\": \"failed\",\n            }\n\n    async def run_batch(self) -> DataFrame:\n        \"\"\"Process each row in df[column_name] with the language model asynchronously.\n\n        Returns:\n            DataFrame: A new DataFrame containing:\n                - All original columns\n                - The model's response column (customizable name)\n                - 'batch_index' column for processing order\n                - 'metadata' (optional)\n\n        Raises:\n            ValueError: If the specified column is not found in the DataFrame\n            TypeError: If the model is not compatible or input types are wrong\n        \"\"\"\n        model: Runnable = self.model\n        system_msg = self.system_message or \"\"\n        df: DataFrame = self.df\n        col_name = self.column_name or \"\"\n\n        # Validate inputs first\n        if not isinstance(df, DataFrame):\n            msg = f\"Expected DataFrame input, got {type(df)}\"\n            raise TypeError(msg)\n\n        if col_name and col_name not in df.columns:\n            msg = f\"Column '{col_name}' not found in the DataFrame. Available columns: {', '.join(df.columns)}\"\n            raise ValueError(msg)\n\n        try:\n            # Determine text input for each row\n            if col_name:\n                user_texts = df[col_name].astype(str).tolist()\n            else:\n                user_texts = [\n                    self._format_row_as_toml(cast(\"dict[str, Any]\", row)) for row in df.to_dict(orient=\"records\")\n                ]\n\n            total_rows = len(user_texts)\n            await logger.ainfo(f\"Processing {total_rows} rows with batch run\")\n\n            # Prepare the batch of conversations\n            conversations = [\n                [{\"role\": \"system\", \"content\": system_msg}, {\"role\": \"user\", \"content\": text}]\n                if system_msg\n                else [{\"role\": \"user\", \"content\": text}]\n                for text in user_texts\n            ]\n\n            # Configure the model with project info and callbacks\n            model = model.with_config(\n                {\n                    \"run_name\": self.display_name,\n                    \"project_name\": self.get_project_name(),\n                    \"callbacks\": self.get_langchain_callbacks(),\n                }\n            )\n            # Process batches and track progress\n            responses_with_idx = list(\n                zip(\n                    range(len(conversations)),\n                    await model.abatch(list(conversations)),\n                    strict=True,\n                )\n            )\n\n            # Sort by index to maintain order\n            responses_with_idx.sort(key=lambda x: x[0])\n\n            # Build the final data with enhanced metadata\n            rows: list[dict[str, Any]] = []\n            for idx, (original_row, response) in enumerate(\n                zip(df.to_dict(orient=\"records\"), responses_with_idx, strict=False)\n            ):\n                response_text = response[1].content if hasattr(response[1], \"content\") else str(response[1])\n                row = self._create_base_row(\n                    cast(\"dict[str, Any]\", original_row), model_response=response_text, batch_index=idx\n                )\n                self._add_metadata(row, success=True, system_msg=system_msg)\n                rows.append(row)\n\n                # Log progress\n                if (idx + 1) % max(1, total_rows // 10) == 0:\n                    await logger.ainfo(f\"Processed {idx + 1}/{total_rows} rows\")\n\n            await logger.ainfo(\"Batch processing completed successfully\")\n            return DataFrame(rows)\n\n        except (KeyError, AttributeError) as e:\n            # Handle data structure and attribute access errors\n            await logger.aerror(f\"Data processing error: {e!s}\")\n            error_row = self._create_base_row(dict.fromkeys(df.columns, \"\"), model_response=\"\", batch_index=-1)\n            self._add_metadata(error_row, success=False, error=str(e))\n            return DataFrame([error_row])\n"
              },
              "column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": false,
                "info": "The name of the DataFrame column to treat as text messages. If empty, all columns will be formatted in TOML.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Query6"
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The DataFrame whose column (specified by 'column_name') we'll treat as text messages.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "enable_metadata": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Enable Metadata",
                "dynamic": false,
                "info": "If True, add metadata to the output DataFrame.",
                "list": false,
                "list_add_label": "Add More",
                "name": "enable_metadata",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Connect the 'Language Model' output from your LLM component here.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "model",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Output Column Name",
                "dynamic": false,
                "info": "Name of the column where the model's response will be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "model_response_6"
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Instructions",
                "dynamic": false,
                "info": "Multi-line system instruction for all rows in the DataFrame.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "BatchRunComponent"
        },
        "dragging": false,
        "id": "BatchRunComponent-qweGM",
        "measured": {
          "height": 488,
          "width": 320
        },
        "position": {
          "x": 1362.0391969780223,
          "y": 1810.7298876247673
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-jA80n",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response_4}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-jA80n",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 2221.2245977807347,
          "y": 4674.537935915916
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-d2GaL",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response_5}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-d2GaL",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 2240.763732053079,
          "y": 5086.383125766273
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-kGA1v",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response_6}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-kGA1v",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 2238.3853178046484,
          "y": 5519.254518980511
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "MessageToLocalFile-kbCOY",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Saves a LangFlow Message as a local file using extracted Program ID.",
            "display_name": "Message to Local File",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input",
              "output_folder",
              "file_extension"
            ],
            "frozen": false,
            "icon": "file",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Result Message",
                "group_outputs": false,
                "hidden": null,
                "method": "build_output",
                "name": "result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from pathlib import Path\r\nimport re\r\nfrom collections.abc import AsyncIterator, Iterator\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import StrInput, MessageInput, Output, DataInput\r\nfrom langflow.schema import Message\r\nfrom langflow.inputs import MessageTextInput\r\nfrom langflow.schema.data import Data\r\n\r\n\r\nclass FileBuilderComponent(Component):\r\n    display_name = \"Message to Local File\"\r\n    description = \"Saves a LangFlow Message as a local file using extracted Program ID.\"\r\n    icon = \"file\"\r\n    name = \"MessageToLocalFile\"\r\n\r\n    inputs = [\r\n        DataInput(\r\n            name=\"input\",\r\n            display_name=\"Input Data\",\r\n            \r\n            required=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"output_folder\",\r\n            display_name=\"Output Folder\",\r\n            info=\"Folder path to save the file locally.\",\r\n            value=\"/app/data\",\r\n            required=False,\r\n        ),\r\n        StrInput(\r\n            name=\"file_extension\",\r\n            display_name=\"File Extension\",\r\n            info=\"Extension for the saved file (e.g. txt, md, json)\",\r\n            value=\"txt\",\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"Result Message\",\r\n            name=\"result\",\r\n            method=\"build_output\",\r\n        ),\r\n    ]\r\n\r\n    async def build_output(self) -> Message:\r\n        \"\"\"Saves a Message as a local file using the Program ID for naming.\"\"\"\r\n\r\n        # message: Message = self.input\r\n        content = self.input.concat_text\r\n\r\n        program_id = self.input.file_name\r\n        program_id = program_id.split('.')[0]\r\n        # raise ValueError(program_id)\r\n        file_name = f\"Summary_{program_id}.{self.file_extension.lstrip('.')}\"\r\n        # raise ValueError(self.output_folder)\r\n        output_path = Path(self.output_folder) / file_name\r\n\r\n        output_path.parent.mkdir(parents=True, exist_ok=True)\r\n        output_path.write_text(content, encoding=\"utf-8\")\r\n\r\n        return Message(text=f\"✅ File saved locally as '{output_path.resolve()}'.\")\r\n\r\n    def _extract_text(self, message: Message) -> str:\r\n        \"\"\"Extracts text from a Message object.\"\"\"\r\n        if isinstance(message.text, AsyncIterator):\r\n            return \"\".join([str(item async for item in message.text)])\r\n        elif isinstance(message.text, Iterator):\r\n            return \"\".join(str(item) for item in message.text)\r\n        return str(message.text)\r\n\r\n    def _extract_program_id(self, content: str) -> str:\r\n        \"\"\"Extracts the Program ID from the message content.\"\"\"\r\n        lines = content.splitlines()\r\n        if len(lines) >= 3:\r\n            line = lines[2].strip()\r\n            match = re.search(r\"\\*\\s+\\*\\*Program ID\\*\\*:\\s*(\\w+)\", line)\r\n            if match:\r\n                return match.group(1)\r\n        raise ValueError(\"Could not extract Program ID from message content.\")\r\n"
              },
              "file_extension": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "File Extension",
                "dynamic": false,
                "info": "Extension for the saved file (e.g. txt, md, json)",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "file_extension",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "md"
              },
              "input": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Input Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_folder": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Output Folder",
                "dynamic": false,
                "info": "Folder path to save the file locally.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_folder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "MessageToLocalFile"
        },
        "dragging": false,
        "id": "MessageToLocalFile-kbCOY",
        "measured": {
          "height": 267,
          "width": 320
        },
        "position": {
          "x": 2266.2592352588536,
          "y": 1980.3664882338016
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-vVdou",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{Move_file_Res}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-vVdou",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 2228.120686682708,
          "y": 5916.361619782335
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "MoveFileComponent-GwHcj",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Move a file from source path to destination folder (message in / message out)",
            "display_name": "Move File",
            "documentation": "",
            "edited": true,
            "field_order": [
              "file_path_msg",
              "destination_dir_msg"
            ],
            "frozen": false,
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Result Message",
                "group_outputs": false,
                "hidden": null,
                "method": "build_result_message",
                "name": "output_message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\r\nfrom langflow.template import Output, Input\r\nfrom langflow.inputs import StrInput, MessageTextInput\r\nfrom langflow.schema.message import Message\r\nimport os\r\nimport shutil\r\nfrom langflow.io import MessageInput\r\n\r\nclass MoveFileComponent(Component):\r\n    display_name = \"Move File\"\r\n    description = \"Move a file from source path to destination folder (message in / message out)\"\r\n\r\n    # Define inputs\r\n    inputs = [\r\n        # Use MessageTextInput if you want to accept a Message’s text as the path\r\n        MessageInput(\r\n            name=\"file_path_msg\",\r\n            display_name=\"File Path Message\",\r\n            info=\"Message whose text is the source file path\"\r\n        ),\r\n        MessageTextInput(\r\n            name=\"destination_dir_msg\",\r\n            display_name=\"Destination Directory Message\",\r\n            info=\"Message whose text is the destination directory path\"\r\n        ),\r\n    ]\r\n\r\n    # Define outputs\r\n    outputs = [\r\n        Output(\r\n            name=\"output_message\",\r\n            display_name=\"Result Message\",\r\n            method=\"build_result_message\"\r\n        ),\r\n    ]\r\n\r\n    def build_result_message(self) -> Message:\r\n        # Extract the path strings from the messages\r\n        # In the component, you can refer to inputs as self.<input_name>\r\n        file_path_msg = self.file_path_msg  # this is a Message object\r\n        # raise TypeError(type(file_path_msg))\r\n        dest_dir_msg = self.destination_dir_msg  # also Message\r\n\r\n        # Some safety: default to empty string if missing\r\n        file_path = file_path_msg.text\r\n        file_path = file_path[17:]\r\n        # raise TypeError(file_path)\r\n        destination_dir = dest_dir_msg #getattr(dest_dir_msg, \"text\", \"\") or \"\"\r\n        \r\n        \r\n        \r\n        # Ensure destination exists\r\n        try:\r\n            os.makedirs(destination_dir, exist_ok=True)\r\n        except Exception as e:\r\n            return Message(text=f\"❌ Failed to create destination directory '{destination_dir}': {e}\")\r\n\r\n        # Compute destination path\r\n        file_name = os.path.basename(file_path)\r\n        new_path = os.path.join(destination_dir, file_name)\r\n        \r\n        \r\n        # Attempt move\r\n        try:\r\n            shutil.move(file_path, new_path)\r\n            return Message(text=f\"✅ File moved to: {new_path}\")\r\n        except FileNotFoundError:\r\n            return Message(text=f\"❌ File not found: {file_path}\")\r\n        except Exception as e:\r\n            return Message(text=f\"❌ Error moving file: {e}\")\r\n"
              },
              "destination_dir_msg": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Destination Directory Message",
                "dynamic": false,
                "info": "Message whose text is the destination directory path",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "destination_dir_msg",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "file_path_msg": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "File Path Message",
                "dynamic": false,
                "info": "Message whose text is the source file path",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "file_path_msg",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "MoveFileComponent"
        },
        "dragging": false,
        "id": "MoveFileComponent-GwHcj",
        "measured": {
          "height": 305,
          "width": 320
        },
        "position": {
          "x": 2773.1689642022475,
          "y": 3708.276488384797
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CreateData-8fHO6",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Dynamically create a Data with a specified number of fields.",
            "display_name": "Create Data",
            "documentation": "",
            "edited": false,
            "field_order": [
              "number_of_fields",
              "text_key",
              "text_key_validator"
            ],
            "frozen": false,
            "icon": "ListFilter",
            "key": "CreateData",
            "last_updated": "2026-02-02T06:32:14.317Z",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data",
                "group_outputs": false,
                "loop_types": null,
                "method": "build_data",
                "name": "data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations"
            ],
            "score": 0.00387276615055604,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import BoolInput, DictInput, IntInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dotdict import dotdict\n\n\nclass CreateDataComponent(Component):\n    display_name: str = \"Create Data\"\n    description: str = \"Dynamically create a Data with a specified number of fields.\"\n    name: str = \"CreateData\"\n    MAX_FIELDS = 15  # Define a constant for maximum number of fields\n    legacy = True\n    replacement = [\"processing.DataOperations\"]\n    icon = \"ListFilter\"\n\n    inputs = [\n        IntInput(\n            name=\"number_of_fields\",\n            display_name=\"Number of Fields\",\n            info=\"Number of fields to be added to the record.\",\n            real_time_refresh=True,\n            value=1,\n            range_spec=RangeSpec(min=1, max=MAX_FIELDS, step=1, step_type=\"int\"),\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"Key that identifies the field to be used as the text content.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"text_key_validator\",\n            display_name=\"Text Key Validator\",\n            advanced=True,\n            info=\"If enabled, checks if the given 'Text Key' is present in the given 'Data'.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"build_data\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"number_of_fields\":\n            default_keys = [\"code\", \"_type\", \"number_of_fields\", \"text_key\", \"text_key_validator\"]\n            try:\n                field_value_int = int(field_value)\n            except ValueError:\n                return build_config\n            existing_fields = {}\n            if field_value_int > self.MAX_FIELDS:\n                build_config[\"number_of_fields\"][\"value\"] = self.MAX_FIELDS\n                msg = (\n                    f\"Number of fields cannot exceed {self.MAX_FIELDS}. \"\n                    \"Please adjust the number of fields to be within the allowed limit.\"\n                )\n                raise ValueError(msg)\n            if len(build_config) > len(default_keys):\n                # back up the existing template fields\n                for key in build_config.copy():\n                    if key not in default_keys:\n                        existing_fields[key] = build_config.pop(key)\n\n            for i in range(1, field_value_int + 1):\n                key = f\"field_{i}_key\"\n                if key in existing_fields:\n                    field = existing_fields[key]\n                    build_config[key] = field\n                else:\n                    field = DictInput(\n                        display_name=f\"Field {i}\",\n                        name=key,\n                        info=f\"Key for field {i}.\",\n                        input_types=[\"Message\", \"Data\"],\n                    )\n                    build_config[field.name] = field.to_dict()\n\n            build_config[\"number_of_fields\"][\"value\"] = field_value_int\n        return build_config\n\n    async def build_data(self) -> Data:\n        data = self.get_data()\n        return_data = Data(data=data, text_key=self.text_key)\n        self.status = return_data\n        if self.text_key_validator:\n            self.validate_text_key()\n        return return_data\n\n    def get_data(self):\n        \"\"\"Function to get the Data from the attributes.\"\"\"\n        data = {}\n        for value_dict in self._attributes.values():\n            if isinstance(value_dict, dict):\n                # Check if the value of the value_dict is a Data\n                value_dict_ = {\n                    key: value.get_text() if isinstance(value, Data) else value for key, value in value_dict.items()\n                }\n                data.update(value_dict_)\n        return data\n\n    def validate_text_key(self) -> None:\n        \"\"\"This function validates that the Text Key is one of the keys in the Data.\"\"\"\n        data_keys = self.get_data().keys()\n        if self.text_key not in data_keys and self.text_key != \"\":\n            formatted_data_keys = \", \".join(data_keys)\n            msg = f\"Text Key: '{self.text_key}' not found in the Data keys: '{formatted_data_keys}'\"\n            raise ValueError(msg)\n"
              },
              "field_1_key": {
                "_input_type": "DictInput",
                "advanced": false,
                "display_name": "Field 1",
                "dynamic": false,
                "info": "Key for field 1.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "field_1_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {
                  "Save_file_Res": ""
                }
              },
              "number_of_fields": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Fields",
                "dynamic": false,
                "info": "Number of fields to be added to the record.",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_of_fields",
                "placeholder": "",
                "range_spec": {
                  "max": 15,
                  "min": 1,
                  "step": 1,
                  "step_type": "int"
                },
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "text_key": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Key",
                "dynamic": false,
                "info": "Key that identifies the field to be used as the text content.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text_key_validator": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Text Key Validator",
                "dynamic": false,
                "info": "If enabled, checks if the given 'Text Key' is present in the given 'Data'.",
                "list": false,
                "list_add_label": "Add More",
                "name": "text_key_validator",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CreateData"
        },
        "dragging": false,
        "id": "CreateData-8fHO6",
        "measured": {
          "height": 317,
          "width": 320
        },
        "position": {
          "x": 2658.404656937802,
          "y": 1950.358495152736
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "MoveFileComponent-2rbae",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Move a file from source path to destination folder (message in / message out)",
            "display_name": "Move File",
            "documentation": "",
            "edited": true,
            "field_order": [
              "file_path_msg",
              "destination_dir_msg"
            ],
            "frozen": false,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Result Message",
                "group_outputs": false,
                "hidden": null,
                "method": "build_result_message",
                "name": "output_message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\r\nfrom langflow.template import Output, Input\r\nfrom langflow.inputs import StrInput, MessageTextInput\r\nfrom langflow.schema.message import Message\r\nimport os\r\nimport shutil\r\nfrom langflow.io import MessageInput\r\n\r\nclass MoveFileComponent(Component):\r\n    display_name = \"Move File\"\r\n    description = \"Move a file from source path to destination folder (message in / message out)\"\r\n\r\n    # Define inputs\r\n    inputs = [\r\n        # Use MessageTextInput if you want to accept a Message’s text as the path\r\n        MessageInput(\r\n            name=\"file_path_msg\",\r\n            display_name=\"File Path Message\",\r\n            info=\"Message whose text is the source file path\"\r\n        ),\r\n        MessageTextInput(\r\n            name=\"destination_dir_msg\",\r\n            display_name=\"Destination Directory Message\",\r\n            info=\"Message whose text is the destination directory path\"\r\n        ),\r\n    ]\r\n\r\n    # Define outputs\r\n    outputs = [\r\n        Output(\r\n            name=\"output_message\",\r\n            display_name=\"Result Message\",\r\n            method=\"build_result_message\"\r\n        ),\r\n    ]\r\n\r\n    def build_result_message(self) -> Message:\r\n        # Extract the path strings from the messages\r\n        # In the component, you can refer to inputs as self.<input_name>\r\n        file_path_msg = self.file_path_msg  # this is a Message object\r\n        # raise TypeError(type(file_path_msg))\r\n        dest_dir_msg = self.destination_dir_msg  # also Message\r\n\r\n        # Some safety: default to empty string if missing\r\n        file_path = file_path_msg.text #getattr(file_path_msg, \"text\", \"\") or \"\"\r\n        destination_dir = dest_dir_msg #getattr(dest_dir_msg, \"text\", \"\") or \"\"\r\n        \r\n        \r\n        \r\n        # Ensure destination exists\r\n        try:\r\n            os.makedirs(destination_dir, exist_ok=True)\r\n        except Exception as e:\r\n            return Message(text=f\"❌ Failed to create destination directory '{destination_dir}': {e}\")\r\n\r\n        # Compute destination path\r\n        file_name = os.path.basename(file_path)\r\n        new_path = os.path.join(destination_dir, file_name)\r\n        \r\n        \r\n        # Attempt move\r\n        try:\r\n            shutil.move(file_path, new_path)\r\n            return Message(text=f\"{new_path}\")\r\n            # return Message(text=f\"{file_name}\")\r\n        except FileNotFoundError:\r\n            return Message(text=f\"❌ File not found: {file_path}\")\r\n        except Exception as e:\r\n            return Message(text=f\"❌ Error moving file: {e}\")\r\n"
              },
              "destination_dir_msg": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Destination Directory Message",
                "dynamic": false,
                "info": "Message whose text is the destination directory path",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "destination_dir_msg",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "file_path_msg": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "File Path Message",
                "dynamic": false,
                "info": "Message whose text is the source file path",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "file_path_msg",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "MoveFileComponent"
        },
        "dragging": false,
        "id": "MoveFileComponent-2rbae",
        "measured": {
          "height": 305,
          "width": 320
        },
        "position": {
          "x": -1725.0424181163382,
          "y": 2409.4525575296525
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CreateData-Wo4xJ",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Dynamically create a Data with a specified number of fields.",
            "display_name": "Create Data",
            "documentation": "",
            "edited": false,
            "field_order": [
              "number_of_fields",
              "text_key",
              "text_key_validator"
            ],
            "frozen": false,
            "icon": "ListFilter",
            "last_updated": "2026-02-02T06:32:14.318Z",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data",
                "group_outputs": false,
                "hidden": null,
                "loop_types": null,
                "method": "build_data",
                "name": "data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations"
            ],
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import BoolInput, DictInput, IntInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dotdict import dotdict\n\n\nclass CreateDataComponent(Component):\n    display_name: str = \"Create Data\"\n    description: str = \"Dynamically create a Data with a specified number of fields.\"\n    name: str = \"CreateData\"\n    MAX_FIELDS = 15  # Define a constant for maximum number of fields\n    legacy = True\n    replacement = [\"processing.DataOperations\"]\n    icon = \"ListFilter\"\n\n    inputs = [\n        IntInput(\n            name=\"number_of_fields\",\n            display_name=\"Number of Fields\",\n            info=\"Number of fields to be added to the record.\",\n            real_time_refresh=True,\n            value=1,\n            range_spec=RangeSpec(min=1, max=MAX_FIELDS, step=1, step_type=\"int\"),\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"Key that identifies the field to be used as the text content.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"text_key_validator\",\n            display_name=\"Text Key Validator\",\n            advanced=True,\n            info=\"If enabled, checks if the given 'Text Key' is present in the given 'Data'.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"build_data\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"number_of_fields\":\n            default_keys = [\"code\", \"_type\", \"number_of_fields\", \"text_key\", \"text_key_validator\"]\n            try:\n                field_value_int = int(field_value)\n            except ValueError:\n                return build_config\n            existing_fields = {}\n            if field_value_int > self.MAX_FIELDS:\n                build_config[\"number_of_fields\"][\"value\"] = self.MAX_FIELDS\n                msg = (\n                    f\"Number of fields cannot exceed {self.MAX_FIELDS}. \"\n                    \"Please adjust the number of fields to be within the allowed limit.\"\n                )\n                raise ValueError(msg)\n            if len(build_config) > len(default_keys):\n                # back up the existing template fields\n                for key in build_config.copy():\n                    if key not in default_keys:\n                        existing_fields[key] = build_config.pop(key)\n\n            for i in range(1, field_value_int + 1):\n                key = f\"field_{i}_key\"\n                if key in existing_fields:\n                    field = existing_fields[key]\n                    build_config[key] = field\n                else:\n                    field = DictInput(\n                        display_name=f\"Field {i}\",\n                        name=key,\n                        info=f\"Key for field {i}.\",\n                        input_types=[\"Message\", \"Data\"],\n                    )\n                    build_config[field.name] = field.to_dict()\n\n            build_config[\"number_of_fields\"][\"value\"] = field_value_int\n        return build_config\n\n    async def build_data(self) -> Data:\n        data = self.get_data()\n        return_data = Data(data=data, text_key=self.text_key)\n        self.status = return_data\n        if self.text_key_validator:\n            self.validate_text_key()\n        return return_data\n\n    def get_data(self):\n        \"\"\"Function to get the Data from the attributes.\"\"\"\n        data = {}\n        for value_dict in self._attributes.values():\n            if isinstance(value_dict, dict):\n                # Check if the value of the value_dict is a Data\n                value_dict_ = {\n                    key: value.get_text() if isinstance(value, Data) else value for key, value in value_dict.items()\n                }\n                data.update(value_dict_)\n        return data\n\n    def validate_text_key(self) -> None:\n        \"\"\"This function validates that the Text Key is one of the keys in the Data.\"\"\"\n        data_keys = self.get_data().keys()\n        if self.text_key not in data_keys and self.text_key != \"\":\n            formatted_data_keys = \", \".join(data_keys)\n            msg = f\"Text Key: '{self.text_key}' not found in the Data keys: '{formatted_data_keys}'\"\n            raise ValueError(msg)\n"
              },
              "field_1_key": {
                "_input_type": "DictInput",
                "advanced": false,
                "display_name": "Field 1",
                "dynamic": false,
                "info": "Key for field 1.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "field_1_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "field_2_key": {
                "_input_type": "DictInput",
                "advanced": false,
                "display_name": "Field 2",
                "dynamic": false,
                "info": "Key for field 2.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "field_2_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "field_3_key": {
                "_input_type": "DictInput",
                "advanced": false,
                "display_name": "Field 3",
                "dynamic": false,
                "info": "Key for field 3.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "field_3_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "field_4_key": {
                "_input_type": "DictInput",
                "advanced": false,
                "display_name": "Field 4",
                "dynamic": false,
                "info": "Key for field 4.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "field_4_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "field_5_key": {
                "_input_type": "DictInput",
                "advanced": false,
                "display_name": "Field 5",
                "dynamic": false,
                "info": "Key for field 5.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "field_5_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "field_6_key": {
                "_input_type": "DictInput",
                "advanced": false,
                "display_name": "Field 6",
                "dynamic": false,
                "info": "Key for field 6.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "field_6_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "field_7_key": {
                "_input_type": "DictInput",
                "advanced": false,
                "display_name": "Field 7",
                "dynamic": false,
                "info": "Key for field 7.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "field_7_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "number_of_fields": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Fields",
                "dynamic": false,
                "info": "Number of fields to be added to the record.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "number_of_fields",
                "placeholder": "",
                "range_spec": {
                  "max": 15,
                  "min": 1,
                  "step": 1,
                  "step_type": "int"
                },
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 7
              },
              "text_key": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Key",
                "dynamic": false,
                "info": "Key that identifies the field to be used as the text content.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text_key_validator": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Text Key Validator",
                "dynamic": false,
                "info": "If enabled, checks if the given 'Text Key' is present in the given 'Data'.",
                "list": false,
                "list_add_label": "Add More",
                "name": "text_key_validator",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CreateData"
        },
        "dragging": false,
        "id": "CreateData-Wo4xJ",
        "measured": {
          "height": 819,
          "width": 320
        },
        "position": {
          "x": -2464.550989252394,
          "y": 4059.3706026961117
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-WCESG",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "file_name"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "file_name": {
                "advanced": false,
                "display_name": "file_name",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "file_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "By analyzing {file_name} in knowledge base, provide the Program Overview, write no less than 300 words in this session. Generate the Program Overview one time only, do not repeat. Strictly follow the defined Markdown output format below, without omitting any part. Do not need to show the word count.\n\n## 1. Program Overview\n\n* **Program ID**: [Extracted from IDENTIFICATION DIVISION]\n* **Function Description**: A concise summary of the program's main business purpose.\n* **Main Processes **: List out all the processes in the cobol program, by looking into the PROCEDURE DIVISION."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-WCESG",
        "measured": {
          "height": 378,
          "width": 320
        },
        "position": {
          "x": -1513.2329232682189,
          "y": 4021.6705104051744
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-4wUOO",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "Text Input",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "hidden": null,
                "method": "text_response",
                "name": "text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Batch_SRD222S.txt"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-4wUOO",
        "measured": {
          "height": 215,
          "width": 320
        },
        "position": {
          "x": -1707.1091197369415,
          "y": 2071.0732277714405
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-ayuRE",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "file_name"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "file_name": {
                "advanced": false,
                "display_name": "file_name",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "file_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "By analyzing {file_name} in knowledge base, provide the Flowchart. Use Mermaid syntax to visualize the main execution flow of `PROCEDURE DIVISION`. \nPlease strictly generate the document in the following Markdown structure:\n\n## 2. Flowchart\n```mermaid\ngraph TD\n    A[Start] --> B[Read Input File];\n    B --> C[End of File?];\n    C -- Yes --> D[Close Files];\n    C -- No --> E[Process Record];\n    E --> F[Write to Output File];\n    F --> B;\n    D --> G[End];\n```"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-ayuRE",
        "measured": {
          "height": 378,
          "width": 320
        },
        "position": {
          "x": -1501.2283317910608,
          "y": 4467.04085420774
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-fdYOJ",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "file_name"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "file_name": {
                "advanced": false,
                "display_name": "file_name",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "file_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "By analyzing {file_name} in knowledge base, provide the Input/Output of the code in below md format\n\n## 3. Input/Output\n* **Input**:\n    * `[Input File Name 1]`: [Briefly describe the purpose and key fields of this file].\n    * `[Input File Name 2]`: ...\n\t...\n* **Output**:\n    * `[Output File Name 1]`: [Briefly describe the purpose and generation method of this file].\n    * `[Output File Name 2]`: ...\n\t..."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-fdYOJ",
        "measured": {
          "height": 378,
          "width": 320
        },
        "position": {
          "x": -1499.6500982177374,
          "y": 4892.003392499137
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-IrqwX",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "file_name"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "file_name": {
                "advanced": false,
                "display_name": "file_name",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "file_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "By analyzing {file_name} in knowledge base, provide the Program Structure Analysis of the code in below md format\n\n## 4. Program Structure Analysis\n* **`IDENTIFICATION DIVISION`**: Metadata information of the program, such as author, date, etc.\n* **`ENVIRONMENT DIVISION`**: Describes the program's runtime environment, especially `FILE-CONTROL` related to files.\n* **`DATA DIVISION`**:\n    * **`FILE SECTION`**: Defines input/output files (FD) used by the program and their record layouts.\n    * **`WORKING-STORAGE SECTION`**: Describes key variables, flags, counters, and data structures used internally in the program.\n* **`PROCEDURE DIVISION`**: The core logic of the program, describing major paragraphs and their functions.\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-IrqwX",
        "measured": {
          "height": 378,
          "width": 320
        },
        "position": {
          "x": -1101.1883260453462,
          "y": 4025.6881683440856
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-awPjg",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "file_name"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "file_name": {
                "advanced": false,
                "display_name": "file_name",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "file_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "By analyzing {file_name} in knowledge base, \nFirst, list out all the functions by looking for the PERFORM (`perform`) in `PROCEDURE DIVISION` in logical order and provide the line no for that function. \nDo not miss out any `perform` in the `PROCEDURE DIVISION`. \nIf the function is calling another sub-function, please list out all the sub-function being called in the main function.\nList all the sub-functions being called as a normal function after all the main function.\nSecond, provide the mermaid flowchart and detailed steps for each function.\nFor both flowcharts and steps, it has to be as detailed as possible to capture all detailed logic of the function. \nDetailed validation rules, default values, error handling must be clearly stated in the steps.\nThe steps have to be in sync with the flowchart. \nWrite no less than 150 words for each function.\nDo not need to generate other section such as overview, flowchart, input/output, Program Structure Analysis. Only need to generate the Detailed Core Logic part.\nprovide the Detailed Core Logic of the code in below md format.\n\n## 5. Detailed Core Logic\n\n* **Function List**:\n    * `[Function 1]`: From Line [150] to line [200]. [Function 1] is calling [Sub-function 1]\n    * `[Function 2]`: From Line [205] to line [249].\n\t* `[Sub-function 1]`: From Line [833] to line [892]. [Sub-function 1] is calling [Sub-function 2]\n\t* `[Sub-function 2]`: From Line [916] to line [990].\n\t...\n\t\n* **`[Function 1]`**: \n\t```mermaid\n\tgraph TD\n\t\tflowchart for Function 1\n\t```\n    * [Step 1, describe the first step of Function 1 in detail]\n\t* [Step 2, describe the second step of Function 1 in detail]\n\t...\n\n* **`[Function 2]`**: \n\t```mermaid\n\tgraph TD\n\t\tflowchart for Function 2\n\t```\n    * [Step 1, describe the first step of Function 2 in detail]\n\t* [Step 2, describe the second step of Function 2 in detail]\n\t...\n..."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-awPjg",
        "measured": {
          "height": 378,
          "width": 320
        },
        "position": {
          "x": -1102.8218988625074,
          "y": 4442.2492367201485
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-yivJF",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "file_name"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "file_name": {
                "advanced": false,
                "display_name": "file_name",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "file_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "By analyzing {file_name} in knowledge base, provide the Dependencies of the code in below md format, list out all the copybooks and called program, do not miss out one of it.\nFor Copybooks, please look for the `COPY` statements in the code.\nFor Called Program, please look for the `CALL` statements in the code.\n\n## 6. Dependencies\n  * **Copybooks**:\n      * `[COPY 'COPYBOOK1.CPY']`: [Briefly explain the purpose of this copybook, e.g., record definitions].\n\t  * `[COPY 'COPYBOOK2.CPY']`: [Briefly explain the purpose of this copybook, e.g., record definitions].\n\t  ...\n  * **Called Programs**:\n      * `[CALL 'SUBPROG1']`: [Briefly explain the purpose of calling this subroutine].\n\t  * `[CALL 'SUBPROG2']`: [Briefly explain the purpose of calling this subroutine].\n\t  ...\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-yivJF",
        "measured": {
          "height": 378,
          "width": 320
        },
        "position": {
          "x": -1082.0739051526969,
          "y": 4880.046751719305
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DataToDataFrame-J7Pe5",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Converts one or multiple Data objects into a DataFrame. Each Data object corresponds to one row. Fields from `.data` become columns, and the `.text` (if present) is placed in a 'text' column.",
            "display_name": "Data → DataFrame",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data_list"
            ],
            "frozen": false,
            "icon": "table",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "hidden": null,
                "method": "build_dataframe",
                "name": "dataframe",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations",
              "processing.TypeConverterComponent"
            ],
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import DataInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\n\n\nclass DataToDataFrameComponent(Component):\n    display_name = \"Data → DataFrame\"\n    description = (\n        \"Converts one or multiple Data objects into a DataFrame. \"\n        \"Each Data object corresponds to one row. Fields from `.data` become columns, \"\n        \"and the `.text` (if present) is placed in a 'text' column.\"\n    )\n    icon = \"table\"\n    name = \"DataToDataFrame\"\n    legacy = True\n    replacement = [\"processing.DataOperations\", \"processing.TypeConverterComponent\"]\n\n    inputs = [\n        DataInput(\n            name=\"data_list\",\n            display_name=\"Data or Data List\",\n            info=\"One or multiple Data objects to transform into a DataFrame.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"DataFrame\",\n            name=\"dataframe\",\n            method=\"build_dataframe\",\n            info=\"A DataFrame built from each Data object's fields plus a 'text' column.\",\n        ),\n    ]\n\n    def build_dataframe(self) -> DataFrame:\n        \"\"\"Builds a DataFrame from Data objects by combining their fields.\n\n        For each Data object:\n          - Merge item.data (dictionary) as columns\n          - If item.text is present, add 'text' column\n\n        Returns a DataFrame with one row per Data object.\n        \"\"\"\n        data_input = self.data_list\n\n        # If user passed a single Data, it might come in as a single object rather than a list\n        if not isinstance(data_input, list):\n            data_input = [data_input]\n\n        rows = []\n        for item in data_input:\n            if not isinstance(item, Data):\n                msg = f\"Expected Data objects, got {type(item)} instead.\"\n                raise TypeError(msg)\n\n            # Start with a copy of item.data or an empty dict\n            row_dict = dict(item.data) if item.data else {}\n\n            # If the Data object has text, store it under 'text' col\n            text_val = item.get_text()\n            if text_val:\n                row_dict[\"text\"] = text_val\n\n            rows.append(row_dict)\n\n        # Build a DataFrame from these row dictionaries\n        df_result = DataFrame(rows)\n        self.status = df_result  # store in self.status for logs\n        return df_result\n"
              },
              "data_list": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data or Data List",
                "dynamic": false,
                "info": "One or multiple Data objects to transform into a DataFrame.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data_list",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DataToDataFrame"
        },
        "dragging": false,
        "id": "DataToDataFrame-J7Pe5",
        "measured": {
          "height": 227,
          "width": 320
        },
        "position": {
          "x": -610.8843487294779,
          "y": 2394.9322333770683
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "JSONtoData-sEp7A",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "data",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert a JSON file, JSON from a file path, or a JSON string to a Data object or a list of Data objects",
            "display_name": "Load JSON",
            "documentation": "",
            "edited": false,
            "field_order": [
              "json_file",
              "json_path",
              "json_string"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "JSONtoData",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data",
                "group_outputs": false,
                "method": "convert_json_to_data",
                "name": "data",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "data.File"
            ],
            "score": 0.07433131107431833,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom pathlib import Path\n\nfrom json_repair import repair_json\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.schema.data import Data\n\n\nclass JSONToDataComponent(Component):\n    display_name = \"Load JSON\"\n    description = (\n        \"Convert a JSON file, JSON from a file path, or a JSON string to a Data object or a list of Data objects\"\n    )\n    icon = \"braces\"\n    name = \"JSONtoData\"\n    legacy = True\n    replacement = [\"data.File\"]\n\n    inputs = [\n        FileInput(\n            name=\"json_file\",\n            display_name=\"JSON File\",\n            file_types=[\"json\"],\n            info=\"Upload a JSON file to convert to a Data object or list of Data objects\",\n        ),\n        MessageTextInput(\n            name=\"json_path\",\n            display_name=\"JSON File Path\",\n            info=\"Provide the path to the JSON file as pure text\",\n        ),\n        MultilineInput(\n            name=\"json_string\",\n            display_name=\"JSON String\",\n            info=\"Enter a valid JSON string (object or array) to convert to a Data object or list of Data objects\",\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"data\", display_name=\"Data\", method=\"convert_json_to_data\"),\n    ]\n\n    def convert_json_to_data(self) -> Data | list[Data]:\n        if sum(bool(field) for field in [self.json_file, self.json_path, self.json_string]) != 1:\n            msg = \"Please provide exactly one of: JSON file, file path, or JSON string.\"\n            self.status = msg\n            raise ValueError(msg)\n\n        json_data = None\n\n        try:\n            if self.json_file:\n                resolved_path = self.resolve_path(self.json_file)\n                file_path = Path(resolved_path)\n                if file_path.suffix.lower() != \".json\":\n                    self.status = \"The provided file must be a JSON file.\"\n                else:\n                    json_data = file_path.read_text(encoding=\"utf-8\")\n\n            elif self.json_path:\n                file_path = Path(self.json_path)\n                if file_path.suffix.lower() != \".json\":\n                    self.status = \"The provided file must be a JSON file.\"\n                else:\n                    json_data = file_path.read_text(encoding=\"utf-8\")\n\n            else:\n                json_data = self.json_string\n\n            if json_data:\n                # Try to parse the JSON string\n                try:\n                    parsed_data = json.loads(json_data)\n                except json.JSONDecodeError:\n                    # If JSON parsing fails, try to repair the JSON string\n                    repaired_json_string = repair_json(json_data)\n                    parsed_data = json.loads(repaired_json_string)\n\n                # Check if the parsed data is a list\n                if isinstance(parsed_data, list):\n                    result = [Data(data=item) for item in parsed_data]\n                else:\n                    result = Data(data=parsed_data)\n                self.status = result\n                return result\n\n        except (json.JSONDecodeError, SyntaxError, ValueError) as e:\n            error_message = f\"Invalid JSON or Python literal: {e}\"\n            self.status = error_message\n            raise ValueError(error_message) from e\n\n        except Exception as e:\n            error_message = f\"An error occurred: {e}\"\n            self.status = error_message\n            raise ValueError(error_message) from e\n\n        # An error occurred\n        raise ValueError(self.status)\n"
              },
              "json_file": {
                "_input_type": "FileInput",
                "advanced": false,
                "display_name": "JSON File",
                "dynamic": false,
                "fileTypes": [
                  "json"
                ],
                "file_path": "",
                "info": "Upload a JSON file to convert to a Data object or list of Data objects",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_file",
                "placeholder": "",
                "required": false,
                "show": true,
                "temp_file": false,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "json_path": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JSON File Path",
                "dynamic": false,
                "info": "Provide the path to the JSON file as pure text",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "json_path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "/data/projects/cobol-test/Cobol_Summary_Gen/config.json"
              },
              "json_string": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "JSON String",
                "dynamic": false,
                "info": "Enter a valid JSON string (object or array) to convert to a Data object or list of Data objects",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "json_string",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "JSONtoData"
        },
        "dragging": false,
        "id": "JSONtoData-sEp7A",
        "measured": {
          "height": 426,
          "width": 320
        },
        "position": {
          "x": -4224.659398684753,
          "y": 1626.5847570572598
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "FilterData-xN6hf",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": true,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Filters a Data object based on a list of keys.",
            "display_name": "Filter Data",
            "documentation": "",
            "edited": true,
            "field_order": [
              "data",
              "filter_criteria"
            ],
            "frozen": false,
            "icon": "filter",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "group_outputs": false,
                "hidden": null,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations"
            ],
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import DataInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.message import Message\n\nclass FilterDataComponent(Component):\n    display_name = \"Filter Data\"\n    description = \"Filters a Data object based on a list of keys.\"\n    icon = \"filter\"\n    beta = True\n    name = \"FilterData\"\n    legacy = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"Data object to filter.\",\n        ),\n        MessageTextInput(\n            name=\"filter_criteria\",\n            display_name=\"Filter Criteria\",\n            info=\"List of keys to filter by.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def filter_data(self) -> Message:\n        # raise ValueError(type(self.filter_criteria[0]))\n        filter_criteria: str = self.filter_criteria[0]\n        data = self.data.data if isinstance(self.data, Data) else {}\n\n        # Filter the data\n        # filtered = {key: value for key, value in data.items() if key in filter_criteria}\n        value = data[filter_criteria]\n\n        # Create a new Data object with the filtered data\n        filtered_data = Message(text=value)\n        self.status = filtered_data\n        return filtered_data\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "filter_criteria": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Filter Criteria",
                "dynamic": false,
                "info": "List of keys to filter by.",
                "input_types": [
                  "Message"
                ],
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "filter_criteria",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "Processing_folder_path"
                ]
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "FilterData"
        },
        "dragging": false,
        "id": "FilterData-xN6hf",
        "measured": {
          "height": 330,
          "width": 320
        },
        "position": {
          "x": -3349.128577752455,
          "y": 1544.0394939746577
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "FilterData-5vIiT",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": true,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Filters a Data object based on a list of keys.",
            "display_name": "Filter Data",
            "documentation": "",
            "edited": true,
            "field_order": [
              "data",
              "filter_criteria"
            ],
            "frozen": false,
            "icon": "filter",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "group_outputs": false,
                "hidden": null,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations"
            ],
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import DataInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.message import Message\n\nclass FilterDataComponent(Component):\n    display_name = \"Filter Data\"\n    description = \"Filters a Data object based on a list of keys.\"\n    icon = \"filter\"\n    beta = True\n    name = \"FilterData\"\n    legacy = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"Data object to filter.\",\n        ),\n        MessageTextInput(\n            name=\"filter_criteria\",\n            display_name=\"Filter Criteria\",\n            info=\"List of keys to filter by.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def filter_data(self) -> Message:\n        # raise ValueError(type(self.filter_criteria[0]))\n        filter_criteria: str = self.filter_criteria[0]\n        data = self.data.data if isinstance(self.data, Data) else {}\n\n        # Filter the data\n        # filtered = {key: value for key, value in data.items() if key in filter_criteria}\n        value = data[filter_criteria]\n\n        # Create a new Data object with the filtered data\n        filtered_data = Message(text=value)\n        self.status = filtered_data\n        return filtered_data\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "filter_criteria": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Filter Criteria",
                "dynamic": false,
                "info": "List of keys to filter by.",
                "input_types": [
                  "Message"
                ],
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "filter_criteria",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "Input_folder_path"
                ]
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "FilterData"
        },
        "dragging": false,
        "id": "FilterData-5vIiT",
        "measured": {
          "height": 330,
          "width": 320
        },
        "position": {
          "x": -3351.4259744624487,
          "y": 1177.604718730604
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "FilterData-nQJ3a",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": true,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Filters a Data object based on a list of keys.",
            "display_name": "Filter Data",
            "documentation": "",
            "edited": true,
            "field_order": [
              "data",
              "filter_criteria"
            ],
            "frozen": false,
            "icon": "filter",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "group_outputs": false,
                "hidden": null,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations"
            ],
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import DataInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.message import Message\n\nclass FilterDataComponent(Component):\n    display_name = \"Filter Data\"\n    description = \"Filters a Data object based on a list of keys.\"\n    icon = \"filter\"\n    beta = True\n    name = \"FilterData\"\n    legacy = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"Data object to filter.\",\n        ),\n        MessageTextInput(\n            name=\"filter_criteria\",\n            display_name=\"Filter Criteria\",\n            info=\"List of keys to filter by.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def filter_data(self) -> Message:\n        # raise ValueError(type(self.filter_criteria[0]))\n        filter_criteria: str = self.filter_criteria[0]\n        data = self.data.data if isinstance(self.data, Data) else {}\n\n        # Filter the data\n        # filtered = {key: value for key, value in data.items() if key in filter_criteria}\n        value = data[filter_criteria]\n\n        # Create a new Data object with the filtered data\n        filtered_data = Message(text=value)\n        self.status = filtered_data\n        return filtered_data\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "filter_criteria": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Filter Criteria",
                "dynamic": false,
                "info": "List of keys to filter by.",
                "input_types": [
                  "Message"
                ],
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "filter_criteria",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "Output_folder_path"
                ]
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "FilterData"
        },
        "dragging": false,
        "id": "FilterData-nQJ3a",
        "measured": {
          "height": 330,
          "width": 320
        },
        "position": {
          "x": -3352.8394194440893,
          "y": 1910.969633300079
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "FilterData-KIDFD",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": true,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Filters a Data object based on a list of keys.",
            "display_name": "Filter Data",
            "documentation": "",
            "edited": true,
            "field_order": [
              "data",
              "filter_criteria"
            ],
            "frozen": false,
            "icon": "filter",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "group_outputs": false,
                "hidden": null,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations"
            ],
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import DataInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.message import Message\n\nclass FilterDataComponent(Component):\n    display_name = \"Filter Data\"\n    description = \"Filters a Data object based on a list of keys.\"\n    icon = \"filter\"\n    beta = True\n    name = \"FilterData\"\n    legacy = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"Data object to filter.\",\n        ),\n        MessageTextInput(\n            name=\"filter_criteria\",\n            display_name=\"Filter Criteria\",\n            info=\"List of keys to filter by.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def filter_data(self) -> Message:\n        # raise ValueError(type(self.filter_criteria[0]))\n        filter_criteria: str = self.filter_criteria[0]\n        data = self.data.data if isinstance(self.data, Data) else {}\n\n        # Filter the data\n        # filtered = {key: value for key, value in data.items() if key in filter_criteria}\n        value = data[filter_criteria]\n\n        # Create a new Data object with the filtered data\n        filtered_data = Message(text=value)\n        self.status = filtered_data\n        return filtered_data\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "filter_criteria": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Filter Criteria",
                "dynamic": false,
                "info": "List of keys to filter by.",
                "input_types": [
                  "Message"
                ],
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "filter_criteria",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "Completed_folder_path"
                ]
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "FilterData"
        },
        "dragging": false,
        "id": "FilterData-KIDFD",
        "measured": {
          "height": 330,
          "width": 320
        },
        "position": {
          "x": -3355.862633993999,
          "y": 2290.479708157791
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "FilterData-RYq4v",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": true,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Filters a Data object based on a list of keys.",
            "display_name": "Filter Data",
            "documentation": "",
            "edited": true,
            "field_order": [
              "data",
              "filter_criteria"
            ],
            "frozen": false,
            "icon": "filter",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "group_outputs": false,
                "hidden": null,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations"
            ],
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import DataInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.message import Message\n\nclass FilterDataComponent(Component):\n    display_name = \"Filter Data\"\n    description = \"Filters a Data object based on a list of keys.\"\n    icon = \"filter\"\n    beta = True\n    name = \"FilterData\"\n    legacy = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"Data object to filter.\",\n        ),\n        MessageTextInput(\n            name=\"filter_criteria\",\n            display_name=\"Filter Criteria\",\n            info=\"List of keys to filter by.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def filter_data(self) -> Message:\n        # raise ValueError(type(self.filter_criteria[0]))\n        filter_criteria: str = self.filter_criteria[0]\n        data = self.data.data if isinstance(self.data, Data) else {}\n\n        # Filter the data\n        # filtered = {key: value for key, value in data.items() if key in filter_criteria}\n        value = data[filter_criteria]\n\n        # Create a new Data object with the filtered data\n        filtered_data = Message(text=value)\n        self.status = filtered_data\n        return filtered_data\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "filter_criteria": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Filter Criteria",
                "dynamic": false,
                "info": "List of keys to filter by.",
                "input_types": [
                  "Message"
                ],
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "filter_criteria",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "RAGflow_chat_id"
                ]
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "FilterData"
        },
        "dragging": false,
        "id": "FilterData-RYq4v",
        "measured": {
          "height": 330,
          "width": 320
        },
        "position": {
          "x": -3806.092742016745,
          "y": 1197.165151862892
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "FilterData-n0F3q",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": true,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Filters a Data object based on a list of keys.",
            "display_name": "Filter Data",
            "documentation": "",
            "edited": true,
            "field_order": [
              "data",
              "filter_criteria"
            ],
            "frozen": false,
            "icon": "filter",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "group_outputs": false,
                "hidden": null,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations"
            ],
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import DataInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.message import Message\n\nclass FilterDataComponent(Component):\n    display_name = \"Filter Data\"\n    description = \"Filters a Data object based on a list of keys.\"\n    icon = \"filter\"\n    beta = True\n    name = \"FilterData\"\n    legacy = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"Data object to filter.\",\n        ),\n        MessageTextInput(\n            name=\"filter_criteria\",\n            display_name=\"Filter Criteria\",\n            info=\"List of keys to filter by.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def filter_data(self) -> Message:\n        # raise ValueError(type(self.filter_criteria[0]))\n        filter_criteria: str = self.filter_criteria[0]\n        data = self.data.data if isinstance(self.data, Data) else {}\n\n        # Filter the data\n        # filtered = {key: value for key, value in data.items() if key in filter_criteria}\n        value = data[filter_criteria]\n\n        # Create a new Data object with the filtered data\n        filtered_data = Message(text=value)\n        self.status = filtered_data\n        return filtered_data\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "filter_criteria": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Filter Criteria",
                "dynamic": false,
                "info": "List of keys to filter by.",
                "input_types": [
                  "Message"
                ],
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "filter_criteria",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "Ragflow_chat_API_key"
                ]
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "FilterData"
        },
        "dragging": false,
        "id": "FilterData-n0F3q",
        "measured": {
          "height": 330,
          "width": 320
        },
        "position": {
          "x": -3812.155608282785,
          "y": 1563.968560958408
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-8xHeQ",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response_1}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-8xHeQ",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": -641.1176364021205,
          "y": 1361.9285325551225
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-dQjhd",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "knowledge",
                "memory"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "knowledge": {
                "advanced": false,
                "display_name": "knowledge",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "knowledge",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "{knowledge}"
              },
              "memory": {
                "advanced": false,
                "display_name": "memory",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "empty"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "# Role\nYou are a professional business analyst with more than 20-year experience in a world class software development company. Having technical user from the bank as the audience of your documentation. The bank is now requesting you to write a technical specification document on the cobol code they provide. Please provide information in a business formal, technical and professional style. Please write in a concise and informative tone. By referring to the knowledge base in the manual dataset, it gives you a better understanding of the cobol structure and definition. \n\n\n# Task\nYour primary task is to analyze the COBOL code file in the path below running on HP non-stop tandem provided by the user and generate a comprehensive, structured Markdown technical document. User may ask you specific question regarding the cobol file, answer the question base on the understanding of the file.\n\n# Constraints and Limitations\n* **Adhere to Original Text**: All explanations and analyses must strictly be based on the provided COBOL code; do not guess or add functionalities do not present in the code.\n* **Professional Terminology**: Use professional and accurate terminology while ensuring clarity.\n* **Language**: Conduct analysis and documentation writing in English.\n* **Format**: Strictly follow the defined Markdown output format below, without omitting any part.\n\nHere is the knowledge base:\n{knowledge}\nThe above is the knowledge base.\n\n\nHere is the chat History:\n{memory}\nThe above is the chat History."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-dQjhd",
        "measured": {
          "height": 462,
          "width": 320
        },
        "position": {
          "x": -2337.752900379616,
          "y": 898.633199089427
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Memory-LFCnc",
          "node": {
            "base_classes": [
              "DataFrame",
              "Message"
            ],
            "beta": false,
            "category": "helpers",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Stores or retrieves stored chat messages from Langflow tables or an external memory.",
            "display_name": "Message History",
            "documentation": "https://docs.langflow.org/components-helpers#message-history",
            "edited": false,
            "field_order": [
              "mode",
              "message",
              "memory",
              "sender_type",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "frozen": false,
            "icon": "message-square-more",
            "key": "Memory",
            "last_updated": "2025-10-22T03:58:35.802Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Messages",
                "group_outputs": false,
                "hidden": null,
                "method": "retrieve_messages_as_text",
                "name": "messages_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Dataframe",
                "group_outputs": false,
                "hidden": null,
                "method": "retrieve_messages_dataframe",
                "name": "dataframe",
                "options": null,
                "required_inputs": null,
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.1676812955549333,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any, cast\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.inputs.inputs import DropdownInput, HandleInput, IntInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.memory import aget_messages, astore_message\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\nfrom langflow.utils.component_utils import set_current_fields, set_field_display\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Message History\"\n    description = \"Stores or retrieves stored chat messages from Langflow tables or an external memory.\"\n    documentation: str = \"https://docs.langflow.org/components-helpers#message-history\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n    default_keys = [\"mode\", \"memory\", \"session_id\"]\n    mode_config = {\n        \"Store\": [\"message\", \"memory\", \"sender\", \"sender_name\", \"session_id\"],\n        \"Retrieve\": [\"n_messages\", \"order\", \"template\", \"memory\", \"session_id\"],\n    }\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Retrieve\", \"Store\"],\n            value=\"Retrieve\",\n            info=\"Operation mode: Store messages or Retrieve messages.\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The chat message to be stored.\",\n            tool_mode=True,\n            dynamic=True,\n            show=False,\n        ),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"Memory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender_type\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender\",\n            display_name=\"Sender\",\n            info=\"The sender of the message. Might be Machine or User. \"\n            \"If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            value=\"\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n            tool_mode=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Message\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True),\n        Output(display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True),\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"mode\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n            if field_value == \"Store\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Stored Messages\",\n                        name=\"stored_messages\",\n                        method=\"store_message\",\n                        hidden=True,\n                        dynamic=True,\n                    )\n                ]\n            if field_value == \"Retrieve\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Messages\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True\n                    ),\n                    Output(\n                        display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True\n                    ),\n                ]\n        return frontend_node\n\n    async def store_message(self) -> Message:\n        message = Message(text=self.message) if isinstance(self.message, str) else self.message\n\n        message.session_id = self.session_id or message.session_id\n        message.sender = self.sender or message.sender or MESSAGE_SENDER_AI\n        message.sender_name = self.sender_name or message.sender_name or MESSAGE_SENDER_NAME_AI\n\n        stored_messages: list[Message] = []\n\n        if self.memory:\n            self.memory.session_id = message.session_id\n            lc_message = message.to_lc_message()\n            await self.memory.aadd_messages([lc_message])\n\n            stored_messages = await self.memory.aget_messages() or []\n\n            stored_messages = [Message.from_lc_message(m) for m in stored_messages] if stored_messages else []\n\n            if message.sender:\n                stored_messages = [m for m in stored_messages if m.sender == message.sender]\n        else:\n            await astore_message(message, flow_id=self.graph.flow_id)\n            stored_messages = (\n                await aget_messages(\n                    session_id=message.session_id, sender_name=message.sender_name, sender=message.sender\n                )\n                or []\n            )\n\n        if not stored_messages:\n            msg = \"No messages were stored. Please ensure that the session ID and sender are properly set.\"\n            raise ValueError(msg)\n\n        stored_message = stored_messages[0]\n        self.status = stored_message\n        return stored_message\n\n    async def retrieve_messages(self) -> Data:\n        sender_type = self.sender_type\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender_type == \"Machine and User\":\n            sender_type = None\n\n        if self.memory and not hasattr(self.memory, \"aget_messages\"):\n            memory_name = type(self.memory).__name__\n            err_msg = f\"External Memory object ({memory_name}) must have 'aget_messages' method.\"\n            raise AttributeError(err_msg)\n        # Check if n_messages is None or 0\n        if n_messages == 0:\n            stored = []\n        elif self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = await self.memory.aget_messages()\n            # langchain memories are supposed to return messages in ascending order\n\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages first\n\n            if order == \"DESC\":\n                stored = stored[::-1]  # Then reverse if needed\n\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender_type:\n                expected_type = MESSAGE_SENDER_AI if sender_type == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            # For internal memory, we always fetch the last N messages by ordering by DESC\n            stored = await aget_messages(\n                sender=sender_type,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=10000,\n                order=order,\n            )\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages\n\n        # self.status = stored\n        return cast(\"Data\", stored)\n\n    async def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, await self.retrieve_messages())\n        # self.status = stored_text\n        return Message(text=stored_text)\n\n    async def retrieve_messages_dataframe(self) -> DataFrame:\n        \"\"\"Convert the retrieved messages into a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the message data.\n        \"\"\"\n        messages = await self.retrieve_messages()\n        return DataFrame(messages)\n\n    def update_build_config(\n        self,\n        build_config: dotdict,\n        field_value: Any,  # noqa: ARG002\n        field_name: str | None = None,  # noqa: ARG002\n    ) -> dotdict:\n        return set_current_fields(\n            build_config=build_config,\n            action_fields=self.mode_config,\n            selected_action=build_config[\"mode\"][\"value\"],\n            default_fields=self.default_keys,\n            func=set_field_display,\n        )\n"
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "message": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": true,
                "info": "The chat message to be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": " "
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Operation mode: Store messages or Retrieve messages.",
                "name": "mode",
                "options": [
                  "Retrieve",
                  "Store"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Retrieve"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "external_options": {},
                "info": "Order of the messages.",
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Sender",
                "dynamic": false,
                "info": "The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender_type": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Filter by sender type.",
                "name": "sender_type",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "/data/projects/cobol-test/Input/CS00001M.txt"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              }
            },
            "tool_mode": false
          },
          "selected_output": "messages_text",
          "showNode": true,
          "type": "Memory"
        },
        "dragging": false,
        "id": "Memory-LFCnc",
        "measured": {
          "height": 692,
          "width": 320
        },
        "position": {
          "x": -3253.1972486766053,
          "y": 198.52997503706027
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-IeMjy",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response_2}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-IeMjy",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": -250.13781860611704,
          "y": 1372.2215556006959
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Memory-zXRE1",
          "node": {
            "base_classes": [
              "DataFrame",
              "Message"
            ],
            "beta": false,
            "category": "helpers",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Stores or retrieves stored chat messages from Langflow tables or an external memory.",
            "display_name": "Message History",
            "documentation": "https://docs.langflow.org/components-helpers#message-history",
            "edited": false,
            "field_order": [
              "mode",
              "message",
              "memory",
              "sender_type",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "frozen": false,
            "icon": "message-square-more",
            "key": "Memory",
            "last_updated": "2025-10-22T04:00:15.486Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Stored Messages",
                "group_outputs": false,
                "hidden": true,
                "method": "store_message",
                "name": "stored_messages",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.1676812955549333,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any, cast\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.inputs.inputs import DropdownInput, HandleInput, IntInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.memory import aget_messages, astore_message\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\nfrom langflow.utils.component_utils import set_current_fields, set_field_display\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Message History\"\n    description = \"Stores or retrieves stored chat messages from Langflow tables or an external memory.\"\n    documentation: str = \"https://docs.langflow.org/components-helpers#message-history\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n    default_keys = [\"mode\", \"memory\", \"session_id\"]\n    mode_config = {\n        \"Store\": [\"message\", \"memory\", \"sender\", \"sender_name\", \"session_id\"],\n        \"Retrieve\": [\"n_messages\", \"order\", \"template\", \"memory\", \"session_id\"],\n    }\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Retrieve\", \"Store\"],\n            value=\"Retrieve\",\n            info=\"Operation mode: Store messages or Retrieve messages.\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The chat message to be stored.\",\n            tool_mode=True,\n            dynamic=True,\n            show=False,\n        ),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"Memory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender_type\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender\",\n            display_name=\"Sender\",\n            info=\"The sender of the message. Might be Machine or User. \"\n            \"If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            value=\"\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n            tool_mode=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Message\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True),\n        Output(display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True),\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"mode\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n            if field_value == \"Store\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Stored Messages\",\n                        name=\"stored_messages\",\n                        method=\"store_message\",\n                        hidden=True,\n                        dynamic=True,\n                    )\n                ]\n            if field_value == \"Retrieve\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Messages\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True\n                    ),\n                    Output(\n                        display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True\n                    ),\n                ]\n        return frontend_node\n\n    async def store_message(self) -> Message:\n        message = Message(text=self.message) if isinstance(self.message, str) else self.message\n\n        message.session_id = self.session_id or message.session_id\n        message.sender = self.sender or message.sender or MESSAGE_SENDER_AI\n        message.sender_name = self.sender_name or message.sender_name or MESSAGE_SENDER_NAME_AI\n\n        stored_messages: list[Message] = []\n\n        if self.memory:\n            self.memory.session_id = message.session_id\n            lc_message = message.to_lc_message()\n            await self.memory.aadd_messages([lc_message])\n\n            stored_messages = await self.memory.aget_messages() or []\n\n            stored_messages = [Message.from_lc_message(m) for m in stored_messages] if stored_messages else []\n\n            if message.sender:\n                stored_messages = [m for m in stored_messages if m.sender == message.sender]\n        else:\n            await astore_message(message, flow_id=self.graph.flow_id)\n            stored_messages = (\n                await aget_messages(\n                    session_id=message.session_id, sender_name=message.sender_name, sender=message.sender\n                )\n                or []\n            )\n\n        if not stored_messages:\n            msg = \"No messages were stored. Please ensure that the session ID and sender are properly set.\"\n            raise ValueError(msg)\n\n        stored_message = stored_messages[0]\n        self.status = stored_message\n        return stored_message\n\n    async def retrieve_messages(self) -> Data:\n        sender_type = self.sender_type\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender_type == \"Machine and User\":\n            sender_type = None\n\n        if self.memory and not hasattr(self.memory, \"aget_messages\"):\n            memory_name = type(self.memory).__name__\n            err_msg = f\"External Memory object ({memory_name}) must have 'aget_messages' method.\"\n            raise AttributeError(err_msg)\n        # Check if n_messages is None or 0\n        if n_messages == 0:\n            stored = []\n        elif self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = await self.memory.aget_messages()\n            # langchain memories are supposed to return messages in ascending order\n\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages first\n\n            if order == \"DESC\":\n                stored = stored[::-1]  # Then reverse if needed\n\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender_type:\n                expected_type = MESSAGE_SENDER_AI if sender_type == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            # For internal memory, we always fetch the last N messages by ordering by DESC\n            stored = await aget_messages(\n                sender=sender_type,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=10000,\n                order=order,\n            )\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages\n\n        # self.status = stored\n        return cast(\"Data\", stored)\n\n    async def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, await self.retrieve_messages())\n        # self.status = stored_text\n        return Message(text=stored_text)\n\n    async def retrieve_messages_dataframe(self) -> DataFrame:\n        \"\"\"Convert the retrieved messages into a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the message data.\n        \"\"\"\n        messages = await self.retrieve_messages()\n        return DataFrame(messages)\n\n    def update_build_config(\n        self,\n        build_config: dotdict,\n        field_value: Any,  # noqa: ARG002\n        field_name: str | None = None,  # noqa: ARG002\n    ) -> dotdict:\n        return set_current_fields(\n            build_config=build_config,\n            action_fields=self.mode_config,\n            selected_action=build_config[\"mode\"][\"value\"],\n            default_fields=self.default_keys,\n            func=set_field_display,\n        )\n"
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "message": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": true,
                "info": "The chat message to be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Operation mode: Store messages or Retrieve messages.",
                "name": "mode",
                "options": [
                  "Retrieve",
                  "Store"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Store"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "external_options": {},
                "info": "Order of the messages.",
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": true,
                "show": false,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Sender",
                "dynamic": false,
                "info": "The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Qwen3"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Qwen3"
              },
              "sender_type": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Filter by sender type.",
                "name": "sender_type",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              }
            },
            "tool_mode": false
          },
          "selected_output": "messages_text",
          "showNode": true,
          "type": "Memory"
        },
        "dragging": false,
        "id": "Memory-zXRE1",
        "measured": {
          "height": 704,
          "width": 320
        },
        "position": {
          "x": -259.6248021560871,
          "y": 601.5449852107505
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-NWvdW",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response_3}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-NWvdW",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 141.70521727969998,
          "y": 1380.4961599414662
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Memory-kkihI",
          "node": {
            "base_classes": [
              "DataFrame",
              "Message"
            ],
            "beta": false,
            "category": "helpers",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Stores or retrieves stored chat messages from Langflow tables or an external memory.",
            "display_name": "Message History",
            "documentation": "https://docs.langflow.org/components-helpers#message-history",
            "edited": false,
            "field_order": [
              "mode",
              "message",
              "memory",
              "sender_type",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "frozen": false,
            "icon": "message-square-more",
            "key": "Memory",
            "last_updated": "2025-10-22T04:00:15.486Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Stored Messages",
                "group_outputs": false,
                "hidden": true,
                "method": "store_message",
                "name": "stored_messages",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.1676812955549333,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any, cast\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.inputs.inputs import DropdownInput, HandleInput, IntInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.memory import aget_messages, astore_message\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\nfrom langflow.utils.component_utils import set_current_fields, set_field_display\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Message History\"\n    description = \"Stores or retrieves stored chat messages from Langflow tables or an external memory.\"\n    documentation: str = \"https://docs.langflow.org/components-helpers#message-history\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n    default_keys = [\"mode\", \"memory\", \"session_id\"]\n    mode_config = {\n        \"Store\": [\"message\", \"memory\", \"sender\", \"sender_name\", \"session_id\"],\n        \"Retrieve\": [\"n_messages\", \"order\", \"template\", \"memory\", \"session_id\"],\n    }\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Retrieve\", \"Store\"],\n            value=\"Retrieve\",\n            info=\"Operation mode: Store messages or Retrieve messages.\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The chat message to be stored.\",\n            tool_mode=True,\n            dynamic=True,\n            show=False,\n        ),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"Memory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender_type\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender\",\n            display_name=\"Sender\",\n            info=\"The sender of the message. Might be Machine or User. \"\n            \"If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            value=\"\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n            tool_mode=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Message\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True),\n        Output(display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True),\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"mode\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n            if field_value == \"Store\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Stored Messages\",\n                        name=\"stored_messages\",\n                        method=\"store_message\",\n                        hidden=True,\n                        dynamic=True,\n                    )\n                ]\n            if field_value == \"Retrieve\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Messages\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True\n                    ),\n                    Output(\n                        display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True\n                    ),\n                ]\n        return frontend_node\n\n    async def store_message(self) -> Message:\n        message = Message(text=self.message) if isinstance(self.message, str) else self.message\n\n        message.session_id = self.session_id or message.session_id\n        message.sender = self.sender or message.sender or MESSAGE_SENDER_AI\n        message.sender_name = self.sender_name or message.sender_name or MESSAGE_SENDER_NAME_AI\n\n        stored_messages: list[Message] = []\n\n        if self.memory:\n            self.memory.session_id = message.session_id\n            lc_message = message.to_lc_message()\n            await self.memory.aadd_messages([lc_message])\n\n            stored_messages = await self.memory.aget_messages() or []\n\n            stored_messages = [Message.from_lc_message(m) for m in stored_messages] if stored_messages else []\n\n            if message.sender:\n                stored_messages = [m for m in stored_messages if m.sender == message.sender]\n        else:\n            await astore_message(message, flow_id=self.graph.flow_id)\n            stored_messages = (\n                await aget_messages(\n                    session_id=message.session_id, sender_name=message.sender_name, sender=message.sender\n                )\n                or []\n            )\n\n        if not stored_messages:\n            msg = \"No messages were stored. Please ensure that the session ID and sender are properly set.\"\n            raise ValueError(msg)\n\n        stored_message = stored_messages[0]\n        self.status = stored_message\n        return stored_message\n\n    async def retrieve_messages(self) -> Data:\n        sender_type = self.sender_type\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender_type == \"Machine and User\":\n            sender_type = None\n\n        if self.memory and not hasattr(self.memory, \"aget_messages\"):\n            memory_name = type(self.memory).__name__\n            err_msg = f\"External Memory object ({memory_name}) must have 'aget_messages' method.\"\n            raise AttributeError(err_msg)\n        # Check if n_messages is None or 0\n        if n_messages == 0:\n            stored = []\n        elif self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = await self.memory.aget_messages()\n            # langchain memories are supposed to return messages in ascending order\n\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages first\n\n            if order == \"DESC\":\n                stored = stored[::-1]  # Then reverse if needed\n\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender_type:\n                expected_type = MESSAGE_SENDER_AI if sender_type == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            # For internal memory, we always fetch the last N messages by ordering by DESC\n            stored = await aget_messages(\n                sender=sender_type,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=10000,\n                order=order,\n            )\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages\n\n        # self.status = stored\n        return cast(\"Data\", stored)\n\n    async def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, await self.retrieve_messages())\n        # self.status = stored_text\n        return Message(text=stored_text)\n\n    async def retrieve_messages_dataframe(self) -> DataFrame:\n        \"\"\"Convert the retrieved messages into a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the message data.\n        \"\"\"\n        messages = await self.retrieve_messages()\n        return DataFrame(messages)\n\n    def update_build_config(\n        self,\n        build_config: dotdict,\n        field_value: Any,  # noqa: ARG002\n        field_name: str | None = None,  # noqa: ARG002\n    ) -> dotdict:\n        return set_current_fields(\n            build_config=build_config,\n            action_fields=self.mode_config,\n            selected_action=build_config[\"mode\"][\"value\"],\n            default_fields=self.default_keys,\n            func=set_field_display,\n        )\n"
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "message": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": true,
                "info": "The chat message to be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Operation mode: Store messages or Retrieve messages.",
                "name": "mode",
                "options": [
                  "Retrieve",
                  "Store"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Store"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "external_options": {},
                "info": "Order of the messages.",
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": true,
                "show": false,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Sender",
                "dynamic": false,
                "info": "The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Qwen3"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Qwen3"
              },
              "sender_type": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Filter by sender type.",
                "name": "sender_type",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              }
            },
            "tool_mode": false
          },
          "selected_output": "messages_text",
          "showNode": true,
          "type": "Memory"
        },
        "dragging": false,
        "id": "Memory-kkihI",
        "measured": {
          "height": 704,
          "width": 320
        },
        "position": {
          "x": 114.13645675977091,
          "y": 606.2734686734672
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-ZL7rg",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response_4}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-ZL7rg",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 541.4522448186667,
          "y": 1401.1727303314135
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Memory-JxkYD",
          "node": {
            "base_classes": [
              "DataFrame",
              "Message"
            ],
            "beta": false,
            "category": "helpers",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Stores or retrieves stored chat messages from Langflow tables or an external memory.",
            "display_name": "Message History",
            "documentation": "https://docs.langflow.org/components-helpers#message-history",
            "edited": false,
            "field_order": [
              "mode",
              "message",
              "memory",
              "sender_type",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "frozen": false,
            "icon": "message-square-more",
            "key": "Memory",
            "last_updated": "2025-10-22T04:00:15.486Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Stored Messages",
                "group_outputs": false,
                "hidden": true,
                "method": "store_message",
                "name": "stored_messages",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.1676812955549333,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any, cast\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.inputs.inputs import DropdownInput, HandleInput, IntInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.memory import aget_messages, astore_message\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\nfrom langflow.utils.component_utils import set_current_fields, set_field_display\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Message History\"\n    description = \"Stores or retrieves stored chat messages from Langflow tables or an external memory.\"\n    documentation: str = \"https://docs.langflow.org/components-helpers#message-history\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n    default_keys = [\"mode\", \"memory\", \"session_id\"]\n    mode_config = {\n        \"Store\": [\"message\", \"memory\", \"sender\", \"sender_name\", \"session_id\"],\n        \"Retrieve\": [\"n_messages\", \"order\", \"template\", \"memory\", \"session_id\"],\n    }\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Retrieve\", \"Store\"],\n            value=\"Retrieve\",\n            info=\"Operation mode: Store messages or Retrieve messages.\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The chat message to be stored.\",\n            tool_mode=True,\n            dynamic=True,\n            show=False,\n        ),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"Memory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender_type\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender\",\n            display_name=\"Sender\",\n            info=\"The sender of the message. Might be Machine or User. \"\n            \"If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            value=\"\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n            tool_mode=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Message\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True),\n        Output(display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True),\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"mode\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n            if field_value == \"Store\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Stored Messages\",\n                        name=\"stored_messages\",\n                        method=\"store_message\",\n                        hidden=True,\n                        dynamic=True,\n                    )\n                ]\n            if field_value == \"Retrieve\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Messages\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True\n                    ),\n                    Output(\n                        display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True\n                    ),\n                ]\n        return frontend_node\n\n    async def store_message(self) -> Message:\n        message = Message(text=self.message) if isinstance(self.message, str) else self.message\n\n        message.session_id = self.session_id or message.session_id\n        message.sender = self.sender or message.sender or MESSAGE_SENDER_AI\n        message.sender_name = self.sender_name or message.sender_name or MESSAGE_SENDER_NAME_AI\n\n        stored_messages: list[Message] = []\n\n        if self.memory:\n            self.memory.session_id = message.session_id\n            lc_message = message.to_lc_message()\n            await self.memory.aadd_messages([lc_message])\n\n            stored_messages = await self.memory.aget_messages() or []\n\n            stored_messages = [Message.from_lc_message(m) for m in stored_messages] if stored_messages else []\n\n            if message.sender:\n                stored_messages = [m for m in stored_messages if m.sender == message.sender]\n        else:\n            await astore_message(message, flow_id=self.graph.flow_id)\n            stored_messages = (\n                await aget_messages(\n                    session_id=message.session_id, sender_name=message.sender_name, sender=message.sender\n                )\n                or []\n            )\n\n        if not stored_messages:\n            msg = \"No messages were stored. Please ensure that the session ID and sender are properly set.\"\n            raise ValueError(msg)\n\n        stored_message = stored_messages[0]\n        self.status = stored_message\n        return stored_message\n\n    async def retrieve_messages(self) -> Data:\n        sender_type = self.sender_type\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender_type == \"Machine and User\":\n            sender_type = None\n\n        if self.memory and not hasattr(self.memory, \"aget_messages\"):\n            memory_name = type(self.memory).__name__\n            err_msg = f\"External Memory object ({memory_name}) must have 'aget_messages' method.\"\n            raise AttributeError(err_msg)\n        # Check if n_messages is None or 0\n        if n_messages == 0:\n            stored = []\n        elif self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = await self.memory.aget_messages()\n            # langchain memories are supposed to return messages in ascending order\n\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages first\n\n            if order == \"DESC\":\n                stored = stored[::-1]  # Then reverse if needed\n\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender_type:\n                expected_type = MESSAGE_SENDER_AI if sender_type == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            # For internal memory, we always fetch the last N messages by ordering by DESC\n            stored = await aget_messages(\n                sender=sender_type,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=10000,\n                order=order,\n            )\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages\n\n        # self.status = stored\n        return cast(\"Data\", stored)\n\n    async def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, await self.retrieve_messages())\n        # self.status = stored_text\n        return Message(text=stored_text)\n\n    async def retrieve_messages_dataframe(self) -> DataFrame:\n        \"\"\"Convert the retrieved messages into a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the message data.\n        \"\"\"\n        messages = await self.retrieve_messages()\n        return DataFrame(messages)\n\n    def update_build_config(\n        self,\n        build_config: dotdict,\n        field_value: Any,  # noqa: ARG002\n        field_name: str | None = None,  # noqa: ARG002\n    ) -> dotdict:\n        return set_current_fields(\n            build_config=build_config,\n            action_fields=self.mode_config,\n            selected_action=build_config[\"mode\"][\"value\"],\n            default_fields=self.default_keys,\n            func=set_field_display,\n        )\n"
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "message": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": true,
                "info": "The chat message to be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Operation mode: Store messages or Retrieve messages.",
                "name": "mode",
                "options": [
                  "Retrieve",
                  "Store"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Store"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "external_options": {},
                "info": "Order of the messages.",
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": true,
                "show": false,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Sender",
                "dynamic": false,
                "info": "The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Qwen3"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Qwen3"
              },
              "sender_type": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Filter by sender type.",
                "name": "sender_type",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              }
            },
            "tool_mode": false
          },
          "selected_output": "messages_text",
          "showNode": true,
          "type": "Memory"
        },
        "dragging": false,
        "id": "Memory-JxkYD",
        "measured": {
          "height": 704,
          "width": 320
        },
        "position": {
          "x": 527.6678645587024,
          "y": 606.2734686734668
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-Lw8Y0",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response_5}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-Lw8Y0",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 938.9018756476398,
          "y": 1391.9831434914372
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Memory-so4FG",
          "node": {
            "base_classes": [
              "DataFrame",
              "Message"
            ],
            "beta": false,
            "category": "helpers",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Stores or retrieves stored chat messages from Langflow tables or an external memory.",
            "display_name": "Message History",
            "documentation": "https://docs.langflow.org/components-helpers#message-history",
            "edited": false,
            "field_order": [
              "mode",
              "message",
              "memory",
              "sender_type",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "frozen": false,
            "icon": "message-square-more",
            "key": "Memory",
            "last_updated": "2025-10-22T04:00:15.486Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Stored Messages",
                "group_outputs": false,
                "hidden": true,
                "method": "store_message",
                "name": "stored_messages",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.1676812955549333,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any, cast\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.inputs.inputs import DropdownInput, HandleInput, IntInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.memory import aget_messages, astore_message\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\nfrom langflow.utils.component_utils import set_current_fields, set_field_display\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Message History\"\n    description = \"Stores or retrieves stored chat messages from Langflow tables or an external memory.\"\n    documentation: str = \"https://docs.langflow.org/components-helpers#message-history\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n    default_keys = [\"mode\", \"memory\", \"session_id\"]\n    mode_config = {\n        \"Store\": [\"message\", \"memory\", \"sender\", \"sender_name\", \"session_id\"],\n        \"Retrieve\": [\"n_messages\", \"order\", \"template\", \"memory\", \"session_id\"],\n    }\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Retrieve\", \"Store\"],\n            value=\"Retrieve\",\n            info=\"Operation mode: Store messages or Retrieve messages.\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The chat message to be stored.\",\n            tool_mode=True,\n            dynamic=True,\n            show=False,\n        ),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"Memory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender_type\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender\",\n            display_name=\"Sender\",\n            info=\"The sender of the message. Might be Machine or User. \"\n            \"If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            value=\"\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n            tool_mode=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Message\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True),\n        Output(display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True),\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"mode\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n            if field_value == \"Store\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Stored Messages\",\n                        name=\"stored_messages\",\n                        method=\"store_message\",\n                        hidden=True,\n                        dynamic=True,\n                    )\n                ]\n            if field_value == \"Retrieve\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Messages\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True\n                    ),\n                    Output(\n                        display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True\n                    ),\n                ]\n        return frontend_node\n\n    async def store_message(self) -> Message:\n        message = Message(text=self.message) if isinstance(self.message, str) else self.message\n\n        message.session_id = self.session_id or message.session_id\n        message.sender = self.sender or message.sender or MESSAGE_SENDER_AI\n        message.sender_name = self.sender_name or message.sender_name or MESSAGE_SENDER_NAME_AI\n\n        stored_messages: list[Message] = []\n\n        if self.memory:\n            self.memory.session_id = message.session_id\n            lc_message = message.to_lc_message()\n            await self.memory.aadd_messages([lc_message])\n\n            stored_messages = await self.memory.aget_messages() or []\n\n            stored_messages = [Message.from_lc_message(m) for m in stored_messages] if stored_messages else []\n\n            if message.sender:\n                stored_messages = [m for m in stored_messages if m.sender == message.sender]\n        else:\n            await astore_message(message, flow_id=self.graph.flow_id)\n            stored_messages = (\n                await aget_messages(\n                    session_id=message.session_id, sender_name=message.sender_name, sender=message.sender\n                )\n                or []\n            )\n\n        if not stored_messages:\n            msg = \"No messages were stored. Please ensure that the session ID and sender are properly set.\"\n            raise ValueError(msg)\n\n        stored_message = stored_messages[0]\n        self.status = stored_message\n        return stored_message\n\n    async def retrieve_messages(self) -> Data:\n        sender_type = self.sender_type\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender_type == \"Machine and User\":\n            sender_type = None\n\n        if self.memory and not hasattr(self.memory, \"aget_messages\"):\n            memory_name = type(self.memory).__name__\n            err_msg = f\"External Memory object ({memory_name}) must have 'aget_messages' method.\"\n            raise AttributeError(err_msg)\n        # Check if n_messages is None or 0\n        if n_messages == 0:\n            stored = []\n        elif self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = await self.memory.aget_messages()\n            # langchain memories are supposed to return messages in ascending order\n\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages first\n\n            if order == \"DESC\":\n                stored = stored[::-1]  # Then reverse if needed\n\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender_type:\n                expected_type = MESSAGE_SENDER_AI if sender_type == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            # For internal memory, we always fetch the last N messages by ordering by DESC\n            stored = await aget_messages(\n                sender=sender_type,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=10000,\n                order=order,\n            )\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages\n\n        # self.status = stored\n        return cast(\"Data\", stored)\n\n    async def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, await self.retrieve_messages())\n        # self.status = stored_text\n        return Message(text=stored_text)\n\n    async def retrieve_messages_dataframe(self) -> DataFrame:\n        \"\"\"Convert the retrieved messages into a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the message data.\n        \"\"\"\n        messages = await self.retrieve_messages()\n        return DataFrame(messages)\n\n    def update_build_config(\n        self,\n        build_config: dotdict,\n        field_value: Any,  # noqa: ARG002\n        field_name: str | None = None,  # noqa: ARG002\n    ) -> dotdict:\n        return set_current_fields(\n            build_config=build_config,\n            action_fields=self.mode_config,\n            selected_action=build_config[\"mode\"][\"value\"],\n            default_fields=self.default_keys,\n            func=set_field_display,\n        )\n"
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "message": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": true,
                "info": "The chat message to be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Operation mode: Store messages or Retrieve messages.",
                "name": "mode",
                "options": [
                  "Retrieve",
                  "Store"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Store"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "external_options": {},
                "info": "Order of the messages.",
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": true,
                "show": false,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Sender",
                "dynamic": false,
                "info": "The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Qwen3"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Qwen3"
              },
              "sender_type": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Filter by sender type.",
                "name": "sender_type",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              }
            },
            "tool_mode": false
          },
          "selected_output": "messages_text",
          "showNode": true,
          "type": "Memory"
        },
        "dragging": false,
        "id": "Memory-so4FG",
        "measured": {
          "height": 704,
          "width": 320
        },
        "position": {
          "x": 913.6305118377051,
          "y": 610.868262093455
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-w2utj",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response_6}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-w2utj",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 1343.4727113386107,
          "y": 1394.8266962284683
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Memory-laxv0",
          "node": {
            "base_classes": [
              "DataFrame",
              "Message"
            ],
            "beta": false,
            "category": "helpers",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Stores or retrieves stored chat messages from Langflow tables or an external memory.",
            "display_name": "Message History",
            "documentation": "https://docs.langflow.org/components-helpers#message-history",
            "edited": false,
            "field_order": [
              "mode",
              "message",
              "memory",
              "sender_type",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "frozen": false,
            "icon": "message-square-more",
            "key": "Memory",
            "last_updated": "2025-10-22T04:00:15.486Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Stored Messages",
                "group_outputs": false,
                "hidden": true,
                "method": "store_message",
                "name": "stored_messages",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.1676812955549333,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any, cast\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.inputs.inputs import DropdownInput, HandleInput, IntInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.memory import aget_messages, astore_message\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\nfrom langflow.utils.component_utils import set_current_fields, set_field_display\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Message History\"\n    description = \"Stores or retrieves stored chat messages from Langflow tables or an external memory.\"\n    documentation: str = \"https://docs.langflow.org/components-helpers#message-history\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n    default_keys = [\"mode\", \"memory\", \"session_id\"]\n    mode_config = {\n        \"Store\": [\"message\", \"memory\", \"sender\", \"sender_name\", \"session_id\"],\n        \"Retrieve\": [\"n_messages\", \"order\", \"template\", \"memory\", \"session_id\"],\n    }\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Retrieve\", \"Store\"],\n            value=\"Retrieve\",\n            info=\"Operation mode: Store messages or Retrieve messages.\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The chat message to be stored.\",\n            tool_mode=True,\n            dynamic=True,\n            show=False,\n        ),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"Memory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender_type\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender\",\n            display_name=\"Sender\",\n            info=\"The sender of the message. Might be Machine or User. \"\n            \"If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            value=\"\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n            tool_mode=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Message\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True),\n        Output(display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True),\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"mode\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n            if field_value == \"Store\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Stored Messages\",\n                        name=\"stored_messages\",\n                        method=\"store_message\",\n                        hidden=True,\n                        dynamic=True,\n                    )\n                ]\n            if field_value == \"Retrieve\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Messages\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True\n                    ),\n                    Output(\n                        display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True\n                    ),\n                ]\n        return frontend_node\n\n    async def store_message(self) -> Message:\n        message = Message(text=self.message) if isinstance(self.message, str) else self.message\n\n        message.session_id = self.session_id or message.session_id\n        message.sender = self.sender or message.sender or MESSAGE_SENDER_AI\n        message.sender_name = self.sender_name or message.sender_name or MESSAGE_SENDER_NAME_AI\n\n        stored_messages: list[Message] = []\n\n        if self.memory:\n            self.memory.session_id = message.session_id\n            lc_message = message.to_lc_message()\n            await self.memory.aadd_messages([lc_message])\n\n            stored_messages = await self.memory.aget_messages() or []\n\n            stored_messages = [Message.from_lc_message(m) for m in stored_messages] if stored_messages else []\n\n            if message.sender:\n                stored_messages = [m for m in stored_messages if m.sender == message.sender]\n        else:\n            await astore_message(message, flow_id=self.graph.flow_id)\n            stored_messages = (\n                await aget_messages(\n                    session_id=message.session_id, sender_name=message.sender_name, sender=message.sender\n                )\n                or []\n            )\n\n        if not stored_messages:\n            msg = \"No messages were stored. Please ensure that the session ID and sender are properly set.\"\n            raise ValueError(msg)\n\n        stored_message = stored_messages[0]\n        self.status = stored_message\n        return stored_message\n\n    async def retrieve_messages(self) -> Data:\n        sender_type = self.sender_type\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender_type == \"Machine and User\":\n            sender_type = None\n\n        if self.memory and not hasattr(self.memory, \"aget_messages\"):\n            memory_name = type(self.memory).__name__\n            err_msg = f\"External Memory object ({memory_name}) must have 'aget_messages' method.\"\n            raise AttributeError(err_msg)\n        # Check if n_messages is None or 0\n        if n_messages == 0:\n            stored = []\n        elif self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = await self.memory.aget_messages()\n            # langchain memories are supposed to return messages in ascending order\n\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages first\n\n            if order == \"DESC\":\n                stored = stored[::-1]  # Then reverse if needed\n\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender_type:\n                expected_type = MESSAGE_SENDER_AI if sender_type == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            # For internal memory, we always fetch the last N messages by ordering by DESC\n            stored = await aget_messages(\n                sender=sender_type,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=10000,\n                order=order,\n            )\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages\n\n        # self.status = stored\n        return cast(\"Data\", stored)\n\n    async def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, await self.retrieve_messages())\n        # self.status = stored_text\n        return Message(text=stored_text)\n\n    async def retrieve_messages_dataframe(self) -> DataFrame:\n        \"\"\"Convert the retrieved messages into a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the message data.\n        \"\"\"\n        messages = await self.retrieve_messages()\n        return DataFrame(messages)\n\n    def update_build_config(\n        self,\n        build_config: dotdict,\n        field_value: Any,  # noqa: ARG002\n        field_name: str | None = None,  # noqa: ARG002\n    ) -> dotdict:\n        return set_current_fields(\n            build_config=build_config,\n            action_fields=self.mode_config,\n            selected_action=build_config[\"mode\"][\"value\"],\n            default_fields=self.default_keys,\n            func=set_field_display,\n        )\n"
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "message": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": true,
                "info": "The chat message to be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Operation mode: Store messages or Retrieve messages.",
                "name": "mode",
                "options": [
                  "Retrieve",
                  "Store"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Store"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "external_options": {},
                "info": "Order of the messages.",
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": true,
                "show": false,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Sender",
                "dynamic": false,
                "info": "The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Qwen3"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Qwen3"
              },
              "sender_type": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Filter by sender type.",
                "name": "sender_type",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              }
            },
            "tool_mode": false
          },
          "selected_output": "messages_text",
          "showNode": true,
          "type": "Memory"
        },
        "dragging": false,
        "id": "Memory-laxv0",
        "measured": {
          "height": 704,
          "width": 320
        },
        "position": {
          "x": 1348.2925102762192,
          "y": 615.0805412981377
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "RegexExtractorComponent-h1F8N",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extract patterns from text using regular expressions.",
            "display_name": "Regex Extractor",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_text",
              "pattern"
            ],
            "frozen": false,
            "icon": "regex",
            "key": "RegexExtractorComponent",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data",
                "group_outputs": false,
                "method": "extract_matches",
                "name": "data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "group_outputs": false,
                "method": "get_matches_text",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.ParserComponent"
            ],
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.message import Message\n\n\nclass RegexExtractorComponent(Component):\n    display_name = \"Regex Extractor\"\n    description = \"Extract patterns from text using regular expressions.\"\n    icon = \"regex\"\n    legacy = True\n    replacement = [\"processing.ParserComponent\"]\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Input Text\",\n            info=\"The text to analyze\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"pattern\",\n            display_name=\"Regex Pattern\",\n            info=\"The regular expression pattern to match\",\n            value=r\"\",\n            required=True,\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"extract_matches\"),\n        Output(display_name=\"Message\", name=\"text\", method=\"get_matches_text\"),\n    ]\n\n    def extract_matches(self) -> list[Data]:\n        if not self.pattern or not self.input_text:\n            self.status = []\n            return []\n\n        try:\n            # Compile regex pattern\n            pattern = re.compile(self.pattern)\n\n            # Find all matches in the input text\n            matches = pattern.findall(self.input_text)\n\n            # Filter out empty matches\n            filtered_matches = [match for match in matches if match]  # Remove empty matches\n\n            # Return empty list for no matches, or list of matches if found\n            result: list = [] if not filtered_matches else [Data(data={\"match\": match}) for match in filtered_matches]\n\n        except re.error as e:\n            error_message = f\"Invalid regex pattern: {e!s}\"\n            result = [Data(data={\"error\": error_message})]\n        except ValueError as e:\n            error_message = f\"Error extracting matches: {e!s}\"\n            result = [Data(data={\"error\": error_message})]\n\n        self.status = result\n        return result\n\n    def get_matches_text(self) -> Message:\n        \"\"\"Get matches as a formatted text message.\"\"\"\n        matches = self.extract_matches()\n\n        if not matches:\n            message = Message(text=\"No matches found\")\n            self.status = message\n            return message\n\n        if \"error\" in matches[0].data:\n            message = Message(text=matches[0].data[\"error\"])\n            self.status = message\n            return message\n\n        result = \"\\n\".join(match.data[\"match\"] for match in matches)\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input Text",
                "dynamic": false,
                "info": "The text to analyze",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "pattern": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Regex Pattern",
                "dynamic": false,
                "info": "The regular expression pattern to match",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "[^/]+$"
              }
            },
            "tool_mode": false
          },
          "selected_output": "text",
          "showNode": true,
          "type": "RegexExtractorComponent"
        },
        "dragging": false,
        "id": "RegexExtractorComponent-h1F8N",
        "measured": {
          "height": 317,
          "width": 320
        },
        "position": {
          "x": -1751.9053226196552,
          "y": 1220.8743774345537
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-SuEWV",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "Text Input",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextInput",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.00004500241402777085,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "# Program Overview\n\n## 1. Program Overview\n\n* **Program ID**: CWKTSUBC  \n* **Function Description**: The CWKTSUBC program serves as a transaction processing utility within the bank's core banking system, specifically designed to generate summary reports for account subtotals. This program processes transaction data to calculate aggregated values for individual accounts, ensuring accurate financial reporting and compliance with regulatory requirements. The program operates within the HP Non-Stop Tandem environment, leveraging COBOL's robust capabilities for high-volume transaction processing while maintaining data integrity and system reliability.  "
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "id": "TextInput-SuEWV",
        "measured": {
          "height": 215,
          "width": 320
        },
        "position": {
          "x": 3014.737064636134,
          "y": 157.86979503265002
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "MessageToLocalFile-X9sAz",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Saves a LangFlow Message as a local file using extracted Program ID.",
            "display_name": "Message to Local File",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input",
              "output_folder",
              "file_extension"
            ],
            "frozen": false,
            "icon": "file",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Result Message",
                "group_outputs": false,
                "hidden": null,
                "method": "build_output",
                "name": "result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from pathlib import Path\r\nimport re\r\nfrom collections.abc import AsyncIterator, Iterator\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import StrInput, MessageInput, Output\r\nfrom langflow.schema import Message\r\nfrom langflow.inputs import MessageTextInput\r\n\r\n\r\nclass FileBuilderComponent(Component):\r\n    display_name = \"Message to Local File\"\r\n    description = \"Saves a LangFlow Message as a local file using extracted Program ID.\"\r\n    icon = \"file\"\r\n    name = \"MessageToLocalFile\"\r\n\r\n    inputs = [\r\n        MessageInput(\r\n            name=\"input\",\r\n            display_name=\"Input Message\",\r\n            required=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"output_folder\",\r\n            display_name=\"Output Folder\",\r\n            info=\"Folder path to save the file locally.\",\r\n            value=\"/app/data\",\r\n            required=False,\r\n        ),\r\n        StrInput(\r\n            name=\"file_extension\",\r\n            display_name=\"File Extension\",\r\n            info=\"Extension for the saved file (e.g. txt, md, json)\",\r\n            value=\"txt\",\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"Result Message\",\r\n            name=\"result\",\r\n            method=\"build_output\",\r\n        ),\r\n    ]\r\n\r\n    async def build_output(self) -> Message:\r\n        \"\"\"Saves a Message as a local file using the Program ID for naming.\"\"\"\r\n\r\n        message: Message = self.input\r\n        content = self._extract_text(message)\r\n\r\n        program_id = self._extract_program_id(content)\r\n        file_name = f\"Summary_{program_id}.{self.file_extension.lstrip('.')}\"\r\n        # raise ValueError(self.output_folder)\r\n        output_path = Path(self.output_folder) / file_name\r\n\r\n        output_path.parent.mkdir(parents=True, exist_ok=True)\r\n        output_path.write_text(content, encoding=\"utf-8\")\r\n\r\n        return Message(text=f\"✅ File saved locally as '{output_path.resolve()}'.\")\r\n\r\n    def _extract_text(self, message: Message) -> str:\r\n        \"\"\"Extracts text from a Message object.\"\"\"\r\n        if isinstance(message.text, AsyncIterator):\r\n            return \"\".join([str(item async for item in message.text)])\r\n        elif isinstance(message.text, Iterator):\r\n            return \"\".join(str(item) for item in message.text)\r\n        return str(message.text)\r\n\r\n    def _extract_program_id(self, content: str) -> str:\r\n        \"\"\"Extracts the Program ID from the message content.\"\"\"\r\n        lines = content.splitlines()\r\n        if len(lines) >= 3:\r\n            line = lines[2].strip()\r\n            raise ValueError(line)\r\n            match = re.search(r\"\\*\\s+\\*\\*Program ID\\*\\*:\\s*(\\w+)\", line)\r\n            \r\n            if match:\r\n                return match.group(1)\r\n        raise ValueError(\"Could not extract Program ID from message content.\")\r\n"
              },
              "file_extension": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "File Extension",
                "dynamic": false,
                "info": "Extension for the saved file (e.g. txt, md, json)",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "file_extension",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "md"
              },
              "input": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input Message",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "output_folder": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Output Folder",
                "dynamic": false,
                "info": "Folder path to save the file locally.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_folder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "/data/projects/cobol-test/Cobol_Summary_Gen/Output"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "MessageToLocalFile"
        },
        "dragging": false,
        "id": "MessageToLocalFile-X9sAz",
        "measured": {
          "height": 305,
          "width": 320
        },
        "position": {
          "x": 3455.449893841746,
          "y": 384.2936968607597
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConcatDataFrame-PCzAc",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Concatenate all columns of a single-row DataFrame into one text message separated by double newlines.",
            "display_name": "Concatenate DataFrame",
            "documentation": "",
            "edited": true,
            "field_order": [
              "dataframe",
              "destination_dir_msg",
              "original_dir_msg"
            ],
            "frozen": false,
            "icon": "table",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Concatenated data",
                "group_outputs": false,
                "hidden": null,
                "method": "concat_dataframe",
                "name": "concatenated_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\r\nfrom langflow.io import DataFrameInput, Output\r\nfrom langflow.schema.message import Message\r\nfrom langflow.schema.data import Data\r\n\r\n\r\nclass ConcatDataFrameComponent(Component):\r\n    display_name = \"Concatenate DataFrame\"\r\n    description = \"Concatenate all columns of a single-row DataFrame into one text message separated by double newlines.\"\r\n    icon = \"table\"\r\n    name = \"ConcatDataFrame\"\r\n    legacy: bool = True\r\n\r\n    inputs = [\r\n        DataFrameInput(\r\n            name=\"dataframe\",\r\n            display_name=\"Input DataFrame\",\r\n            info=\"A Langflow DataFrame with exactly one row to concatenate its columns.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"destination_dir_msg\",\r\n            display_name=\"Destination Directory Message\",\r\n            info=\"Message whose text is the destination directory path\"\r\n        ),\r\n        MessageTextInput(\r\n            name=\"original_dir_msg\",\r\n            display_name=\"Original Directory Message\",\r\n            info=\"Message whose text is the destination directory path\"\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"Concatenated data\",\r\n            name=\"concatenated_data\",\r\n            method=\"concat_dataframe\",\r\n        ),\r\n    ]\r\n\r\n    def concat_dataframe(self) -> Data:\r\n        # Convert Langflow DataFrameInput to pandas DataFrame\r\n        # raise ValueError(self.dataframe['model_response_6'])\r\n        df = self.dataframe\r\n\r\n        # Validate single-row condition\r\n        if df.shape[0] != 1:\r\n            raise ValueError(\"Input DataFrame must have exactly one row.\")\r\n        \r\n        # Concatenate selected columns with double newlines\r\n        selected_cols = ['model_response_1', 'model_response_2', 'model_response_3', 'model_response_4', 'model_response_5', 'model_response_6']\r\n        row = next(df.iterrows())[1]  # (index, Series-like row)\r\n        # raise ValueError(row)\r\n        concatenated_text = \"\\n\\n\".join(str(row[col]) for col in selected_cols)\r\n        \r\n        # Move thte file to Competed folder\r\n        # file_name = str(row['File_name'])\r\n        file_path = str(row['File_name'])\r\n        \r\n        # Ensure destination exists\r\n        destination_dir = self.destination_dir_msg\r\n        original_dir = self.original_dir_msg\r\n        try:\r\n            os.makedirs(destination_dir, exist_ok=True)\r\n        except Exception as e:\r\n            return Message(text=f\"❌ Failed to create destination directory '{destination_dir}': {e}\")\r\n\r\n        # Compute destination path\r\n        file_name = os.path.basename(file_path)\r\n        # file_path = os.path.join(original_dir, file_name)\r\n        new_path = os.path.join(destination_dir, file_name)\r\n        \r\n        \r\n        # Attempt move\r\n        try:\r\n            shutil.move(file_path, new_path)\r\n            # return Message(text=f\"✅ File moved to: {new_path}\")\r\n        except FileNotFoundError:\r\n            return Message(text=f\"❌ File not found: {file_path}\")\r\n        except Exception as e:\r\n            return Message(text=f\"❌ Error moving file: {e}\")\r\n\r\n        # Optionally update component status in UI\r\n        self.status = concatenated_text\r\n\r\n        # Return as Langflow Message\r\n        concatenated_data = {'file_name':file_name, 'concat_text' : concatenated_text}\r\n        return Data(data=concatenated_data)\r\n"
              },
              "dataframe": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "Input DataFrame",
                "dynamic": false,
                "info": "A Langflow DataFrame with exactly one row to concatenate its columns.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "dataframe",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "destination_dir_msg": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Destination Directory Message",
                "dynamic": false,
                "info": "Message whose text is the destination directory path",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "destination_dir_msg",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "original_dir_msg": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Original Directory Message",
                "dynamic": false,
                "info": "Message whose text is the destination directory path",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "original_dir_msg",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConcatDataFrame"
        },
        "dragging": false,
        "id": "ConcatDataFrame-PCzAc",
        "measured": {
          "height": 445,
          "width": 320
        },
        "position": {
          "x": 1835.6074460917616,
          "y": 1897.3330175341123
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-40JUD",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "file_name"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "file_name": {
                "advanced": false,
                "display_name": "file_name",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "file_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "/data/projects/cobol-test/Cobol_Summary_Gen/Input/DFSIVP34.txt"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "By analyzing {file_name} in knowledge base, provide the Program Overview, write no less than 300 words in this session. Generate the Program Overview one time only, do not repeat. Strictly follow the defined Markdown output format below, without omitting any part. Do not need to show the word count.\n\n## 1. Program Overview\n\n* **Program ID**: [Extracted from IDENTIFICATION DIVISION]\n* **Function Description**: A concise summary of the program's main business purpose.\n* **Main Processes **: List out all the processes in the cobol program, by looking into the PROCEDURE DIVISION.\n\n------\n\nBy analyzing {file_name} in knowledge base, provide the Flowchart. Use Mermaid syntax to visualize the main execution flow of `PROCEDURE DIVISION`. \nPlease strictly generate the document in the following Markdown structure:\n\n## 2. Flowchart\n```mermaid\ngraph TD\n    A[Start] --> B[Read Input File];\n    B --> C[End of File?];\n    C -- Yes --> D[Close Files];\n    C -- No --> E[Process Record];\n    E --> F[Write to Output File];\n    F --> B;\n    D --> G[End];\n```\n\n------\n\nBy analyzing {file_name} in knowledge base, provide the Input/Output of the code in below md format\n\n## 3. Input/Output\n* **Input**:\n    * `[Input File Name 1]`: [Briefly describe the purpose and key fields of this file].\n    * `[Input File Name 2]`: ...\n\t...\n* **Output**:\n    * `[Output File Name 1]`: [Briefly describe the purpose and generation method of this file].\n    * `[Output File Name 2]`: ...\n\t...\n\n------\n\nBy analyzing {file_name} in knowledge base, provide the Program Structure Analysis of the code in below md format\n\n## 4. Program Structure Analysis\n* **`IDENTIFICATION DIVISION`**: Metadata information of the program, such as author, date, etc.\n* **`ENVIRONMENT DIVISION`**: Describes the program's runtime environment, especially `FILE-CONTROL` related to files.\n* **`DATA DIVISION`**:\n    * **`FILE SECTION`**: Defines input/output files (FD) used by the program and their record layouts.\n    * **`WORKING-STORAGE SECTION`**: Describes key variables, flags, counters, and data structures used internally in the program.\n* **`PROCEDURE DIVISION`**: The core logic of the program, describing major paragraphs and their functions.\n\n------\n\nBy analyzing {file_name} in knowledge base, \nFirst, list out all the functions by looking for the PERFORM (`perform`) in `PROCEDURE DIVISION` in logical order and provide the line no for that function. \nDo not miss out any `perform` in the `PROCEDURE DIVISION`. \nIf the function is calling another sub-function, please list out all the sub-function being called in the main function.\nList all the sub-functions being called as a normal function after all the main function.\nSecond, provide the mermaid flowchart and detailed steps for each function.\nFor both flowcharts and steps, it has to be as detailed as possible to capture all detailed logic of the function. \nDetailed validation rules, default values, error handling must be clearly stated in the steps.\nThe steps have to be in sync with the flowchart. \nWrite no less than 150 words for each function.\nDo not need to generate other section such as overview, flowchart, input/output, Program Structure Analysis. Only need to generate the Detailed Core Logic part.\nprovide the Detailed Core Logic of the code in below md format.\n\n## 5. Detailed Core Logic\n\n* **Function List**:\n    * `[Function 1]`: From Line [150] to line [200]. [Function 1] is calling [Sub-function 1]\n    * `[Function 2]`: From Line [205] to line [249].\n\t* `[Sub-function 1]`: From Line [833] to line [892]. [Sub-function 1] is calling [Sub-function 2]\n\t* `[Sub-function 2]`: From Line [916] to line [990].\n\t...\n\t\n* **`[Function 1]`**: \n\t```mermaid\n\tgraph TD\n\t\tflowchart for Function 1\n\t```\n    * [Step 1, describe the first step of Function 1 in detail]\n\t* [Step 2, describe the second step of Function 1 in detail]\n\t...\n\n* **`[Function 2]`**: \n\t```mermaid\n\tgraph TD\n\t\tflowchart for Function 2\n\t```\n    * [Step 1, describe the first step of Function 2 in detail]\n\t* [Step 2, describe the second step of Function 2 in detail]\n\t...\n...\n\n------\n\nBy analyzing {file_name} in knowledge base, provide the Dependencies of the code in below md format, list out all the copybooks and called program, do not miss out one of it.\nFor Copybooks, please look for the `COPY` statements in the code.\nFor Called Program, please look for the `CALL` statements in the code.\n\n## 6. Dependencies\n  * **Copybooks**:\n      * `[COPY 'COPYBOOK1.CPY']`: [Briefly explain the purpose of this copybook, e.g., record definitions].\n\t  * `[COPY 'COPYBOOK2.CPY']`: [Briefly explain the purpose of this copybook, e.g., record definitions].\n\t  ...\n  * **Called Programs**:\n      * `[CALL 'SUBPROG1']`: [Briefly explain the purpose of calling this subroutine].\n\t  * `[CALL 'SUBPROG2']`: [Briefly explain the purpose of calling this subroutine].\n\t  ...\n\n------\n{file_name}\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-40JUD",
        "measured": {
          "height": 378,
          "width": 320
        },
        "position": {
          "x": -1739.9789676178768,
          "y": 2834.6760230973255
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SplitMessageToQueryData-zMTZu",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Splits a Message text by '------' and outputs a Data object with keys 'Query1', 'Query2', etc.",
            "display_name": "Split Message to Query Data",
            "documentation": "",
            "edited": true,
            "field_order": [
              "message"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Query Data",
                "group_outputs": false,
                "hidden": null,
                "method": "split_message_to_data",
                "name": "query_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\r\nfrom langflow.inputs.inputs import HandleInput\r\nfrom langflow.io import Output\r\nfrom langflow.schema.message import Message\r\nfrom langflow.schema.data import Data\r\n\r\n\r\nclass SplitMessageToQueryDataComponent(Component):\r\n    display_name = \"Split Message to Query Data\"\r\n    description = \"Splits a Message text by '------' and outputs a Data object with keys 'Query1', 'Query2', etc.\"\r\n    name = \"SplitMessageToQueryData\"\r\n    icon = \"split\"\r\n    legacy = True\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"message\",\r\n            display_name=\"Input Message\",\r\n            input_types=[\"Message\"],\r\n            info=\"The message whose text will be split by '------'.\",\r\n            required=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"Query Data\",\r\n            name=\"query_data\",\r\n            method=\"split_message_to_data\",\r\n        ),\r\n    ]\r\n\r\n    def split_message_to_data(self) -> Data:\r\n        # Ensure valid Message input\r\n        if not isinstance(self.message, Message):\r\n            raise ValueError(\"Input must be a Langflow Message.\")\r\n\r\n        text = (self.message.text or \"\").strip()\r\n        if not text:\r\n            raise ValueError(\"Message text is empty.\")\r\n\r\n        # Split by delimiter and clean whitespace\r\n        split_items = [chunk.strip() for chunk in text.split(\"------\") if chunk.strip()]\r\n\r\n        if not split_items:\r\n            raise ValueError(\"No valid content found after splitting by '------'.\")\r\n\r\n        # Build dictionary with Query1, Query2, ...\r\n        data_dict = {f\"Query{i+1}\": chunk for i, chunk in enumerate(split_items)}\r\n\r\n        # Wrap in Langflow Data object\r\n        data_obj = Data(data=data_dict)\r\n\r\n        # Update component status in UI\r\n        self.status = f\"Created Data with {len(split_items)} queries.\"\r\n        \r\n        \r\n\r\n        return data_obj\r\n"
              },
              "message": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input Message",
                "dynamic": false,
                "info": "The message whose text will be split by '------'.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "message",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SplitMessageToQueryData"
        },
        "dragging": false,
        "id": "SplitMessageToQueryData-zMTZu",
        "measured": {
          "height": 262,
          "width": 320
        },
        "position": {
          "x": -1048.3770730784986,
          "y": 2670.434570880729
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DataOperations-7E3hs",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Perform various operations on a Data object.",
            "display_name": "Data Operations",
            "documentation": "https://docs.langflow.org/components-processing#data-operations",
            "edited": false,
            "field_order": [
              "data",
              "operations",
              "select_keys_input",
              "filter_key",
              "operator",
              "filter_values",
              "append_update_data",
              "remove_keys_input",
              "rename_keys_input"
            ],
            "frozen": false,
            "icon": "file-json",
            "last_updated": "2026-02-02T03:24:49.119Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {
              "keywords": [
                "data",
                "operations",
                "filter values",
                "Append or Update",
                "remove keys",
                "rename keys",
                "select keys",
                "literal eval",
                "combine",
                "filter",
                "append",
                "update",
                "remove",
                "rename",
                "data operations",
                "data manipulation",
                "data transformation",
                "data filtering",
                "data selection",
                "data combination"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data",
                "group_outputs": false,
                "loop_types": null,
                "method": "as_data",
                "name": "data_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "ce767eeb-d198-4f14-b5a1-2ec08b22b1ec"
              },
              "_frontend_node_folder_id": {
                "value": "ad4db6bf-94a7-4138-978a-b55a38dc9cf4"
              },
              "_type": "Component",
              "append_update_data": {
                "_input_type": "DictInput",
                "advanced": false,
                "display_name": "Append or Update",
                "dynamic": false,
                "info": "Data to Append or Updatethe existing data with.",
                "list": true,
                "list_add_label": "Add More",
                "name": "append_update_data",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {
                  "key": "value"
                }
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import ast\nfrom typing import TYPE_CHECKING, Any\n\nfrom langflow.custom import Component\nfrom langflow.inputs import DictInput, DropdownInput, MessageTextInput, SortableListInput\nfrom langflow.io import DataInput, Output\nfrom langflow.logging import logger\nfrom langflow.schema import Data\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.utils.component_utils import set_current_fields, set_field_display\n\nif TYPE_CHECKING:\n    from collections.abc import Callable\n\nACTION_CONFIG = {\n    \"Select Keys\": {\"is_list\": False, \"log_msg\": \"setting filter fields\"},\n    \"Literal Eval\": {\"is_list\": False, \"log_msg\": \"setting evaluate fields\"},\n    \"Combine\": {\"is_list\": True, \"log_msg\": \"setting combine fields\"},\n    \"Filter Values\": {\"is_list\": False, \"log_msg\": \"setting filter values fields\"},\n    \"Append or Update\": {\"is_list\": False, \"log_msg\": \"setting Append or Update fields\"},\n    \"Remove Keys\": {\"is_list\": False, \"log_msg\": \"setting remove keys fields\"},\n    \"Rename Keys\": {\"is_list\": False, \"log_msg\": \"setting rename keys fields\"},\n}\nOPERATORS = {\n    \"equals\": lambda a, b: str(a) == str(b),\n    \"not equals\": lambda a, b: str(a) != str(b),\n    \"contains\": lambda a, b: str(b) in str(a),\n    \"starts with\": lambda a, b: str(a).startswith(str(b)),\n    \"ends with\": lambda a, b: str(a).endswith(str(b)),\n}\n\n\nclass DataOperationsComponent(Component):\n    display_name = \"Data Operations\"\n    description = \"Perform various operations on a Data object.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#data-operations\"\n    icon = \"file-json\"\n    name = \"DataOperations\"\n    default_keys = [\"operations\", \"data\"]\n    metadata = {\n        \"keywords\": [\n            \"data\",\n            \"operations\",\n            \"filter values\",\n            \"Append or Update\",\n            \"remove keys\",\n            \"rename keys\",\n            \"select keys\",\n            \"literal eval\",\n            \"combine\",\n            \"filter\",\n            \"append\",\n            \"update\",\n            \"remove\",\n            \"rename\",\n            \"data operations\",\n            \"data manipulation\",\n            \"data transformation\",\n            \"data filtering\",\n            \"data selection\",\n            \"data combination\",\n        ],\n    }\n    actions_data = {\n        \"Select Keys\": [\"select_keys_input\", \"operations\"],\n        \"Literal Eval\": [],\n        \"Combine\": [],\n        \"Filter Values\": [\"filter_values\", \"operations\", \"operator\", \"filter_key\"],\n        \"Append or Update\": [\"append_update_data\", \"operations\"],\n        \"Remove Keys\": [\"remove_keys_input\", \"operations\"],\n        \"Rename Keys\": [\"rename_keys_input\", \"operations\"],\n    }\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"Data object to filter.\", required=True, is_list=True),\n        SortableListInput(\n            name=\"operations\",\n            display_name=\"Operations\",\n            placeholder=\"Select Operation\",\n            info=\"List of operations to perform on the data.\",\n            options=[\n                {\"name\": \"Select Keys\", \"icon\": \"lasso-select\"},\n                {\"name\": \"Literal Eval\", \"icon\": \"braces\"},\n                {\"name\": \"Combine\", \"icon\": \"merge\"},\n                {\"name\": \"Filter Values\", \"icon\": \"filter\"},\n                {\"name\": \"Append or Update\", \"icon\": \"circle-plus\"},\n                {\"name\": \"Remove Keys\", \"icon\": \"eraser\"},\n                {\"name\": \"Rename Keys\", \"icon\": \"pencil-line\"},\n            ],\n            real_time_refresh=True,\n            limit=1,\n        ),\n        # select keys inputs\n        MessageTextInput(\n            name=\"select_keys_input\",\n            display_name=\"Select Keys\",\n            info=\"List of keys to select from the data.\",\n            show=False,\n            is_list=True,\n        ),\n        # filter values inputs\n        MessageTextInput(\n            name=\"filter_key\",\n            display_name=\"Filter Key\",\n            info=\"Key to filter by.\",\n            is_list=True,\n            show=False,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Comparison Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\"],\n            info=\"The operator to apply for comparing the values.\",\n            value=\"equals\",\n            advanced=False,\n            show=False,\n        ),\n        DictInput(\n            name=\"filter_values\",\n            display_name=\"Filter Values\",\n            info=\"List of values to filter by.\",\n            show=False,\n            is_list=True,\n        ),\n        # update/ Append data inputs\n        DictInput(\n            name=\"append_update_data\",\n            display_name=\"Append or Update\",\n            info=\"Data to Append or Updatethe existing data with.\",\n            show=False,\n            value={\"key\": \"value\"},\n            is_list=True,\n        ),\n        # remove keys inputs\n        MessageTextInput(\n            name=\"remove_keys_input\",\n            display_name=\"Remove Keys\",\n            info=\"List of keys to remove from the data.\",\n            show=False,\n            is_list=True,\n        ),\n        # rename keys inputs\n        DictInput(\n            name=\"rename_keys_input\",\n            display_name=\"Rename Keys\",\n            info=\"List of keys to rename in the data.\",\n            show=False,\n            is_list=True,\n            value={\"old_key\": \"new_key\"},\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Data\", name=\"data_output\", method=\"as_data\"),\n    ]\n\n    # Helper methods for data operations\n    def get_data_dict(self) -> dict:\n        \"\"\"Extract data dictionary from Data object.\"\"\"\n        # TODO: rasie error if it s list of data objects\n        data = self.data[0] if isinstance(self.data, list) and len(self.data) == 1 else self.data\n        return data.model_dump()\n\n    def get_normalized_data(self) -> dict:\n        \"\"\"Get normalized data dictionary, handling the 'data' key if present.\"\"\"\n        data_dict = self.get_data_dict()\n        return data_dict.get(\"data\", data_dict)\n\n    def data_is_list(self) -> bool:\n        \"\"\"Check if data contains multiple items.\"\"\"\n        return isinstance(self.data, list) and len(self.data) > 1\n\n    def validate_single_data(self, operation: str) -> None:\n        \"\"\"Validate that the operation is being performed on a single data object.\"\"\"\n        if self.data_is_list():\n            msg = f\"{operation} operation is not supported for multiple data objects.\"\n            raise ValueError(msg)\n\n    def operation_exception(self, operations: list[str]) -> None:\n        \"\"\"Raise exception for incompatible operations.\"\"\"\n        msg = f\"{operations} operations are not supported in combination with each other.\"\n        raise ValueError(msg)\n\n    # Data transformation operations\n    def select_keys(self, *, evaluate: bool | None = None) -> Data:\n        \"\"\"Select specific keys from the data dictionary.\"\"\"\n        self.validate_single_data(\"Select Keys\")\n        data_dict = self.get_normalized_data()\n        filter_criteria: list[str] = self.select_keys_input\n\n        # Filter the data\n        if len(filter_criteria) == 1 and filter_criteria[0] == \"data\":\n            filtered = data_dict[\"data\"]\n        else:\n            if not all(key in data_dict for key in filter_criteria):\n                msg = f\"Select key not found in data. Available keys: {list(data_dict.keys())}\"\n                raise ValueError(msg)\n            filtered = {key: value for key, value in data_dict.items() if key in filter_criteria}\n\n        # Create a new Data object with the filtered data\n        if evaluate:\n            filtered = self.recursive_eval(filtered)\n\n        # Return a new Data object with the filtered data directly in the data attribute\n        return Data(data=filtered)\n\n    def remove_keys(self) -> Data:\n        \"\"\"Remove specified keys from the data dictionary.\"\"\"\n        self.validate_single_data(\"Remove Keys\")\n        data_dict = self.get_normalized_data()\n        remove_keys_input: list[str] = self.remove_keys_input\n\n        for key in remove_keys_input:\n            if key in data_dict:\n                data_dict.pop(key)\n            else:\n                logger.warning(f\"Key '{key}' not found in data. Skipping removal.\")\n\n        return Data(**data_dict)\n\n    def rename_keys(self) -> Data:\n        \"\"\"Rename keys in the data dictionary.\"\"\"\n        self.validate_single_data(\"Rename Keys\")\n        data_dict = self.get_normalized_data()\n        rename_keys_input: dict[str, str] = self.rename_keys_input\n\n        for old_key, new_key in rename_keys_input.items():\n            if old_key in data_dict:\n                data_dict[new_key] = data_dict[old_key]\n                data_dict.pop(old_key)\n            else:\n                msg = f\"Key '{old_key}' not found in data. Skipping rename.\"\n                raise ValueError(msg)\n\n        return Data(**data_dict)\n\n    def recursive_eval(self, data: Any) -> Any:\n        \"\"\"Recursively evaluate string values in a dictionary or list.\n\n        If the value is a string that can be evaluated, it will be evaluated.\n        Otherwise, the original value is returned.\n        \"\"\"\n        if isinstance(data, dict):\n            return {k: self.recursive_eval(v) for k, v in data.items()}\n        if isinstance(data, list):\n            return [self.recursive_eval(item) for item in data]\n        if isinstance(data, str):\n            try:\n                # Only attempt to evaluate strings that look like Python literals\n                if (\n                    data.strip().startswith((\"{\", \"[\", \"(\", \"'\", '\"'))\n                    or data.strip().lower() in (\"true\", \"false\", \"none\")\n                    or data.strip().replace(\".\", \"\").isdigit()\n                ):\n                    return ast.literal_eval(data)\n                # return data\n            except (ValueError, SyntaxError, TypeError, MemoryError):\n                # If evaluation fails for any reason, return the original string\n                return data\n            else:\n                return data\n        return data\n\n    def evaluate_data(self) -> Data:\n        \"\"\"Evaluate string values in the data dictionary.\"\"\"\n        self.validate_single_data(\"Literal Eval\")\n        logger.info(\"evaluating data\")\n        return Data(**self.recursive_eval(self.get_data_dict()))\n\n    def combine_data(self, *, evaluate: bool | None = None) -> Data:\n        \"\"\"Combine multiple data objects into one.\"\"\"\n        logger.info(\"combining data\")\n        if not self.data_is_list():\n            return self.data[0] if self.data else Data(data={})\n\n        if len(self.data) == 1:\n            msg = \"Combine operation requires multiple data inputs.\"\n            raise ValueError(msg)\n\n        data_dicts = [data.model_dump().get(\"data\", data.model_dump()) for data in self.data]\n        combined_data = {}\n\n        for data_dict in data_dicts:\n            for key, value in data_dict.items():\n                if key not in combined_data:\n                    combined_data[key] = value\n                elif isinstance(combined_data[key], list):\n                    if isinstance(value, list):\n                        combined_data[key].extend(value)\n                    else:\n                        combined_data[key].append(value)\n                else:\n                    # If current value is not a list, convert it to list and add new value\n                    combined_data[key] = (\n                        [combined_data[key], value] if not isinstance(value, list) else [combined_data[key], *value]\n                    )\n\n        if evaluate:\n            combined_data = self.recursive_eval(combined_data)\n\n        return Data(**combined_data)\n\n    def compare_values(self, item_value: Any, filter_value: str, operator: str) -> bool:\n        \"\"\"Compare values based on the specified operator.\"\"\"\n        comparison_func = OPERATORS.get(operator)\n        if comparison_func:\n            return comparison_func(item_value, filter_value)\n        return False\n\n    def filter_data(self, input_data: list[dict[str, Any]], filter_key: str, filter_value: str, operator: str) -> list:\n        \"\"\"Filter list data based on key, value, and operator.\"\"\"\n        # Validate inputs\n        if not input_data:\n            self.status = \"Input data is empty.\"\n            return []\n\n        if not filter_key or not filter_value:\n            self.status = \"Filter key or value is missing.\"\n            return input_data\n\n        # Filter the data\n        filtered_data = []\n        for item in input_data:\n            if isinstance(item, dict) and filter_key in item:\n                if self.compare_values(item[filter_key], filter_value, operator):\n                    filtered_data.append(item)\n            else:\n                self.status = f\"Warning: Some items don't have the key '{filter_key}' or are not dictionaries.\"\n\n        return filtered_data\n\n    def multi_filter_data(self) -> Data:\n        \"\"\"Apply multiple filters to the data.\"\"\"\n        self.validate_single_data(\"Filter Values\")\n        data_filtered = self.get_normalized_data()\n\n        for filter_key in self.filter_key:\n            if filter_key not in data_filtered:\n                msg = f\"Filter key '{filter_key}' not found in data. Available keys: {list(data_filtered.keys())}\"\n                raise ValueError(msg)\n\n            if isinstance(data_filtered[filter_key], list):\n                for filter_data in self.filter_values:\n                    filter_value = self.filter_values.get(filter_data)\n                    if filter_value is not None:\n                        data_filtered[filter_key] = self.filter_data(\n                            input_data=data_filtered[filter_key],\n                            filter_key=filter_data,\n                            filter_value=filter_value,\n                            operator=self.operator,\n                        )\n            else:\n                msg = f\"Filter key '{filter_key}' is not a list.\"\n                raise TypeError(msg)\n\n        return Data(**data_filtered)\n\n    def append_update(self) -> Data:\n        \"\"\"Append or Update with new key-value pairs.\"\"\"\n        self.validate_single_data(\"Append or Update\")\n        data_filtered = self.get_normalized_data()\n\n        for key, value in self.append_update_data.items():\n            data_filtered[key] = value\n\n        return Data(**data_filtered)\n\n    # Configuration and execution methods\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        \"\"\"Update build configuration based on selected action.\"\"\"\n        if field_name != \"operations\":\n            return build_config\n\n        build_config[\"operations\"][\"value\"] = field_value\n        selected_actions = [action[\"name\"] for action in field_value]\n\n        # Handle single action case\n        if len(selected_actions) == 1 and selected_actions[0] in ACTION_CONFIG:\n            action = selected_actions[0]\n            config = ACTION_CONFIG[action]\n\n            build_config[\"data\"][\"is_list\"] = config[\"is_list\"]\n            logger.info(config[\"log_msg\"])\n\n            return set_current_fields(\n                build_config=build_config,\n                action_fields=self.actions_data,\n                selected_action=action,\n                default_fields=self.default_keys,\n                func=set_field_display,\n            )\n\n        # Handle no operations case\n        if not selected_actions:\n            logger.info(\"setting default fields\")\n            return set_current_fields(\n                build_config=build_config,\n                action_fields=self.actions_data,\n                selected_action=None,\n                default_fields=self.default_keys,\n                func=set_field_display,\n            )\n\n        return build_config\n\n    def as_data(self) -> Data:\n        \"\"\"Execute the selected action on the data.\"\"\"\n        if not hasattr(self, \"operations\") or not self.operations:\n            return Data(data={})\n\n        selected_actions = [action[\"name\"] for action in self.operations]\n        logger.info(f\"selected_actions: {selected_actions}\")\n\n        # Only handle single action case for now\n        if len(selected_actions) != 1:\n            return Data(data={})\n\n        action = selected_actions[0]\n\n        # Explicitly type the action_map\n        action_map: dict[str, Callable[[], Data]] = {\n            \"Select Keys\": self.select_keys,\n            \"Literal Eval\": self.evaluate_data,\n            \"Combine\": self.combine_data,\n            \"Filter Values\": self.multi_filter_data,\n            \"Append or Update\": self.append_update,\n            \"Remove Keys\": self.remove_keys,\n            \"Rename Keys\": self.rename_keys,\n        }\n\n        handler: Callable[[], Data] | None = action_map.get(action)\n        if handler:\n            try:\n                return handler()\n            except Exception as e:\n                logger.error(f\"Error executing {action}: {e!s}\")\n                raise\n\n        return Data(data={})\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Data"
                ],
                "is_list": false,
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "filter_key": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Filter Key",
                "dynamic": false,
                "info": "Key to filter by.",
                "input_types": [
                  "Message"
                ],
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "filter_key",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "filter_values": {
                "_input_type": "DictInput",
                "advanced": false,
                "display_name": "Filter Values",
                "dynamic": false,
                "info": "List of values to filter by.",
                "list": true,
                "list_add_label": "Add More",
                "name": "filter_values",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "is_refresh": false,
              "operations": {
                "_input_type": "SortableListInput",
                "advanced": false,
                "display_name": "Operations",
                "dynamic": false,
                "info": "List of operations to perform on the data.",
                "limit": 1,
                "name": "operations",
                "options": [
                  {
                    "icon": "lasso-select",
                    "name": "Select Keys"
                  },
                  {
                    "icon": "braces",
                    "name": "Literal Eval"
                  },
                  {
                    "icon": "merge",
                    "name": "Combine"
                  },
                  {
                    "icon": "filter",
                    "name": "Filter Values"
                  },
                  {
                    "icon": "circle-plus",
                    "name": "Append or Update"
                  },
                  {
                    "icon": "eraser",
                    "name": "Remove Keys"
                  },
                  {
                    "icon": "pencil-line",
                    "name": "Rename Keys"
                  }
                ],
                "placeholder": "Select Operation",
                "real_time_refresh": true,
                "required": false,
                "search_category": [],
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "sortableList",
                "value": [
                  {
                    "chosen": false,
                    "icon": "pencil-line",
                    "name": "Rename Keys",
                    "selected": false
                  }
                ]
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Comparison Operator",
                "dynamic": false,
                "external_options": {},
                "info": "The operator to apply for comparing the values.",
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "equals"
              },
              "remove_keys_input": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Remove Keys",
                "dynamic": false,
                "info": "List of keys to remove from the data.",
                "input_types": [
                  "Message"
                ],
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "remove_keys_input",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "rename_keys_input": {
                "_input_type": "DictInput",
                "advanced": false,
                "display_name": "Rename Keys",
                "dynamic": false,
                "info": "List of keys to rename in the data.",
                "list": true,
                "list_add_label": "Add More",
                "name": "rename_keys_input",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": [
                  {
                    "Query7": "File_name"
                  }
                ]
              },
              "select_keys_input": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Select Keys",
                "dynamic": false,
                "info": "List of keys to select from the data.",
                "input_types": [
                  "Message"
                ],
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "select_keys_input",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DataOperations"
        },
        "dragging": false,
        "id": "DataOperations-7E3hs",
        "measured": {
          "height": 329,
          "width": 320
        },
        "position": {
          "x": -684.9429144251353,
          "y": 2830.892068409558
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 1273.3157338409665,
      "y": 35.38140392961657,
      "zoom": 0.25
    }
  },
  "description": "Design, Develop, Dialogize.",
  "endpoint_name": null,
  "id": "ce767eeb-d198-4f14-b5a1-2ec08b22b1ec",
  "is_component": false,
  "last_tested_version": "1.7.3",
  "name": "Cobol_Summary_11Nov",
  "tags": []
}