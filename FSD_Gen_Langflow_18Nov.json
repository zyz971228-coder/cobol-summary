{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-CoeHK",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "field_1_key",
            "id": "CreateData-3eRdR",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "dict"
          }
        },
        "id": "reactflow__edge-Prompt Template-CoeHK{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-CoeHKœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-CreateData-3eRdR{œfieldNameœ:œfield_1_keyœ,œidœ:œCreateData-3eRdRœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œdictœ}",
        "selected": false,
        "source": "Prompt Template-CoeHK",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-CoeHKœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CreateData-3eRdR",
        "targetHandle": "{œfieldNameœ:œfield_1_keyœ,œidœ:œCreateData-3eRdRœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œdictœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-i1XaW",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "field_2_key",
            "id": "CreateData-3eRdR",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "dict"
          }
        },
        "id": "reactflow__edge-Prompt Template-i1XaW{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-i1XaWœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-CreateData-3eRdR{œfieldNameœ:œfield_2_keyœ,œidœ:œCreateData-3eRdRœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œdictœ}",
        "selected": false,
        "source": "Prompt Template-i1XaW",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-i1XaWœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CreateData-3eRdR",
        "targetHandle": "{œfieldNameœ:œfield_2_keyœ,œidœ:œCreateData-3eRdRœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œdictœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-Fio2j",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "field_3_key",
            "id": "CreateData-3eRdR",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "dict"
          }
        },
        "id": "reactflow__edge-Prompt Template-Fio2j{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-Fio2jœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-CreateData-3eRdR{œfieldNameœ:œfield_3_keyœ,œidœ:œCreateData-3eRdRœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œdictœ}",
        "selected": false,
        "source": "Prompt Template-Fio2j",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-Fio2jœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CreateData-3eRdR",
        "targetHandle": "{œfieldNameœ:œfield_3_keyœ,œidœ:œCreateData-3eRdRœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œdictœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-xh21F",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "field_4_key",
            "id": "CreateData-3eRdR",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "dict"
          }
        },
        "id": "reactflow__edge-Prompt Template-xh21F{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-xh21Fœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-CreateData-3eRdR{œfieldNameœ:œfield_4_keyœ,œidœ:œCreateData-3eRdRœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œdictœ}",
        "selected": false,
        "source": "Prompt Template-xh21F",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-xh21Fœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CreateData-3eRdR",
        "targetHandle": "{œfieldNameœ:œfield_4_keyœ,œidœ:œCreateData-3eRdRœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œdictœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Directory",
            "id": "Directory-1lkTg",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "DataFrameOperations-S8seY",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-Directory-1lkTg{œdataTypeœ:œDirectoryœ,œidœ:œDirectory-1lkTgœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-DataFrameOperations-S8seY{œfieldNameœ:œdfœ,œidœ:œDataFrameOperations-S8seYœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "Directory-1lkTg",
        "sourceHandle": "{œdataTypeœ:œDirectoryœ,œidœ:œDirectory-1lkTgœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "DataFrameOperations-S8seY",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œDataFrameOperations-S8seYœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DataFrameOperations",
            "id": "DataFrameOperations-S8seY",
            "name": "output",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "TypeConverterComponent-lPPTr",
            "inputTypes": [
              "Message",
              "Data",
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-DataFrameOperations-S8seY{œdataTypeœ:œDataFrameOperationsœ,œidœ:œDataFrameOperations-S8seYœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataFrameœ]}-TypeConverterComponent-lPPTr{œfieldNameœ:œinput_dataœ,œidœ:œTypeConverterComponent-lPPTrœ,œinputTypesœ:[œMessageœ,œDataœ,œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "DataFrameOperations-S8seY",
        "sourceHandle": "{œdataTypeœ:œDataFrameOperationsœ,œidœ:œDataFrameOperations-S8seYœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "TypeConverterComponent-lPPTr",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œTypeConverterComponent-lPPTrœ,œinputTypesœ:[œMessageœ,œDataœ,œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-NQK2c",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text1",
            "id": "CombineText-qpcMq",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-NQK2c{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-NQK2cœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-CombineText-qpcMq{œfieldNameœ:œtext1œ,œidœ:œCombineText-qpcMqœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-NQK2c",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-NQK2cœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-qpcMq",
        "targetHandle": "{œfieldNameœ:œtext1œ,œidœ:œCombineText-qpcMqœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RAGFlowChatModel",
            "id": "RAGFlowChatModel-RNPtF",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "model",
            "id": "BatchRunComponent-agd5D",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-RAGFlowChatModel-RNPtF{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-RNPtFœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-BatchRunComponent-agd5D{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-agd5Dœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "RAGFlowChatModel-RNPtF",
        "sourceHandle": "{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-RNPtFœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "BatchRunComponent-agd5D",
        "targetHandle": "{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-agd5Dœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DataToDataFrame",
            "id": "DataToDataFrame-VS3fa",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "BatchRunComponent-agd5D",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-DataToDataFrame-VS3fa{œdataTypeœ:œDataToDataFrameœ,œidœ:œDataToDataFrame-VS3faœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-BatchRunComponent-agd5D{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-agd5Dœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "DataToDataFrame-VS3fa",
        "sourceHandle": "{œdataTypeœ:œDataToDataFrameœ,œidœ:œDataToDataFrame-VS3faœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "BatchRunComponent-agd5D",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-agd5Dœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-yOiBQ",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "BatchRunComponent-agd5D",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-yOiBQ{œdataTypeœ:œTextInputœ,œidœ:œTextInput-yOiBQœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-BatchRunComponent-agd5D{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-agd5Dœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-yOiBQ",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-yOiBQœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "BatchRunComponent-agd5D",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-agd5Dœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-agd5D",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "BatchRunComponent-v2I2a",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-agd5D{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-agd5Dœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-BatchRunComponent-v2I2a{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-v2I2aœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-agd5D",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-agd5Dœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "BatchRunComponent-v2I2a",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-v2I2aœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-v2I2a",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "BatchRunComponent-2B7ke",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-v2I2a{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-v2I2aœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-BatchRunComponent-2B7ke{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-2B7keœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-v2I2a",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-v2I2aœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "BatchRunComponent-2B7ke",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-2B7keœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-2B7ke",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "BatchRunComponent-M53dp",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-2B7ke{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-2B7keœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-BatchRunComponent-M53dp{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-M53dpœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-2B7ke",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-2B7keœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "BatchRunComponent-M53dp",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-M53dpœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RAGFlowChatModel",
            "id": "RAGFlowChatModel-RNPtF",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "model",
            "id": "BatchRunComponent-v2I2a",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-RAGFlowChatModel-RNPtF{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-RNPtFœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-BatchRunComponent-v2I2a{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-v2I2aœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "RAGFlowChatModel-RNPtF",
        "sourceHandle": "{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-RNPtFœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "BatchRunComponent-v2I2a",
        "targetHandle": "{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-v2I2aœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RAGFlowChatModel",
            "id": "RAGFlowChatModel-RNPtF",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "model",
            "id": "BatchRunComponent-2B7ke",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-RAGFlowChatModel-RNPtF{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-RNPtFœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-BatchRunComponent-2B7ke{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-2B7keœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "RAGFlowChatModel-RNPtF",
        "sourceHandle": "{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-RNPtFœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "BatchRunComponent-2B7ke",
        "targetHandle": "{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-2B7keœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RAGFlowChatModel",
            "id": "RAGFlowChatModel-RNPtF",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "model",
            "id": "BatchRunComponent-M53dp",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-RAGFlowChatModel-RNPtF{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-RNPtFœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-BatchRunComponent-M53dp{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-M53dpœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "RAGFlowChatModel-RNPtF",
        "sourceHandle": "{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-RNPtFœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "BatchRunComponent-M53dp",
        "targetHandle": "{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-M53dpœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-yOiBQ",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "BatchRunComponent-v2I2a",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-yOiBQ{œdataTypeœ:œTextInputœ,œidœ:œTextInput-yOiBQœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-BatchRunComponent-v2I2a{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-v2I2aœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-yOiBQ",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-yOiBQœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "BatchRunComponent-v2I2a",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-v2I2aœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-yOiBQ",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "BatchRunComponent-2B7ke",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-yOiBQ{œdataTypeœ:œTextInputœ,œidœ:œTextInput-yOiBQœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-BatchRunComponent-2B7ke{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-2B7keœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-yOiBQ",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-yOiBQœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "BatchRunComponent-2B7ke",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-2B7keœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-yOiBQ",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "BatchRunComponent-M53dp",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-yOiBQ{œdataTypeœ:œTextInputœ,œidœ:œTextInput-yOiBQœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-BatchRunComponent-M53dp{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-M53dpœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-yOiBQ",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-yOiBQœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "BatchRunComponent-M53dp",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-M53dpœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-9bxjG",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text1",
            "id": "CombineText-WjgZh",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-9bxjG{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-9bxjGœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-CombineText-WjgZh{œfieldNameœ:œtext1œ,œidœ:œCombineText-WjgZhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-9bxjG",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-9bxjGœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-WjgZh",
        "targetHandle": "{œfieldNameœ:œtext1œ,œidœ:œCombineText-WjgZhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-UK5tM",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text2",
            "id": "CombineText-WjgZh",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-UK5tM{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-UK5tMœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-CombineText-WjgZh{œfieldNameœ:œtext2œ,œidœ:œCombineText-WjgZhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-UK5tM",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-UK5tMœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-WjgZh",
        "targetHandle": "{œfieldNameœ:œtext2œ,œidœ:œCombineText-WjgZhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-HadYb",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text3",
            "id": "CombineText-WjgZh",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-HadYb{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-HadYbœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-CombineText-WjgZh{œfieldNameœ:œtext3œ,œidœ:œCombineText-WjgZhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-HadYb",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-HadYbœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-WjgZh",
        "targetHandle": "{œfieldNameœ:œtext3œ,œidœ:œCombineText-WjgZhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-90P7C",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text4",
            "id": "CombineText-WjgZh",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-90P7C{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-90P7Cœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-CombineText-WjgZh{œfieldNameœ:œtext4œ,œidœ:œCombineText-WjgZhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-90P7C",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-90P7Cœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-WjgZh",
        "targetHandle": "{œfieldNameœ:œtext4œ,œidœ:œCombineText-WjgZhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CombineText",
            "id": "CombineText-WjgZh",
            "name": "combined_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input",
            "id": "MessageToLocalFile-gKwMk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-CombineText-WjgZh{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-WjgZhœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}-MessageToLocalFile-gKwMk{œfieldNameœ:œinputœ,œidœ:œMessageToLocalFile-gKwMkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "CombineText-WjgZh",
        "sourceHandle": "{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-WjgZhœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MessageToLocalFile-gKwMk",
        "targetHandle": "{œfieldNameœ:œinputœ,œidœ:œMessageToLocalFile-gKwMkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-ByoEB",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "SplitMessageToQueryData-jnuZz",
            "inputTypes": [
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-Prompt Template-ByoEB{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-ByoEBœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-SplitMessageToQueryData-jnuZz{œfieldNameœ:œmessageœ,œidœ:œSplitMessageToQueryData-jnuZzœ,œinputTypesœ:[œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "Prompt Template-ByoEB",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-ByoEBœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "SplitMessageToQueryData-jnuZz",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œSplitMessageToQueryData-jnuZzœ,œinputTypesœ:[œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SplitMessageToQueryData",
            "id": "SplitMessageToQueryData-jnuZz",
            "name": "query_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data_list",
            "id": "DataToDataFrame-VS3fa",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-SplitMessageToQueryData-jnuZz{œdataTypeœ:œSplitMessageToQueryDataœ,œidœ:œSplitMessageToQueryData-jnuZzœ,œnameœ:œquery_dataœ,œoutput_typesœ:[œDataœ]}-DataToDataFrame-VS3fa{œfieldNameœ:œdata_listœ,œidœ:œDataToDataFrame-VS3faœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "SplitMessageToQueryData-jnuZz",
        "sourceHandle": "{œdataTypeœ:œSplitMessageToQueryDataœ,œidœ:œSplitMessageToQueryData-jnuZzœ,œnameœ:œquery_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "DataToDataFrame-VS3fa",
        "targetHandle": "{œfieldNameœ:œdata_listœ,œidœ:œDataToDataFrame-VS3faœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-yOiBQ",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "RAGFlowChatModel-RNPtF",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-yOiBQ{œdataTypeœ:œTextInputœ,œidœ:œTextInput-yOiBQœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-RAGFlowChatModel-RNPtF{œfieldNameœ:œsystem_messageœ,œidœ:œRAGFlowChatModel-RNPtFœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-yOiBQ",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-yOiBQœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "RAGFlowChatModel-RNPtF",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œRAGFlowChatModel-RNPtFœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-M53dp",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "BatchRunComponent-XXTFh",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-M53dp{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-M53dpœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-BatchRunComponent-XXTFh{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-XXTFhœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-M53dp",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-M53dpœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "BatchRunComponent-XXTFh",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-XXTFhœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-XXTFh",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-9bxjG",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-XXTFh{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-XXTFhœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-9bxjG{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-9bxjGœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-XXTFh",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-XXTFhœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-9bxjG",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-9bxjGœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-XXTFh",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-UK5tM",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-XXTFh{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-XXTFhœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-UK5tM{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-UK5tMœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-XXTFh",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-XXTFhœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-UK5tM",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-UK5tMœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-XXTFh",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-HadYb",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-XXTFh{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-XXTFhœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-HadYb{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-HadYbœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-XXTFh",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-XXTFhœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-HadYb",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-HadYbœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-XXTFh",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-90P7C",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-XXTFh{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-XXTFhœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-90P7C{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-90P7Cœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-XXTFh",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-XXTFhœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-90P7C",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-90P7Cœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-XXTFh",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-a6CY9",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-XXTFh{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-XXTFhœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-a6CY9{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-a6CY9œ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-XXTFh",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-XXTFhœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-a6CY9",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-a6CY9œ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RAGFlowChatModel",
            "id": "RAGFlowChatModel-RNPtF",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "model",
            "id": "BatchRunComponent-XXTFh",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-RAGFlowChatModel-RNPtF{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-RNPtFœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-BatchRunComponent-XXTFh{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-XXTFhœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "RAGFlowChatModel-RNPtF",
        "sourceHandle": "{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-RNPtFœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "BatchRunComponent-XXTFh",
        "targetHandle": "{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-XXTFhœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-yOiBQ",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "BatchRunComponent-XXTFh",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-yOiBQ{œdataTypeœ:œTextInputœ,œidœ:œTextInput-yOiBQœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-BatchRunComponent-XXTFh{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-XXTFhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-yOiBQ",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-yOiBQœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "BatchRunComponent-XXTFh",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œBatchRunComponent-XXTFhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SplitMessageToQueryData",
            "id": "SplitMessageToQueryData-jIQQY",
            "name": "query_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data_list",
            "id": "DataToDataFrame-3U1Qo",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-SplitMessageToQueryData-jIQQY{œdataTypeœ:œSplitMessageToQueryDataœ,œidœ:œSplitMessageToQueryData-jIQQYœ,œnameœ:œquery_dataœ,œoutput_typesœ:[œDataœ]}-DataToDataFrame-3U1Qo{œfieldNameœ:œdata_listœ,œidœ:œDataToDataFrame-3U1Qoœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "SplitMessageToQueryData-jIQQY",
        "sourceHandle": "{œdataTypeœ:œSplitMessageToQueryDataœ,œidœ:œSplitMessageToQueryData-jIQQYœ,œnameœ:œquery_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "DataToDataFrame-3U1Qo",
        "targetHandle": "{œfieldNameœ:œdata_listœ,œidœ:œDataToDataFrame-3U1Qoœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DataToDataFrame",
            "id": "DataToDataFrame-3U1Qo",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "LoopComponent-iCfBD",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-DataToDataFrame-3U1Qo{œdataTypeœ:œDataToDataFrameœ,œidœ:œDataToDataFrame-3U1Qoœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-LoopComponent-iCfBD{œfieldNameœ:œdataœ,œidœ:œLoopComponent-iCfBDœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "DataToDataFrame-3U1Qo",
        "sourceHandle": "{œdataTypeœ:œDataToDataFrameœ,œidœ:œDataToDataFrame-3U1Qoœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "LoopComponent-iCfBD",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œLoopComponent-iCfBDœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LoopComponent",
            "id": "LoopComponent-iCfBD",
            "name": "item",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-4RSNH",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-LoopComponent-iCfBD{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-iCfBDœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}-ParserComponent-4RSNH{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-4RSNHœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "LoopComponent-iCfBD",
        "sourceHandle": "{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-iCfBDœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParserComponent-4RSNH",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-4RSNHœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-4RSNH",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "Function_Info",
            "id": "Prompt Template-qG8s0",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-4RSNH{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-4RSNHœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-qG8s0{œfieldNameœ:œFunction_Infoœ,œidœ:œPrompt Template-qG8s0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-4RSNH",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-4RSNHœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-qG8s0",
        "targetHandle": "{œfieldNameœ:œFunction_Infoœ,œidœ:œPrompt Template-qG8s0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-qG8s0",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "RAGFlowChatModel-Miup3",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt Template-qG8s0{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-qG8s0œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-RAGFlowChatModel-Miup3{œfieldNameœ:œinput_valueœ,œidœ:œRAGFlowChatModel-Miup3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt Template-qG8s0",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-qG8s0œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "RAGFlowChatModel-Miup3",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œRAGFlowChatModel-Miup3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-yOiBQ",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "RAGFlowChatModel-Miup3",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-yOiBQ{œdataTypeœ:œTextInputœ,œidœ:œTextInput-yOiBQœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-RAGFlowChatModel-Miup3{œfieldNameœ:œsystem_messageœ,œidœ:œRAGFlowChatModel-Miup3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-yOiBQ",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-yOiBQœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "RAGFlowChatModel-Miup3",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œRAGFlowChatModel-Miup3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RAGFlowChatModel",
            "id": "RAGFlowChatModel-Miup3",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "TypeConverterComponent-Bj8Tq",
            "inputTypes": [
              "Message",
              "Data",
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-RAGFlowChatModel-Miup3{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-Miup3œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-TypeConverterComponent-Bj8Tq{œfieldNameœ:œinput_dataœ,œidœ:œTypeConverterComponent-Bj8Tqœ,œinputTypesœ:[œMessageœ,œDataœ,œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "RAGFlowChatModel-Miup3",
        "sourceHandle": "{œdataTypeœ:œRAGFlowChatModelœ,œidœ:œRAGFlowChatModel-Miup3œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TypeConverterComponent-Bj8Tq",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œTypeConverterComponent-Bj8Tqœ,œinputTypesœ:[œMessageœ,œDataœ,œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TypeConverterComponent",
            "id": "TypeConverterComponent-Bj8Tq",
            "name": "data_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "dataType": "LoopComponent",
            "id": "LoopComponent-iCfBD",
            "name": "item",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-TypeConverterComponent-Bj8Tq{œdataTypeœ:œTypeConverterComponentœ,œidœ:œTypeConverterComponent-Bj8Tqœ,œnameœ:œdata_outputœ,œoutput_typesœ:[œDataœ]}-LoopComponent-iCfBD{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-iCfBDœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}",
        "selected": false,
        "source": "TypeConverterComponent-Bj8Tq",
        "sourceHandle": "{œdataTypeœ:œTypeConverterComponentœ,œidœ:œTypeConverterComponent-Bj8Tqœ,œnameœ:œdata_outputœ,œoutput_typesœ:[œDataœ]}",
        "target": "LoopComponent-iCfBD",
        "targetHandle": "{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-iCfBDœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LoopComponent",
            "id": "LoopComponent-iCfBD",
            "name": "done",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_df",
            "id": "CustomComponent-rtFpp",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-LoopComponent-iCfBD{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-iCfBDœ,œnameœ:œdoneœ,œoutput_typesœ:[œDataFrameœ]}-CustomComponent-rtFpp{œfieldNameœ:œinput_dfœ,œidœ:œCustomComponent-rtFppœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "LoopComponent-iCfBD",
        "sourceHandle": "{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-iCfBDœ,œnameœ:œdoneœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "CustomComponent-rtFpp",
        "targetHandle": "{œfieldNameœ:œinput_dfœ,œidœ:œCustomComponent-rtFppœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-rtFpp",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text5",
            "id": "CombineText-WjgZh",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-CustomComponent-rtFpp{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-rtFppœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-CombineText-WjgZh{œfieldNameœ:œtext5œ,œidœ:œCombineText-WjgZhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "CustomComponent-rtFpp",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-rtFppœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-WjgZh",
        "targetHandle": "{œfieldNameœ:œtext5œ,œidœ:œCombineText-WjgZhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-a6CY9",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "SplitMessageToQueryData-jIQQY",
            "inputTypes": [
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ParserComponent-a6CY9{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-a6CY9œ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-SplitMessageToQueryData-jIQQY{œfieldNameœ:œmessageœ,œidœ:œSplitMessageToQueryData-jIQQYœ,œinputTypesœ:[œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParserComponent-a6CY9",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-a6CY9œ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "SplitMessageToQueryData-jIQQY",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œSplitMessageToQueryData-jIQQYœ,œinputTypesœ:[œMessageœ],œtypeœ:œotherœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "Directory-1lkTg",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Recursively load files from a directory.",
            "display_name": "Directory",
            "documentation": "https://docs.langflow.org/components-data#directory",
            "edited": true,
            "field_order": [
              "path",
              "types",
              "depth",
              "max_concurrency",
              "load_hidden",
              "recursive",
              "silent_errors",
              "use_multithreading"
            ],
            "frozen": false,
            "icon": "folder",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Loaded Files",
                "group_outputs": false,
                "hidden": null,
                "method": "as_dataframe",
                "name": "dataframe",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data, retrieve_file_paths\r\nfrom langflow.custom.custom_component.component import Component\r\nfrom langflow.io import BoolInput, IntInput, MessageTextInput, MultiselectInput\r\nfrom langflow.schema.data import Data\r\nfrom langflow.schema.dataframe import DataFrame\r\nfrom langflow.template.field.base import Output\r\n\r\n\r\nclass DirectoryComponent(Component):\r\n    display_name = \"Directory\"\r\n    description = \"Recursively load files from a directory.\"\r\n    documentation: str = \"https://docs.langflow.org/components-data#directory\"\r\n    icon = \"folder\"\r\n    name = \"Directory\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"path\",\r\n            display_name=\"Path\",\r\n            info=\"Path to the directory to load files from. Defaults to current directory ('.')\",\r\n            value=\".\",\r\n            tool_mode=True,\r\n        ),\r\n        MultiselectInput(\r\n            name=\"types\",\r\n            display_name=\"File Types\",\r\n            info=\"File types to load. Select one or more types or leave empty to load all supported types.\",\r\n            options=TEXT_FILE_TYPES,\r\n            value=[],\r\n        ),\r\n        IntInput(\r\n            name=\"depth\",\r\n            display_name=\"Depth\",\r\n            info=\"Depth to search for files.\",\r\n            value=0,\r\n        ),\r\n        IntInput(\r\n            name=\"max_concurrency\",\r\n            display_name=\"Max Concurrency\",\r\n            advanced=True,\r\n            info=\"Maximum concurrency for loading files.\",\r\n            value=2,\r\n        ),\r\n        BoolInput(\r\n            name=\"load_hidden\",\r\n            display_name=\"Load Hidden\",\r\n            advanced=True,\r\n            info=\"If true, hidden files will be loaded.\",\r\n        ),\r\n        BoolInput(\r\n            name=\"recursive\",\r\n            display_name=\"Recursive\",\r\n            advanced=True,\r\n            info=\"If true, the search will be recursive.\",\r\n        ),\r\n        BoolInput(\r\n            name=\"silent_errors\",\r\n            display_name=\"Silent Errors\",\r\n            advanced=True,\r\n            info=\"If true, errors will not raise an exception.\",\r\n        ),\r\n        BoolInput(\r\n            name=\"use_multithreading\",\r\n            display_name=\"Use Multithreading\",\r\n            advanced=True,\r\n            info=\"If true, multithreading will be used.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Loaded Files\", name=\"dataframe\", method=\"as_dataframe\"),\r\n    ]\r\n\r\n    def load_directory(self) -> list[Data]:\r\n        path = self.path\r\n        types = self.types\r\n        depth = self.depth\r\n        max_concurrency = self.max_concurrency\r\n        load_hidden = self.load_hidden\r\n        recursive = self.recursive\r\n        silent_errors = self.silent_errors\r\n        use_multithreading = self.use_multithreading\r\n\r\n        resolved_path = self.resolve_path(path)\r\n\r\n        # If no types are specified, use all supported types\r\n        if not types:\r\n            types = TEXT_FILE_TYPES\r\n\r\n        # Check if all specified types are valid\r\n        invalid_types = [t for t in types if t not in TEXT_FILE_TYPES]\r\n        if invalid_types:\r\n            msg = f\"Invalid file types specified: {invalid_types}. Valid types are: {TEXT_FILE_TYPES}\"\r\n            raise ValueError(msg)\r\n\r\n        valid_types = types\r\n\r\n        file_paths = retrieve_file_paths(\r\n            resolved_path, load_hidden=load_hidden, recursive=recursive, depth=depth, types=valid_types\r\n        )\r\n\r\n        loaded_data = []\r\n        if use_multithreading:\r\n            loaded_data = parallel_load_data(file_paths, silent_errors=silent_errors, max_concurrency=max_concurrency)\r\n        else:\r\n            loaded_data = [parse_text_file_to_data(file_path, silent_errors=silent_errors) for file_path in file_paths]\r\n\r\n        valid_data = [x for x in loaded_data if x is not None and isinstance(x, Data)]\r\n        self.status = valid_data\r\n        return valid_data\r\n\r\n    def as_dataframe(self) -> DataFrame:\r\n        data = self.load_directory()\r\n        # Add file_id starting from 1\r\n        for idx, d in enumerate(data, start=1):\r\n            d.data[\"file_id\"] = \"F00\" + str(idx)\r\n        return DataFrame(data)\r\n\r\n"
              },
              "depth": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Depth",
                "dynamic": false,
                "info": "Depth to search for files.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "depth",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "load_hidden": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Load Hidden",
                "dynamic": false,
                "info": "If true, hidden files will be loaded.",
                "list": false,
                "list_add_label": "Add More",
                "name": "load_hidden",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_concurrency": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Concurrency",
                "dynamic": false,
                "info": "Maximum concurrency for loading files.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 2
              },
              "path": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Path",
                "dynamic": false,
                "info": "Path to the directory to load files from. Defaults to current directory ('.')",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "/data/projects/cobol-test/FSD_Gen/Input"
              },
              "recursive": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Recursive",
                "dynamic": false,
                "info": "If true, the search will be recursive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "recursive",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "silent_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Silent Errors",
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "list": false,
                "list_add_label": "Add More",
                "name": "silent_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "types": {
                "_input_type": "MultiselectInput",
                "advanced": false,
                "combobox": false,
                "display_name": "File Types",
                "dynamic": false,
                "info": "File types to load. Select one or more types or leave empty to load all supported types.",
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "types",
                "options": [
                  "csv",
                  "json",
                  "pdf",
                  "txt",
                  "md",
                  "mdx",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "md"
                ]
              },
              "use_multithreading": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Use Multithreading",
                "dynamic": false,
                "info": "If true, multithreading will be used.",
                "list": false,
                "list_add_label": "Add More",
                "name": "use_multithreading",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Directory"
        },
        "dragging": false,
        "id": "Directory-1lkTg",
        "measured": {
          "height": 367,
          "width": 320
        },
        "position": {
          "x": 588.4192718488871,
          "y": -508.8775099827236
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CreateData-3eRdR",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Dynamically create a Data with a specified number of fields.",
            "display_name": "Create Data",
            "documentation": "",
            "edited": false,
            "field_order": [
              "number_of_fields",
              "text_key",
              "text_key_validator"
            ],
            "frozen": false,
            "icon": "ListFilter",
            "last_updated": "2026-02-02T03:26:04.108Z",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data",
                "group_outputs": false,
                "loop_types": null,
                "method": "build_data",
                "name": "data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations"
            ],
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import BoolInput, DictInput, IntInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dotdict import dotdict\n\n\nclass CreateDataComponent(Component):\n    display_name: str = \"Create Data\"\n    description: str = \"Dynamically create a Data with a specified number of fields.\"\n    name: str = \"CreateData\"\n    MAX_FIELDS = 15  # Define a constant for maximum number of fields\n    legacy = True\n    replacement = [\"processing.DataOperations\"]\n    icon = \"ListFilter\"\n\n    inputs = [\n        IntInput(\n            name=\"number_of_fields\",\n            display_name=\"Number of Fields\",\n            info=\"Number of fields to be added to the record.\",\n            real_time_refresh=True,\n            value=1,\n            range_spec=RangeSpec(min=1, max=MAX_FIELDS, step=1, step_type=\"int\"),\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"Key that identifies the field to be used as the text content.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"text_key_validator\",\n            display_name=\"Text Key Validator\",\n            advanced=True,\n            info=\"If enabled, checks if the given 'Text Key' is present in the given 'Data'.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"build_data\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"number_of_fields\":\n            default_keys = [\"code\", \"_type\", \"number_of_fields\", \"text_key\", \"text_key_validator\"]\n            try:\n                field_value_int = int(field_value)\n            except ValueError:\n                return build_config\n            existing_fields = {}\n            if field_value_int > self.MAX_FIELDS:\n                build_config[\"number_of_fields\"][\"value\"] = self.MAX_FIELDS\n                msg = (\n                    f\"Number of fields cannot exceed {self.MAX_FIELDS}. \"\n                    \"Please adjust the number of fields to be within the allowed limit.\"\n                )\n                raise ValueError(msg)\n            if len(build_config) > len(default_keys):\n                # back up the existing template fields\n                for key in build_config.copy():\n                    if key not in default_keys:\n                        existing_fields[key] = build_config.pop(key)\n\n            for i in range(1, field_value_int + 1):\n                key = f\"field_{i}_key\"\n                if key in existing_fields:\n                    field = existing_fields[key]\n                    build_config[key] = field\n                else:\n                    field = DictInput(\n                        display_name=f\"Field {i}\",\n                        name=key,\n                        info=f\"Key for field {i}.\",\n                        input_types=[\"Message\", \"Data\"],\n                    )\n                    build_config[field.name] = field.to_dict()\n\n            build_config[\"number_of_fields\"][\"value\"] = field_value_int\n        return build_config\n\n    async def build_data(self) -> Data:\n        data = self.get_data()\n        return_data = Data(data=data, text_key=self.text_key)\n        self.status = return_data\n        if self.text_key_validator:\n            self.validate_text_key()\n        return return_data\n\n    def get_data(self):\n        \"\"\"Function to get the Data from the attributes.\"\"\"\n        data = {}\n        for value_dict in self._attributes.values():\n            if isinstance(value_dict, dict):\n                # Check if the value of the value_dict is a Data\n                value_dict_ = {\n                    key: value.get_text() if isinstance(value, Data) else value for key, value in value_dict.items()\n                }\n                data.update(value_dict_)\n        return data\n\n    def validate_text_key(self) -> None:\n        \"\"\"This function validates that the Text Key is one of the keys in the Data.\"\"\"\n        data_keys = self.get_data().keys()\n        if self.text_key not in data_keys and self.text_key != \"\":\n            formatted_data_keys = \", \".join(data_keys)\n            msg = f\"Text Key: '{self.text_key}' not found in the Data keys: '{formatted_data_keys}'\"\n            raise ValueError(msg)\n"
              },
              "field_1_key": {
                "_input_type": "DictInput",
                "advanced": false,
                "display_name": "Field 1",
                "dynamic": false,
                "info": "Key for field 1.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "field_1_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {
                  "Query1": ""
                }
              },
              "field_2_key": {
                "_input_type": "DictInput",
                "advanced": false,
                "display_name": "Field 2",
                "dynamic": false,
                "info": "Key for field 2.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "field_2_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {
                  "Query2": ""
                }
              },
              "field_3_key": {
                "_input_type": "DictInput",
                "advanced": false,
                "display_name": "Field 3",
                "dynamic": false,
                "info": "Key for field 3.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "field_3_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {
                  "Query3": ""
                }
              },
              "field_4_key": {
                "_input_type": "DictInput",
                "advanced": false,
                "display_name": "Field 4",
                "dynamic": false,
                "info": "Key for field 4.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "field_4_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {
                  "Query4": ""
                }
              },
              "number_of_fields": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Fields",
                "dynamic": false,
                "info": "Number of fields to be added to the record.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "number_of_fields",
                "placeholder": "",
                "range_spec": {
                  "max": 15,
                  "min": 1,
                  "step": 1,
                  "step_type": "int"
                },
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 4
              },
              "text_key": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Key",
                "dynamic": false,
                "info": "Key that identifies the field to be used as the text content.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text_key_validator": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Text Key Validator",
                "dynamic": false,
                "info": "If enabled, checks if the given 'Text Key' is present in the given 'Data'.",
                "list": false,
                "list_add_label": "Add More",
                "name": "text_key_validator",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CreateData"
        },
        "dragging": false,
        "id": "CreateData-3eRdR",
        "measured": {
          "height": 558,
          "width": 320
        },
        "position": {
          "x": 1297.511144708637,
          "y": 2484.0064685132784
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-CoeHK",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": []
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "By analyzing all cobol Summary document in knowledge base, provide the System Overview, write no less than 300 words in this session. Generate the System Overview one time only, do not repeat. Strictly follow the defined Markdown output format below, without omitting any part.\n\n## 1. System Overview\n\n* **System Summary**: Describe the high level system summary including overall concept of the module, assumptions and system requirement. \n* **Function Description**: A concise summary of the program's main business purpose.\n* **Main Processes **: List out all the processes for the module."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-CoeHK",
        "measured": {
          "height": 292,
          "width": 320
        },
        "position": {
          "x": 524.1102729415536,
          "y": 2426.5198699160874
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-i1XaW",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": []
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "By analyzing all cobol Summary document in knowledge base, provide a high level architecture diagram. Use Mermaid syntax to visualize the architecture diagram. \nPlease strictly generate the document in the following Markdown structure:\n\n## 2. System Summary\n```mermaid\nflowchart TD\n\n    %% Frontend to Gateway\n    A[Front-End Web/Mobile Client] -->|REST/HTTPS| B[SOA Gateway]\n\n    %% Gateway to Application Server\n    B -->|API Routing / Auth / Logging| C[Application Server]\n\n    %% Application Server to Storage\n    C -->|Business Logic Calls| D[(Storage: Database / Data Lake)]\n\n    %% External Interfaces\n    C -->|External API Calls| E[External System 1 Partner API]\n    C -->|External API Calls| F[External System 2 Payment Gateway]\n\n    %% Tier Grouping\n    subgraph User_Tier [User Tier]\n        A\n    end\n\n    subgraph Integration_Tier [Integration Tier]\n        B\n    end\n\n    subgraph Application_Tier [Application Tier]\n        C\n    end\n\n    subgraph Data_Tier [Data Tier]\n        D\n    end\n\n    subgraph External_Interfaces [External Interfaces]\n        E\n        F\n    end\n```"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-i1XaW",
        "measured": {
          "height": 292,
          "width": 320
        },
        "position": {
          "x": 524.2359724950622,
          "y": 2788.737970253107
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-Fio2j",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": []
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "By analyzing all cobol Summary document in knowledge base, \nFirst, list out all the functions in logical order and provide the reference summary document for that function. Do not miss out any function. \nFor below function provide these information:\n\nFunction: **Report Generation**: Formats aggregated results into structured output reports with headers, line-item details, and summary totals adhering to predefined layout specifications.\n\nList out all the assumptions, including the output of all upstream systems, prerequisite input data existence, parameters setting etc. \nList out all the dependencies, including required upstream and downstream system, required configurations etc. \nSecond, provide the mermaid flowchart and detailed steps for that function.\nFor both flowcharts and steps, it has to be as detailed as possible to capture all detailed logic of the function. Assuming the steps will be used for developers to write java code and microservice to reproduce the function. Therefore, detailed fields, validation rules, default values, error handling must be clearly stated in the steps.\nThe steps have to be in sync with the flowchart, to enhance readability. \nFinally, describe the outcome of the function. Including any report generated, if exist, or any data to be stored in the database. \nWrite no less than 200 words for that function.\nDo not need to generate other section such as system overview, system summary etc. Only need to generate the Function part.\nprovide the Function of all the cobol Summary document in below md format.\n\n## 3. Function\n\n* **`[Report Generation]`**: \n\n\t* **`[Purpose]`**: High level purpose of this function. \n\n\t* **Assumption**:\n\t\t* `[Assumption 1]`: Detailed Assumption descripion. \n\t\t* `[Assumption 2]`: Detailed Assumption descripion. \n\n\t* **Dependency**:\n\t\t* `[Dependency 1]`: Detailed Dependency descripion. \n\t\t* `[Dependency 2]`: Detailed Dependency descripion. \n\t\t\n\t```mermaid\n\tgraph TD\n\t\tflowchart for Function 1\n\t```\n\n\t\t* [Step 1, describe the first step of Function 1 in detail]\n\t\t* [Step 2, describe the second step of Function 1 in detail]\n\t\t...\n\t\n\t* **Outcome**: Describe the expected outcome for Report Generation. Including any generated report if exist or data stored in database."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-Fio2j",
        "measured": {
          "height": 292,
          "width": 320
        },
        "position": {
          "x": 897.029578682432,
          "y": 2420.7844726409003
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-xh21F",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": []
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "By analyzing Functional Specifications - CPF SRS POC (Trade Settlement) v0.6.docx in knowledge base, provide any other essential part you think is suitable for this functional specification, to better capture the business functionalities. \n\n## 4. Title\n\tContent\n\t  ...\n\t  \n## 5. Title\n\tContent\n\t  ...\n...\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-xh21F",
        "measured": {
          "height": 292,
          "width": 320
        },
        "position": {
          "x": 906.4576403553026,
          "y": 2804.7226234499576
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DataToDataFrame-VS3fa",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Converts one or multiple Data objects into a DataFrame. Each Data object corresponds to one row. Fields from `.data` become columns, and the `.text` (if present) is placed in a 'text' column.",
            "display_name": "Data → DataFrame",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data_list"
            ],
            "frozen": false,
            "icon": "table",
            "key": "DataToDataFrame",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "method": "build_dataframe",
                "name": "dataframe",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations",
              "processing.TypeConverterComponent"
            ],
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import DataInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\n\n\nclass DataToDataFrameComponent(Component):\n    display_name = \"Data → DataFrame\"\n    description = (\n        \"Converts one or multiple Data objects into a DataFrame. \"\n        \"Each Data object corresponds to one row. Fields from `.data` become columns, \"\n        \"and the `.text` (if present) is placed in a 'text' column.\"\n    )\n    icon = \"table\"\n    name = \"DataToDataFrame\"\n    legacy = True\n    replacement = [\"processing.DataOperations\", \"processing.TypeConverterComponent\"]\n\n    inputs = [\n        DataInput(\n            name=\"data_list\",\n            display_name=\"Data or Data List\",\n            info=\"One or multiple Data objects to transform into a DataFrame.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"DataFrame\",\n            name=\"dataframe\",\n            method=\"build_dataframe\",\n            info=\"A DataFrame built from each Data object's fields plus a 'text' column.\",\n        ),\n    ]\n\n    def build_dataframe(self) -> DataFrame:\n        \"\"\"Builds a DataFrame from Data objects by combining their fields.\n\n        For each Data object:\n          - Merge item.data (dictionary) as columns\n          - If item.text is present, add 'text' column\n\n        Returns a DataFrame with one row per Data object.\n        \"\"\"\n        data_input = self.data_list\n\n        # If user passed a single Data, it might come in as a single object rather than a list\n        if not isinstance(data_input, list):\n            data_input = [data_input]\n\n        rows = []\n        for item in data_input:\n            if not isinstance(item, Data):\n                msg = f\"Expected Data objects, got {type(item)} instead.\"\n                raise TypeError(msg)\n\n            # Start with a copy of item.data or an empty dict\n            row_dict = dict(item.data) if item.data else {}\n\n            # If the Data object has text, store it under 'text' col\n            text_val = item.get_text()\n            if text_val:\n                row_dict[\"text\"] = text_val\n\n            rows.append(row_dict)\n\n        # Build a DataFrame from these row dictionaries\n        df_result = DataFrame(rows)\n        self.status = df_result  # store in self.status for logs\n        return df_result\n"
              },
              "data_list": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data or Data List",
                "dynamic": false,
                "info": "One or multiple Data objects to transform into a DataFrame.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data_list",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DataToDataFrame"
        },
        "dragging": false,
        "id": "DataToDataFrame-VS3fa",
        "measured": {
          "height": 226,
          "width": 320
        },
        "position": {
          "x": 2015.4251028007766,
          "y": 1462.6779818411726
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DataFrameOperations-S8seY",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Perform various operations on a DataFrame.",
            "display_name": "DataFrame Operations",
            "documentation": "https://docs.langflow.org/components-processing#dataframe-operations",
            "edited": false,
            "field_order": [
              "df",
              "operation",
              "column_name",
              "filter_value",
              "filter_operator",
              "ascending",
              "new_column_name",
              "new_column_value",
              "columns_to_select",
              "num_rows",
              "replace_value",
              "replacement_value"
            ],
            "frozen": false,
            "icon": "table",
            "key": "DataFrameOperations",
            "last_updated": "2026-02-02T03:26:04.501Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "loop_types": null,
                "method": "perform_operation",
                "name": "output",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_frontend_node_flow_id": {
                "value": "1cf2e908-dcd4-43b1-b2ab-df12d7607aa0"
              },
              "_frontend_node_folder_id": {
                "value": "ad4db6bf-94a7-4138-978a-b55a38dc9cf4"
              },
              "_type": "Component",
              "ascending": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Sort Ascending",
                "dynamic": true,
                "info": "Whether to sort in ascending order.",
                "list": false,
                "list_add_label": "Add More",
                "name": "ascending",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import pandas as pd\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs import SortableListInput\nfrom langflow.io import (\n    BoolInput,\n    DataFrameInput,\n    DropdownInput,\n    IntInput,\n    MessageTextInput,\n    Output,\n    StrInput,\n)\nfrom langflow.logging import logger\nfrom langflow.schema.dataframe import DataFrame\n\n\nclass DataFrameOperationsComponent(Component):\n    display_name = \"DataFrame Operations\"\n    description = \"Perform various operations on a DataFrame.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#dataframe-operations\"\n    icon = \"table\"\n    name = \"DataFrameOperations\"\n\n    OPERATION_CHOICES = [\n        \"Add Column\",\n        \"Drop Column\",\n        \"Filter\",\n        \"Head\",\n        \"Rename Column\",\n        \"Replace Value\",\n        \"Select Columns\",\n        \"Sort\",\n        \"Tail\",\n        \"Drop Duplicates\",\n    ]\n\n    inputs = [\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The input DataFrame to operate on.\",\n            required=True,\n        ),\n        SortableListInput(\n            name=\"operation\",\n            display_name=\"Operation\",\n            placeholder=\"Select Operation\",\n            info=\"Select the DataFrame operation to perform.\",\n            options=[\n                {\"name\": \"Add Column\", \"icon\": \"plus\"},\n                {\"name\": \"Drop Column\", \"icon\": \"minus\"},\n                {\"name\": \"Filter\", \"icon\": \"filter\"},\n                {\"name\": \"Head\", \"icon\": \"arrow-up\"},\n                {\"name\": \"Rename Column\", \"icon\": \"pencil\"},\n                {\"name\": \"Replace Value\", \"icon\": \"replace\"},\n                {\"name\": \"Select Columns\", \"icon\": \"columns\"},\n                {\"name\": \"Sort\", \"icon\": \"arrow-up-down\"},\n                {\"name\": \"Tail\", \"icon\": \"arrow-down\"},\n                {\"name\": \"Drop Duplicates\", \"icon\": \"copy-x\"},\n            ],\n            real_time_refresh=True,\n            limit=1,\n        ),\n        StrInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=\"The column name to use for the operation.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"filter_value\",\n            display_name=\"Filter Value\",\n            info=\"The value to filter rows by.\",\n            dynamic=True,\n            show=False,\n        ),\n        DropdownInput(\n            name=\"filter_operator\",\n            display_name=\"Filter Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"greater than\", \"less than\"],\n            value=\"equals\",\n            info=\"The operator to apply for filtering rows.\",\n            advanced=False,\n            dynamic=True,\n            show=False,\n        ),\n        BoolInput(\n            name=\"ascending\",\n            display_name=\"Sort Ascending\",\n            info=\"Whether to sort in ascending order.\",\n            dynamic=True,\n            show=False,\n            value=True,\n        ),\n        StrInput(\n            name=\"new_column_name\",\n            display_name=\"New Column Name\",\n            info=\"The new column name when renaming or adding a column.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"new_column_value\",\n            display_name=\"New Column Value\",\n            info=\"The value to populate the new column with.\",\n            dynamic=True,\n            show=False,\n        ),\n        StrInput(\n            name=\"columns_to_select\",\n            display_name=\"Columns to Select\",\n            dynamic=True,\n            is_list=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"num_rows\",\n            display_name=\"Number of Rows\",\n            info=\"Number of rows to return (for head/tail).\",\n            dynamic=True,\n            show=False,\n            value=5,\n        ),\n        MessageTextInput(\n            name=\"replace_value\",\n            display_name=\"Value to Replace\",\n            info=\"The value to replace in the column.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"replacement_value\",\n            display_name=\"Replacement Value\",\n            info=\"The value to replace with.\",\n            dynamic=True,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"DataFrame\",\n            name=\"output\",\n            method=\"perform_operation\",\n            info=\"The resulting DataFrame after the operation.\",\n        )\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        dynamic_fields = [\n            \"column_name\",\n            \"filter_value\",\n            \"filter_operator\",\n            \"ascending\",\n            \"new_column_name\",\n            \"new_column_value\",\n            \"columns_to_select\",\n            \"num_rows\",\n            \"replace_value\",\n            \"replacement_value\",\n        ]\n        for field in dynamic_fields:\n            build_config[field][\"show\"] = False\n\n        if field_name == \"operation\":\n            # Handle SortableListInput format\n            if isinstance(field_value, list):\n                operation_name = field_value[0].get(\"name\", \"\") if field_value else \"\"\n            else:\n                operation_name = field_value or \"\"\n\n            # If no operation selected, all dynamic fields stay hidden (already set to False above)\n            if not operation_name:\n                return build_config\n\n            if operation_name == \"Filter\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"filter_value\"][\"show\"] = True\n                build_config[\"filter_operator\"][\"show\"] = True\n            elif operation_name == \"Sort\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"ascending\"][\"show\"] = True\n            elif operation_name == \"Drop Column\":\n                build_config[\"column_name\"][\"show\"] = True\n            elif operation_name == \"Rename Column\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"new_column_name\"][\"show\"] = True\n            elif operation_name == \"Add Column\":\n                build_config[\"new_column_name\"][\"show\"] = True\n                build_config[\"new_column_value\"][\"show\"] = True\n            elif operation_name == \"Select Columns\":\n                build_config[\"columns_to_select\"][\"show\"] = True\n            elif operation_name in {\"Head\", \"Tail\"}:\n                build_config[\"num_rows\"][\"show\"] = True\n            elif operation_name == \"Replace Value\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"replace_value\"][\"show\"] = True\n                build_config[\"replacement_value\"][\"show\"] = True\n            elif operation_name == \"Drop Duplicates\":\n                build_config[\"column_name\"][\"show\"] = True\n\n        return build_config\n\n    def perform_operation(self) -> DataFrame:\n        df_copy = self.df.copy()\n\n        # Handle SortableListInput format for operation\n        operation_input = getattr(self, \"operation\", [])\n        if isinstance(operation_input, list) and len(operation_input) > 0:\n            op = operation_input[0].get(\"name\", \"\")\n        else:\n            op = \"\"\n\n        # If no operation selected, return original DataFrame\n        if not op:\n            return df_copy\n\n        if op == \"Filter\":\n            return self.filter_rows_by_value(df_copy)\n        if op == \"Sort\":\n            return self.sort_by_column(df_copy)\n        if op == \"Drop Column\":\n            return self.drop_column(df_copy)\n        if op == \"Rename Column\":\n            return self.rename_column(df_copy)\n        if op == \"Add Column\":\n            return self.add_column(df_copy)\n        if op == \"Select Columns\":\n            return self.select_columns(df_copy)\n        if op == \"Head\":\n            return self.head(df_copy)\n        if op == \"Tail\":\n            return self.tail(df_copy)\n        if op == \"Replace Value\":\n            return self.replace_values(df_copy)\n        if op == \"Drop Duplicates\":\n            return self.drop_duplicates(df_copy)\n        msg = f\"Unsupported operation: {op}\"\n        logger.error(msg)\n        raise ValueError(msg)\n\n    def filter_rows_by_value(self, df: DataFrame) -> DataFrame:\n        column = df[self.column_name]\n        filter_value = self.filter_value\n\n        # Handle regular DropdownInput format (just a string value)\n        operator = getattr(self, \"filter_operator\", \"equals\")  # Default to equals for backward compatibility\n\n        if operator == \"equals\":\n            mask = column == filter_value\n        elif operator == \"not equals\":\n            mask = column != filter_value\n        elif operator == \"contains\":\n            mask = column.astype(str).str.contains(str(filter_value), na=False)\n        elif operator == \"starts with\":\n            mask = column.astype(str).str.startswith(str(filter_value), na=False)\n        elif operator == \"ends with\":\n            mask = column.astype(str).str.endswith(str(filter_value), na=False)\n        elif operator == \"greater than\":\n            try:\n                # Try to convert filter_value to numeric for comparison\n                numeric_value = pd.to_numeric(filter_value)\n                mask = column > numeric_value\n            except (ValueError, TypeError):\n                # If conversion fails, compare as strings\n                mask = column.astype(str) > str(filter_value)\n        elif operator == \"less than\":\n            try:\n                # Try to convert filter_value to numeric for comparison\n                numeric_value = pd.to_numeric(filter_value)\n                mask = column < numeric_value\n            except (ValueError, TypeError):\n                # If conversion fails, compare as strings\n                mask = column.astype(str) < str(filter_value)\n        else:\n            mask = column == filter_value  # Fallback to equals\n\n        return DataFrame(df[mask])\n\n    def sort_by_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.sort_values(by=self.column_name, ascending=self.ascending))\n\n    def drop_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.drop(columns=[self.column_name]))\n\n    def rename_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.rename(columns={self.column_name: self.new_column_name}))\n\n    def add_column(self, df: DataFrame) -> DataFrame:\n        df[self.new_column_name] = [self.new_column_value] * len(df)\n        return DataFrame(df)\n\n    def select_columns(self, df: DataFrame) -> DataFrame:\n        columns = [col.strip() for col in self.columns_to_select]\n        return DataFrame(df[columns])\n\n    def head(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.head(self.num_rows))\n\n    def tail(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.tail(self.num_rows))\n\n    def replace_values(self, df: DataFrame) -> DataFrame:\n        df[self.column_name] = df[self.column_name].replace(self.replace_value, self.replacement_value)\n        return DataFrame(df)\n\n    def drop_duplicates(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.drop_duplicates(subset=self.column_name))\n"
              },
              "column_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": true,
                "info": "The column name to use for the operation.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "columns_to_select": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Columns to Select",
                "dynamic": true,
                "info": "",
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "columns_to_select",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "text"
                ]
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The input DataFrame to operate on.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "filter_operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Filter Operator",
                "dynamic": true,
                "external_options": {},
                "info": "The operator to apply for filtering rows.",
                "name": "filter_operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "greater than",
                  "less than"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "equals"
              },
              "filter_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Filter Value",
                "dynamic": true,
                "info": "The value to filter rows by.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "filter_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "new_column_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "New Column Name",
                "dynamic": true,
                "info": "The new column name when renaming or adding a column.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "new_column_name",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "new_column_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "New Column Value",
                "dynamic": true,
                "info": "The value to populate the new column with.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "new_column_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "num_rows": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Rows",
                "dynamic": true,
                "info": "Number of rows to return (for head/tail).",
                "list": false,
                "list_add_label": "Add More",
                "name": "num_rows",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "operation": {
                "_input_type": "SortableListInput",
                "advanced": false,
                "display_name": "Operation",
                "dynamic": false,
                "info": "Select the DataFrame operation to perform.",
                "limit": 1,
                "name": "operation",
                "options": [
                  {
                    "icon": "plus",
                    "name": "Add Column"
                  },
                  {
                    "icon": "minus",
                    "name": "Drop Column"
                  },
                  {
                    "icon": "filter",
                    "name": "Filter"
                  },
                  {
                    "icon": "arrow-up",
                    "name": "Head"
                  },
                  {
                    "icon": "pencil",
                    "name": "Rename Column"
                  },
                  {
                    "icon": "replace",
                    "name": "Replace Value"
                  },
                  {
                    "icon": "columns",
                    "name": "Select Columns"
                  },
                  {
                    "icon": "arrow-up-down",
                    "name": "Sort"
                  },
                  {
                    "icon": "arrow-down",
                    "name": "Tail"
                  },
                  {
                    "icon": "copy-x",
                    "name": "Drop Duplicates"
                  }
                ],
                "placeholder": "Select Operation",
                "real_time_refresh": true,
                "required": false,
                "search_category": [],
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "sortableList",
                "value": [
                  {
                    "chosen": false,
                    "icon": "columns",
                    "name": "Select Columns",
                    "selected": false
                  }
                ]
              },
              "replace_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Value to Replace",
                "dynamic": true,
                "info": "The value to replace in the column.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "replace_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "replacement_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Replacement Value",
                "dynamic": true,
                "info": "The value to replace with.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "replacement_value",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DataFrameOperations"
        },
        "dragging": false,
        "id": "DataFrameOperations-S8seY",
        "measured": {
          "height": 324,
          "width": 320
        },
        "position": {
          "x": 1039.0246130630092,
          "y": -423.7245505126705
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TypeConverterComponent-lPPTr",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert between different types (Message, Data, DataFrame)",
            "display_name": "Type Convert",
            "documentation": "https://docs.langflow.org/components-processing#type-convert",
            "edited": false,
            "field_order": [
              "input_data",
              "output_type"
            ],
            "frozen": false,
            "icon": "repeat",
            "key": "TypeConverterComponent",
            "last_updated": "2026-02-02T03:26:10.928Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame Output",
                "group_outputs": false,
                "hidden": null,
                "loop_types": null,
                "method": "convert_to_dataframe",
                "name": "dataframe_output",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.008834292878014125,
            "template": {
              "_frontend_node_flow_id": {
                "value": "1cf2e908-dcd4-43b1-b2ab-df12d7607aa0"
              },
              "_frontend_node_folder_id": {
                "value": "ad4db6bf-94a7-4138-978a-b55a38dc9cf4"
              },
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, Output, TabInput\nfrom langflow.schema import Data, DataFrame, Message\n\n\ndef convert_to_message(v) -> Message:\n    \"\"\"Convert input to Message type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Message: Converted Message object\n    \"\"\"\n    return v if isinstance(v, Message) else v.to_message()\n\n\ndef convert_to_data(v: DataFrame | Data | Message | dict) -> Data:\n    \"\"\"Convert input to Data type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Data: Converted Data object\n    \"\"\"\n    if isinstance(v, dict):\n        return Data(v)\n    if isinstance(v, Message):\n        return v.to_data()\n    return v if isinstance(v, Data) else v.to_data()\n\n\ndef convert_to_dataframe(v: DataFrame | Data | Message | dict) -> DataFrame:\n    \"\"\"Convert input to DataFrame type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        DataFrame: Converted DataFrame object\n    \"\"\"\n    if isinstance(v, dict):\n        return DataFrame([v])\n    return v if isinstance(v, DataFrame) else v.to_dataframe()\n\n\nclass TypeConverterComponent(Component):\n    display_name = \"Type Convert\"\n    description = \"Convert between different types (Message, Data, DataFrame)\"\n    documentation: str = \"https://docs.langflow.org/components-processing#type-convert\"\n    icon = \"repeat\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Input\",\n            input_types=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Accept Message, Data or DataFrame as input\",\n            required=True,\n        ),\n        TabInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Select the desired output data type\",\n            real_time_refresh=True,\n            value=\"Message\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message Output\",\n            name=\"message_output\",\n            method=\"convert_to_message\",\n        )\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"output_type\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n\n            # Add only the selected output type\n            if field_value == \"Message\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Message Output\",\n                        name=\"message_output\",\n                        method=\"convert_to_message\",\n                    ).to_dict()\n                )\n            elif field_value == \"Data\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Data Output\",\n                        name=\"data_output\",\n                        method=\"convert_to_data\",\n                    ).to_dict()\n                )\n            elif field_value == \"DataFrame\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"DataFrame Output\",\n                        name=\"dataframe_output\",\n                        method=\"convert_to_dataframe\",\n                    ).to_dict()\n                )\n\n        return frontend_node\n\n    def convert_to_message(self) -> Message:\n        \"\"\"Convert input to Message type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_message(input_value)\n        self.status = result\n        return result\n\n    def convert_to_data(self) -> Data:\n        \"\"\"Convert input to Data type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_data(input_value)\n        self.status = result\n        return result\n\n    def convert_to_dataframe(self) -> DataFrame:\n        \"\"\"Convert input to DataFrame type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_dataframe(input_value)\n        self.status = result\n        return result\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Accept Message, Data or DataFrame as input",
                "input_types": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "is_refresh": false,
              "output_type": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Output Type",
                "dynamic": false,
                "info": "Select the desired output data type",
                "name": "output_type",
                "options": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "DataFrame"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TypeConverterComponent"
        },
        "dragging": false,
        "id": "TypeConverterComponent-lPPTr",
        "measured": {
          "height": 261,
          "width": 320
        },
        "position": {
          "x": 1540.7167343906794,
          "y": -392.72110481264576
        },
        "selected": true,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-NQK2c",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "last_updated": "2025-10-30T03:23:06.171Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Clean Data",
                "dynamic": false,
                "info": "Enable to clean the data by removing empty rows and lines in each cell of the DataFrame/ Data object.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Stringify"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Text: {text}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-NQK2c",
        "measured": {
          "height": 254,
          "width": 320
        },
        "position": {
          "x": 1976.8874242085305,
          "y": -374.9437419086526
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CombineText-qpcMq",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
            "display_name": "Combine Text",
            "documentation": "",
            "edited": false,
            "field_order": [
              "text1",
              "text2",
              "delimiter"
            ],
            "frozen": false,
            "icon": "merge",
            "key": "CombineText",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Combined Text",
                "group_outputs": false,
                "method": "combine_texts",
                "name": "combined_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations"
            ],
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n    legacy: bool = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2])\n        self.status = combined\n        return Message(text=combined)\n"
              },
              "delimiter": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Delimiter",
                "dynamic": false,
                "info": "A string used to separate the two text inputs. Defaults to a whitespace.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "delimiter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": " \\n\\n"
              },
              "text1": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "First Text",
                "dynamic": false,
                "info": "The first text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text1",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text2": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Second Text",
                "dynamic": false,
                "info": "The second text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text2",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "By analyzing the above multiple Cobol Summary document, provide a functional specification document for all summary"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CombineText"
        },
        "dragging": false,
        "id": "CombineText-qpcMq",
        "measured": {
          "height": 394,
          "width": 320
        },
        "position": {
          "x": 2390.5809827203525,
          "y": -630.9987266623046
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "RAGFlowChatModel-RNPtF",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "sunshine_coder",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using RAGFlow.",
            "display_name": "RAGFlow Chat Model",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "ragflow_ca_bundle",
              "ragflow_chat_base_url",
              "ragflow_chat_id",
              "ragflow_chat_api_key",
              "timeout",
              "max_retries",
              "model_name",
              "temperature",
              "max_tokens",
              "json_mode",
              "use_responses_api",
              "model_kwargs"
            ],
            "frozen": false,
            "icon": "SunshineCoder",
            "key": "RAGFlowChatModel",
            "last_updated": "2025-10-30T03:36:33.500Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import httpx\nimport ssl\n\nfrom typing import Any\nfrom pydantic.v1 import SecretStr\nfrom langchain_openai import ChatOpenAI\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    IntInput,\n    MessageInput,\n    MultilineInput,\n    SecretStrInput,\n    SliderInput,\n    StrInput,\n)\nfrom langflow.components.sunshine_coder.constants import (\n    CA_BUNDLE,\n    RAGFLOW_CHAT_BASE_URL,\n    RAGFLOW_CHAT_MODEL_LIST,\n)\nfrom langflow.logging import logger\n\n\nclass RAGFlowChatModelComponent(LCModelComponent):\n    name = \"RAGFlowChatModel\"\n    display_name = \"RAGFlow Chat Model\"\n    description = \"Generates text using RAGFlow.\"\n    icon = \"SunshineCoder\"\n    inputs = [\n        *LCModelComponent._base_inputs,\n        MultilineInput(\n            name=\"ragflow_ca_bundle\",\n            display_name=\"RAGFlow CA Bundle\",\n            info=\"Leave empty unless you're using a self-signed certificate. \"\n            \"Paste the entire certificate including the '-----BEGIN/END CERTIFICATE-----' lines. \"\n            \"Not sure? Just leave it blank!\",\n            value=CA_BUNDLE,\n            advanced=True,\n            dynamic=True,\n        ),\n        StrInput(\n            name=\"ragflow_chat_base_url\",\n            display_name=\"RAGFlow Chat Base URL\",\n            value=RAGFLOW_CHAT_BASE_URL,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"ragflow_chat_id\",\n            display_name=\"RAGFlow Chat Id\",\n            required=True\n        ),\n        SecretStrInput(\n            name=\"ragflow_chat_api_key\",\n            display_name=\"RAGFlow Chat API Key\",\n            required=True\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            value=600,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            value=3,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=RAGFLOW_CHAT_MODEL_LIST,\n            value=RAGFLOW_CHAT_MODEL_LIST[0],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=262144),\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"use_responses_api\",\n            display_name=\"Use Responses API\",\n            info=\"Whether to use the Responses API instead of the Chat API.\",\n            advanced=True,\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            info=\"Additional keyword arguments to pass to the model.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        self.log(f\"Executing request with model: {self.model_name}\")\n        ssl_ctx = None\n        if self.ragflow_ca_bundle:\n            try:\n                ssl_ctx = ssl.create_default_context()\n                ssl_ctx.load_verify_locations(cadata=self.ragflow_ca_bundle)\n            except (ssl.SSLError, ValueError) as e:\n                logger.error(f\"Failed to load CA bundle: {e}\")\n                raise ValueError(f\"Invalid CA bundle: {e}\") from e\n        parameters = {\n            \"base_url\": self.ragflow_chat_base_url + \"/\" + self.ragflow_chat_id,\n            \"api_key\": (\n                SecretStr(self.ragflow_chat_api_key).get_secret_value()\n                if self.ragflow_chat_api_key\n                else None\n            ),\n            \"timeout\": self.timeout,\n            \"max_retries\": self.max_retries,\n            \"model_name\": self.model_name,\n            \"temperature\": self.temperature,\n            \"max_tokens\": self.max_tokens or None,\n            \"use_responses_api\": self.use_responses_api or None,\n            \"model_kwargs\": self.model_kwargs or {},\n        }\n        output = ChatOpenAI(\n            http_client=httpx.Client(verify=ssl_ctx) if self.ragflow_ca_bundle else None,\n            http_async_client=httpx.AsyncClient(verify=ssl_ctx) if self.ragflow_ca_bundle else None,\n            **parameters\n        )\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(\n        self, build_config: dict, field_value: Any, field_name: str | None = None\n    ) -> dict:\n        build_config[\"temperature\"][\"show\"] = True\n        if \"system_message\" in build_config:\n            build_config[\"system_message\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://172.31.2.60"
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 3
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 262144,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 0
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "external_options": {},
                "info": "",
                "name": "model_name",
                "options": [
                  "qwen3-coder-30b-a3b",
                  "qwen3-30b-a3b-thinking",
                  "qwen3-vl-30b-a3b-thinking"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "qwen3-coder-30b-a3b"
              },
              "ragflow_ca_bundle": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "RAGFlow CA Bundle",
                "dynamic": true,
                "info": "Leave empty unless you're using a self-signed certificate. Paste the entire certificate including the '-----BEGIN/END CERTIFICATE-----' lines. Not sure? Just leave it blank!",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "ragflow_ca_bundle",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "-----BEGIN CERTIFICATE-----\nMIIFEzCCAvugAwIBAgIQHNtXzZext4JPNifVibRoXzANBgkqhkiG9w0BAQsFADAc\nMRowGAYDVQQDExFOQ1NEZXZOZXQgUm9vdCBDQTAeFw0yMDA0MDIwNjQ5MjBaFw0z\nNTA0MDIwNjU5MTlaMBwxGjAYBgNVBAMTEU5DU0Rldk5ldCBSb290IENBMIICIjAN\nBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAywoxwa5oCujD63Dg+XR2Lre7Nfd/\nNohA4eG5oTbbC3Ng6h95m6QfnyzzrZYcftW8aqRhakIDQITYp9QXR6fJ9DvHxWO9\n7Jb/8TPER7xHPPwiKocPjCNeWPETiWjpNg9YyAzOAwLWJJRNpLzynvdVsD4el6ZD\n43J2iUlohMhE0qGL56PwNgt8Z4BHcr81Ymm8mgpZyaq0CspnzdUQxhZYPsTBqvnh\nzRktfZlNu6C4u9xrGClKNH1Q1H9L8YUoKFf5Y/ePJtNYviAINqvYyDqiba2SnFSC\n4KELQZpLb2SqfEgWLI4T8mSrbAMV17ybsbWxrFrY34dTYA1vKIVQm2ea9sB73Pat\no0uX7gPyZiAneXRXdtwLTBnDz5+PowzE/jwVxth4ZlHq14nODLvrfpjMxmXUDlhO\nuWfpvNiMkWitK5Q6vrPe04V1v7IwNywRb1AqZciPdznOkP79Mv70lUqNid2goYws\ncIOL3sRcDedMuxEtWKIyfyqC38MqgLpjKEfU4ozxrE2nvf2qPrAf4n8KBRy9KDf2\n7BeUr6mJULofseohMh2n3RIljcP02nMVdOy6p9N93AIQwL996Oe0mOikkYU+rFtM\naLHOeCmw7tbASoVymT+ja1NGoO99S7p1UwehF5//pV1PXUQmO5Z3F6fGWebLV6F2\nArnGzR6CXTkdjcECAwEAAaNRME8wCwYDVR0PBAQDAgGGMA8GA1UdEwEB/wQFMAMB\nAf8wHQYDVR0OBBYEFDpqUad1Arn/92XUwq2uqs1hbYtpMBAGCSsGAQQBgjcVAQQD\nAgEAMA0GCSqGSIb3DQEBCwUAA4ICAQACXcOTV7NeAQdvbAM9DO9ef+peFm1oCzJj\nh66VW8wtXknTDykprciB9JRE2ac5fx9xOfIl/gdzVXuddYoVr9JJdD3mKDij0uqS\nkD1BhNxTpc9tD3U5lPcRcjbSXmKGICM+dGG9IUt8Gs0p/NuzYho0P2jDnar8ZFhL\n/BPAFdVifjUlFLRjEE3gET11pSnyaeF6zYrBY6rQVjm3Hk+q/TioAn3P57WCWzzt\nLx2t8WGB8QxZd/A1aBC7TXkOJTOidJp15/98fImyOpu096u9WfRPyrWDCzeUFBkc\n9WeS52P+qlpQksUnLq1c9XJfqGJZiBvf+XeuCLP9S3LXb0ShKyha0xwf3sIos4Hi\ngj7RP30KZRJXXBV9w4RicI/kzCScZhSkvn8EJ2t7qaVJA6v8QVmIQ18R/9inG0TJ\ntRuw7Yfwc+EAdzDp2e4Fijm6wa8OcKx9FGNDKLR6W2o/iGGOrK+5N4L/ZMxXWXtF\nYsJh6dFmWGMmckM0kRXnfIhvQkLv49+lD2np+MzCVeRxvGdEq2/zYjMljyjaTaqA\nYPPrPKH+VqKGXlXHnMM/9UrYw8gj28BRrKfAYbLL38BSOTbsvYa1QqgTvF7u1PDS\nGcLEjC6llllje/0GAo25einsDGvsyUbvn4/gigLYYvE4a1G6oo1Lg4YwhQw5W/s+\nCKGHxKUDLg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIE0zCCA7ugAwIBAgIJANu+mC2Jt3uTMA0GCSqGSIb3DQEBCwUAMIGhMQswCQYD\nVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTERMA8GA1UEBxMIU2FuIEpvc2Ux\nFTATBgNVBAoTDFpzY2FsZXIgSW5jLjEVMBMGA1UECxMMWnNjYWxlciBJbmMuMRgw\nFgYDVQQDEw9ac2NhbGVyIFJvb3QgQ0ExIjAgBgkqhkiG9w0BCQEWE3N1cHBvcnRA\nenNjYWxlci5jb20wHhcNMTQxMjE5MDAyNzU1WhcNNDIwNTA2MDAyNzU1WjCBoTEL\nMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExETAPBgNVBAcTCFNhbiBK\nb3NlMRUwEwYDVQQKEwxac2NhbGVyIEluYy4xFTATBgNVBAsTDFpzY2FsZXIgSW5j\nLjEYMBYGA1UEAxMPWnNjYWxlciBSb290IENBMSIwIAYJKoZIhvcNAQkBFhNzdXBw\nb3J0QHpzY2FsZXIuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA\nqT7STSxZRTgEFFf6doHajSc1vk5jmzmM6BWuOo044EsaTc9eVEV/HjH/1DWzZtcr\nfTj+ni205apMTlKBW3UYR+lyLHQ9FoZiDXYXK8poKSV5+Tm0Vls/5Kb8mkhVVqv7\nLgYEmvEY7HPY+i1nEGZCa46ZXCOohJ0mBEtB9JVlpDIO+nN0hUMAYYdZ1KZWCMNf\n5J/aTZiShsorN2A38iSOhdd+mcRM4iNL3gsLu99XhKnRqKoHeH83lVdfu1XBeoQz\nz5V6gA3kbRvhDwoIlTBeMa5l4yRdJAfdpkbFzqiwSgNdhbxTHnYYorDzKfr2rEFM\ndsMU0DHdeAZf711+1CunuQIDAQABo4IBCjCCAQYwHQYDVR0OBBYEFLm33UrNww4M\nhp1d3+wcBGnFTpjfMIHWBgNVHSMEgc4wgcuAFLm33UrNww4Mhp1d3+wcBGnFTpjf\noYGnpIGkMIGhMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTERMA8G\nA1UEBxMIU2FuIEpvc2UxFTATBgNVBAoTDFpzY2FsZXIgSW5jLjEVMBMGA1UECxMM\nWnNjYWxlciBJbmMuMRgwFgYDVQQDEw9ac2NhbGVyIFJvb3QgQ0ExIjAgBgkqhkiG\n9w0BCQEWE3N1cHBvcnRAenNjYWxlci5jb22CCQDbvpgtibd7kzAMBgNVHRMEBTAD\nAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQAw0NdJh8w3NsJu4KHuVZUrmZgIohnTm0j+\nRTmYQ9IKA/pvxAcA6K1i/LO+Bt+tCX+C0yxqB8qzuo+4vAzoY5JEBhyhBhf1uK+P\n/WVWFZN/+hTgpSbZgzUEnWQG2gOVd24msex+0Sr7hyr9vn6OueH+jj+vCMiAm5+u\nkd7lLvJsBu3AO3jGWVLyPkS3i6Gf+rwAp1OsRrv3WnbkYcFf9xjuaf4z0hRCrLN2\nxFNjavxrHmsH8jPHVvgc1VD0Opja0l/BRVauTrUaoW6tE+wFG5rEcPGS80jjHK4S\npB5iDj2mUZH1T8lzYtuZy0ZPirxmtsk3135+CKNa2OCAhhFjE0xd\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIESzCCAzOgAwIBAgICAQEwDQYJKoZIhvcNAQELBQAwgaExCzAJBgNVBAYTAlVT\nMRMwEQYDVQQIEwpDYWxpZm9ybmlhMREwDwYDVQQHEwhTYW4gSm9zZTEVMBMGA1UE\nChMMWnNjYWxlciBJbmMuMRUwEwYDVQQLEwxac2NhbGVyIEluYy4xGDAWBgNVBAMT\nD1pzY2FsZXIgUm9vdCBDQTEiMCAGCSqGSIb3DQEJARYTc3VwcG9ydEB6c2NhbGVy\nLmNvbTAeFw0yMDA2MDUwNTMyNDRaFw00MTA2MjMwNTMyNDRaMIGuMQswCQYDVQQG\nEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEVMBMGA1UEChMMWnNjYWxlciBJbmMu\nMRUwEwYDVQQLEwxac2NhbGVyIEluYy4xODA2BgNVBAMTL1pzY2FsZXIgSW50ZXJt\nZWRpYXRlIFJvb3QgQ0EgKHpzY2FsZXJ0aHJlZS5uZXQpMSIwIAYJKoZIhvcNAQkB\nFhNzdXBwb3J0QHpzY2FsZXIuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIB\nCgKCAQEAmioqA+ZMX9KzDDO6VXfPWU4dQ3Knj68Y16L50vd6cAxY6CyBclodGxA1\nmwyIv+Q+kV1oaaoowMGjMDQVyCWFa3w7MaiJdx1x0XgtO1u6nEtA7hRaYnJb+/8J\nLRdXjXQpPNRuis7CE/jfpaUn4zikoBWk3GPQ3ZePX8PdQDtPd47Le5AXNd8rCpFR\nMOJSvZYYrlcEWqMbdBs5sSE3B2UKxQ00Qbj8eQHpvH1/aEa48KsY+9q4ZlB2xzS7\nAklK0NFwuebkhR9JTN59o9rxqVwGJhUbQGpUhMnG+g+4b1qrxRsyOFfludc9UjS5\nofjSsZk5ypGZf5W/npp6Ctz+Qc/gkwIDAQABo34wfDAdBgNVHQ4EFgQUB5R6G+iB\ndfUCJzsePyRCVDjsGdkwDAYDVR0TBAUwAwEB/zALBgNVHQ8EBAMCAf4wQAYDVR0f\nBDkwNzA1oDOgMYYvaHR0cDovL2dhdGV3YXkuenNjYWxlcnRocmVlLm5ldC9jcmwv\nenMzLWludC5jcmwwDQYJKoZIhvcNAQELBQADggEBAD4Jc1RkDa/0ktmwdWqEpTGa\nJuKuN8BY9J7yusclOKKXef8XcAH4Zb/D/9sOWc7PSQKZ0jbGcSmuUjkZZfHnpJ8s\nY3chfEdl4BbVYsg1zF+3b0LrD09+8JHYBYIzE1Rc0/WSQtt/wra1aBijDqZWme3t\n/qB7xTH7VyLg0bz5v178+tcbBWyT4YRydInl5rlOFCWheb9wnF0O4wqh2ZdObagf\nxURV25gYLODsE86fWm/GWSTMytp/Cp1+dVpZVqOx2GbTsxhtM+EmTTptu2ixmLMZ\niPwYIidlYicHBgfhnEv6O2ukM3LeD/IeqdCmhptBKgsWDuxj7t/nUgzaETHuJL4=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\n2dbWAFZtIJCBkzFB\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\nKqClq3gnEytH0g==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\nukxwysXvK5fMqjg0G1UVn2pOsgUKGEBzLOwBiq/4xbUja+Y=\n-----END CERTIFICATE-----\n\n\n-----BEGIN CERTIFICATE-----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\nIMLDPEm0C0fPfnNViYnAIx66tXi6cEvSu3cagXeHa8PpAw6O\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\nKuaoZ8ZJba4dWrcnuYhfAuZwg/Hcr8YbkzwjdAw2jg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIFHTCCAwWgAwIBAgIQGQAgWCt94IRNpVmNTEmCDDANBgkqhkiG9w0BAQsFADAh\nMR8wHQYDVQQDExZOQ1NEZXZOZXQgUHJvZCBSb290IENBMB4XDTI0MTAwNDA5MTQ0\nNFoXDTQ0MTAwNDA5MjQ0M1owITEfMB0GA1UEAxMWTkNTRGV2TmV0IFByb2QgUm9v\ndCBDQTCCAiIwDQYJKoZIhvcNAQEBBQADggIPADCCAgoCggIBAKeglq4tsgEQuy9u\n1SSFVR0YdjRBBrba95BFRNYYHya8zbvJrUTY3aGwftNGKfvj+PZtLmjwKZUdIIQb\nqXi6ysbC6MBKrREwUxT6j9ONcWvm+pV8kgrFS1+gEt7xSX4KzaIJbR7B2MkR91GV\nQ8rJgDUCYZbbmTEoZ3gZWu+ae8xDfyNcAF12KxyXpdCTwiQ3I84EGUoqW0VlbyNU\nuAc2XIAFB9onQX31gCZLShKE9i41czsi2lXjyXegkuuGfkC1nYbQws4ECXkXl397\nK2GdgJ1E8ePoed26qfYGmu6K4RmfnfY98b7j42n1lu+wwx+Edi//Pus/Sdk29YrX\nA5u5NTq4TVKPocpL1MeOhzc2XshHbKS14ZXdY6VcGWIaGsOB2lJ2b2PEyYytKJVc\nTlr2SUnIRr5Yxn7Dttju1myuOHfDu4AXoYswM5D9MGWT3+HWe2onERd6kICmSe0b\nzaAhH12ml9UUX4UMx0Mw6D4ew//xI2uw8pAv0VzU+r9UontVxuoWMek8zpAimxuY\nPT36oCJUOMkiIEg2ihohNY/+nZ6N3g8s53ldqAn1oGL6sv1SA7B729/yGLIngA6l\nUJ7g5QAtEmR8PcJB2hFRGs2o8eQzrpVZgxM89rikLIPRXCqudLajiIna1iY7TMcA\neESBn86We77wj212hn3G4j+k2j7RAgMBAAGjUTBPMAsGA1UdDwQEAwIBhjAPBgNV\nHRMBAf8EBTADAQH/MB0GA1UdDgQWBBSy94Kn5kkkja5ug0M0yltVMweYCTAQBgkr\nBgEEAYI3FQEEAwIBADANBgkqhkiG9w0BAQsFAAOCAgEACGws1+VsSNwRpy2+sAys\nPAnJ0LF+l0MaW3T3g5c2rExwwR4mYgH9EghWnarLNAO28yxhtemovXcmBWsIurK1\nX0wgYqFBMoizjxtjA4SrqDHqkSMWpsF7yGAMhc3x5MFsM2WCGD3mcjJRPTQmcRRL\nGcGmaUdgm2v+q3BwyRsZAiSgSnrjpPjnFuPI+RF9mOxF5mpsR5DFBCzYp2deptvF\nNnRf506h0nJbCUXbDeAxdacKqL5jO/06hO7OW/uYyc51GE1C5+SM1Wfe4e54KQQM\niXJM/2m7YNtHmJSPCvJzpeEKhMkXRwxmQeRNqFzvxyVBNQaqAmFd2Gij+boDfHBJ\n4KlF77+730RVZeIVL8cTBMizTFkAk7DUsDo+99+M5SNQTuxyQvj1WiUed518DjS5\nZ6dGNhZbNx2bgx0hi0a5C19SvtKa1OFRwCgiS0M6PgVnm59uA3FwHrLwlhhzmVTU\nsCxyTWh7lx1GEPOwXf0NdSn6kXs4X3MWoOAlDslo28a8hN50fkON4JaNcCIi0koQ\n+rCOs9M5G4ZNvQVrkBqccOWUewEn3NNeo+Yy5Nx4kmKn0nZ6bICb0ek/GaWcaGQZ\nEepzgY+Efq00LL8qXH4QWg+B/+rL1rBJndoI1JB0fmtUJSD7XGcim2bYEiE/eSaT\njvlvccMaCzx1UZGSJhZNxiQ=\n-----END CERTIFICATE-----\n\n\n-----BEGIN CERTIFICATE-----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\n-----END CERTIFICATE-----\n"
              },
              "ragflow_chat_api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "RAGFlow Chat API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "ragflow_chat_api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "ragflow-uJGoQOClfbtTh1OAmm25y2zhawWGbbOUZSswvtszLvo"
              },
              "ragflow_chat_base_url": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "RAGFlow Chat Base URL",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "ragflow_chat_base_url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://ragflow-ui.devnet.int/api/v1/chats_openai"
              },
              "ragflow_chat_id": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "RAGFlow Chat Id",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "ragflow_chat_id",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "4ee54264b4ab11f0b2056ec56199ba7f"
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "# Role\nYou are a professional business analyst with more than 20-year experience in a world class software development company. Having functional user from the bank as the audience of your documentation. The bank is now requesting you to write a functional specification document on the cobol code they provide. Please provide information in a business formal, professional style. Please write in a concise and informative tone. By referring to the knowledge base in the dataset, it gives you a better understanding of the cobol structure and definition. \n\n# Task\nYour primary task is to analyze the COBOL Summary documents and the source codes running on HP non-stop tandem provided by the user and generate a comprehensive, structured Markdown functional document. This document must be purely diecribing the function of all the Summary documents, the document is also code language independent. Focus on the functionality and outcome of the codes and summary.\n\n# Instructions and Workflow\n1.  **Complete Summary Analysis**: First, thoroughly read and understand the entire Summary files including the business logic and funcations. \n\n# Background\nEach module consists of a list of COBOL summary documents in markdown format. Each COBOL summary document summarizes one COBOL source code file. The summaries and the source code are stored in the dataset as a knowledge base. All provided Summary and codes belongs to the same module. \n\n# Constraints and Limitations\n* **Adhere to Original Text**: All explanations and analyses must strictly be based on the provided COBOL code; do not guess or add functionalities do not present in the code.\n* **Professional Terminology**: Use professional and accurate terminology while ensuring clarity.\n* **Language**: Conduct analysis and documentation writing in English.\n* **Format**: Strictly follow the defined Markdown output format below, without omitting any part.\n"
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 3600
              },
              "use_responses_api": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Use Responses API",
                "dynamic": false,
                "info": "Whether to use the Responses API instead of the Chat API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "use_responses_api",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "selected_output": "model_output",
          "showNode": true,
          "type": "RAGFlowChatModel"
        },
        "dragging": false,
        "id": "RAGFlowChatModel-RNPtF",
        "measured": {
          "height": 783,
          "width": 320
        },
        "position": {
          "x": 1979.798657333919,
          "y": 610.859341985557
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-yOiBQ",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "Text Input",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "# Role\nYou are a professional business analyst with more than 20-year experience in a world class software development company. Having functional user from the bank as the audience of your documentation. The bank is now requesting you to write a functional specification document on the cobol code they provide. Please provide information in a business formal, professional style. Please write in a concise and informative tone. By referring to the knowledge base in the dataset, it gives you a better understanding of the cobol structure and definition. \n\n# Background\nEach module consists of a list of COBOL summary documents in markdown format. Each COBOL summary document summarizes one COBOL source code file. The summaries and the source code are stored in the dataset as a knowledge base. All provided Summary and codes belongs to the same module. \n\n# Task\nYour primary task is to analyze the COBOL Summary documents and the source codes running on HP non-stop tandem provided by the user and generate a comprehensive, structured Markdown functional specification document. This functional specification document must be purely describing the function of all the Summary documents, the functional specification document must be code language independent. Focus on the functionality and outcome of the codes and summary.\n\n# Instructions and Workflow\n1.  **Complete Summary Analysis**: First, read and understand the entire cobol Summary files in the knowledge base including the business logic and functions. \n2.  **Extract Function from Code Summary**: Summarize the business function of each cobol summary files.\n3.  **Integrate all Functions**: Summarize the key business function of all cobol summary file.\n4.  **Reference from Manual FSD**: Prodive the functional specification document in the format of Functional Specifications - CPF SRS POC (Trade Settlement) v0.6.docx in the knowledge base. But do not copy content from this reference document. Only take reference of the format.\n\n# Constraints and Limitations\n* **Adhere to Original Text**: All explanations and analyses must strictly be based on the provided cobol code Summary, COBOL source code; do not guess or add functionalities do not present in the code.\n* **Professional Terminology**: Use professional and accurate terminology while ensuring clarity.\n* **Language**: Conduct analysis and documentation writing in English.\n* **Format**: Strictly follow the defined Markdown output format below, without omitting any part.\n\n\nHere is the knowledge base:\n{knowledge}\nThe above is the knowledge base."
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-yOiBQ",
        "measured": {
          "height": 212,
          "width": 320
        },
        "position": {
          "x": 1570.2199738565548,
          "y": 834.400769979219
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "BatchRunComponent-agd5D",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.",
            "display_name": "Batch Run",
            "documentation": "https://docs.langflow.org/components-processing#batch-run",
            "edited": false,
            "field_order": [
              "model",
              "system_message",
              "df",
              "column_name",
              "output_column_name",
              "enable_metadata"
            ],
            "frozen": false,
            "icon": "List",
            "key": "BatchRunComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "LLM Results",
                "group_outputs": false,
                "method": "run_batch",
                "name": "batch_results",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, cast\n\nimport toml  # type: ignore[import-untyped]\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DataFrameInput, HandleInput, MessageTextInput, MultilineInput, Output\nfrom langflow.logging.logger import logger\nfrom langflow.schema.dataframe import DataFrame\n\nif TYPE_CHECKING:\n    from langchain_core.runnables import Runnable\n\n\nclass BatchRunComponent(Component):\n    display_name = \"Batch Run\"\n    description = \"Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#batch-run\"\n    icon = \"List\"\n\n    inputs = [\n        HandleInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Connect the 'Language Model' output from your LLM component here.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"Instructions\",\n            info=\"Multi-line system instruction for all rows in the DataFrame.\",\n            required=False,\n        ),\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The DataFrame whose column (specified by 'column_name') we'll treat as text messages.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=(\n                \"The name of the DataFrame column to treat as text messages. \"\n                \"If empty, all columns will be formatted in TOML.\"\n            ),\n            required=False,\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"output_column_name\",\n            display_name=\"Output Column Name\",\n            info=\"Name of the column where the model's response will be stored.\",\n            value=\"model_response\",\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_metadata\",\n            display_name=\"Enable Metadata\",\n            info=\"If True, add metadata to the output DataFrame.\",\n            value=False,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"LLM Results\",\n            name=\"batch_results\",\n            method=\"run_batch\",\n            info=\"A DataFrame with all original columns plus the model's response column.\",\n        ),\n    ]\n\n    def _format_row_as_toml(self, row: dict[str, Any]) -> str:\n        \"\"\"Convert a dictionary (row) into a TOML-formatted string.\"\"\"\n        formatted_dict = {str(col): {\"value\": str(val)} for col, val in row.items()}\n        return toml.dumps(formatted_dict)\n\n    def _create_base_row(\n        self, original_row: dict[str, Any], model_response: str = \"\", batch_index: int = -1\n    ) -> dict[str, Any]:\n        \"\"\"Create a base row with original columns and additional metadata.\"\"\"\n        row = original_row.copy()\n        row[self.output_column_name] = model_response\n        row[\"batch_index\"] = batch_index\n        return row\n\n    def _add_metadata(\n        self, row: dict[str, Any], *, success: bool = True, system_msg: str = \"\", error: str | None = None\n    ) -> None:\n        \"\"\"Add metadata to a row if enabled.\"\"\"\n        if not self.enable_metadata:\n            return\n\n        if success:\n            row[\"metadata\"] = {\n                \"has_system_message\": bool(system_msg),\n                \"input_length\": len(row.get(\"text_input\", \"\")),\n                \"response_length\": len(row[self.output_column_name]),\n                \"processing_status\": \"success\",\n            }\n        else:\n            row[\"metadata\"] = {\n                \"error\": error,\n                \"processing_status\": \"failed\",\n            }\n\n    async def run_batch(self) -> DataFrame:\n        \"\"\"Process each row in df[column_name] with the language model asynchronously.\n\n        Returns:\n            DataFrame: A new DataFrame containing:\n                - All original columns\n                - The model's response column (customizable name)\n                - 'batch_index' column for processing order\n                - 'metadata' (optional)\n\n        Raises:\n            ValueError: If the specified column is not found in the DataFrame\n            TypeError: If the model is not compatible or input types are wrong\n        \"\"\"\n        model: Runnable = self.model\n        system_msg = self.system_message or \"\"\n        df: DataFrame = self.df\n        col_name = self.column_name or \"\"\n\n        # Validate inputs first\n        if not isinstance(df, DataFrame):\n            msg = f\"Expected DataFrame input, got {type(df)}\"\n            raise TypeError(msg)\n\n        if col_name and col_name not in df.columns:\n            msg = f\"Column '{col_name}' not found in the DataFrame. Available columns: {', '.join(df.columns)}\"\n            raise ValueError(msg)\n\n        try:\n            # Determine text input for each row\n            if col_name:\n                user_texts = df[col_name].astype(str).tolist()\n            else:\n                user_texts = [\n                    self._format_row_as_toml(cast(\"dict[str, Any]\", row)) for row in df.to_dict(orient=\"records\")\n                ]\n\n            total_rows = len(user_texts)\n            await logger.ainfo(f\"Processing {total_rows} rows with batch run\")\n\n            # Prepare the batch of conversations\n            conversations = [\n                [{\"role\": \"system\", \"content\": system_msg}, {\"role\": \"user\", \"content\": text}]\n                if system_msg\n                else [{\"role\": \"user\", \"content\": text}]\n                for text in user_texts\n            ]\n\n            # Configure the model with project info and callbacks\n            model = model.with_config(\n                {\n                    \"run_name\": self.display_name,\n                    \"project_name\": self.get_project_name(),\n                    \"callbacks\": self.get_langchain_callbacks(),\n                }\n            )\n            # Process batches and track progress\n            responses_with_idx = list(\n                zip(\n                    range(len(conversations)),\n                    await model.abatch(list(conversations)),\n                    strict=True,\n                )\n            )\n\n            # Sort by index to maintain order\n            responses_with_idx.sort(key=lambda x: x[0])\n\n            # Build the final data with enhanced metadata\n            rows: list[dict[str, Any]] = []\n            for idx, (original_row, response) in enumerate(\n                zip(df.to_dict(orient=\"records\"), responses_with_idx, strict=False)\n            ):\n                response_text = response[1].content if hasattr(response[1], \"content\") else str(response[1])\n                row = self._create_base_row(\n                    cast(\"dict[str, Any]\", original_row), model_response=response_text, batch_index=idx\n                )\n                self._add_metadata(row, success=True, system_msg=system_msg)\n                rows.append(row)\n\n                # Log progress\n                if (idx + 1) % max(1, total_rows // 10) == 0:\n                    await logger.ainfo(f\"Processed {idx + 1}/{total_rows} rows\")\n\n            await logger.ainfo(\"Batch processing completed successfully\")\n            return DataFrame(rows)\n\n        except (KeyError, AttributeError) as e:\n            # Handle data structure and attribute access errors\n            await logger.aerror(f\"Data processing error: {e!s}\")\n            error_row = self._create_base_row(dict.fromkeys(df.columns, \"\"), model_response=\"\", batch_index=-1)\n            self._add_metadata(error_row, success=False, error=str(e))\n            return DataFrame([error_row])\n"
              },
              "column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": false,
                "info": "The name of the DataFrame column to treat as text messages. If empty, all columns will be formatted in TOML.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Query1"
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The DataFrame whose column (specified by 'column_name') we'll treat as text messages.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "enable_metadata": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Enable Metadata",
                "dynamic": false,
                "info": "If True, add metadata to the output DataFrame.",
                "list": false,
                "list_add_label": "Add More",
                "name": "enable_metadata",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Connect the 'Language Model' output from your LLM component here.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "model",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Output Column Name",
                "dynamic": false,
                "info": "Name of the column where the model's response will be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "model_response_1"
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Instructions",
                "dynamic": false,
                "info": "Multi-line system instruction for all rows in the DataFrame.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "BatchRunComponent"
        },
        "dragging": false,
        "id": "BatchRunComponent-agd5D",
        "measured": {
          "height": 522,
          "width": 320
        },
        "position": {
          "x": 2595.4444082012524,
          "y": 1252.526582962201
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "BatchRunComponent-v2I2a",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.",
            "display_name": "Batch Run",
            "documentation": "https://docs.langflow.org/components-processing#batch-run",
            "edited": false,
            "field_order": [
              "model",
              "system_message",
              "df",
              "column_name",
              "output_column_name",
              "enable_metadata"
            ],
            "frozen": false,
            "icon": "List",
            "key": "BatchRunComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "LLM Results",
                "group_outputs": false,
                "method": "run_batch",
                "name": "batch_results",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, cast\n\nimport toml  # type: ignore[import-untyped]\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DataFrameInput, HandleInput, MessageTextInput, MultilineInput, Output\nfrom langflow.logging.logger import logger\nfrom langflow.schema.dataframe import DataFrame\n\nif TYPE_CHECKING:\n    from langchain_core.runnables import Runnable\n\n\nclass BatchRunComponent(Component):\n    display_name = \"Batch Run\"\n    description = \"Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#batch-run\"\n    icon = \"List\"\n\n    inputs = [\n        HandleInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Connect the 'Language Model' output from your LLM component here.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"Instructions\",\n            info=\"Multi-line system instruction for all rows in the DataFrame.\",\n            required=False,\n        ),\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The DataFrame whose column (specified by 'column_name') we'll treat as text messages.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=(\n                \"The name of the DataFrame column to treat as text messages. \"\n                \"If empty, all columns will be formatted in TOML.\"\n            ),\n            required=False,\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"output_column_name\",\n            display_name=\"Output Column Name\",\n            info=\"Name of the column where the model's response will be stored.\",\n            value=\"model_response\",\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_metadata\",\n            display_name=\"Enable Metadata\",\n            info=\"If True, add metadata to the output DataFrame.\",\n            value=False,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"LLM Results\",\n            name=\"batch_results\",\n            method=\"run_batch\",\n            info=\"A DataFrame with all original columns plus the model's response column.\",\n        ),\n    ]\n\n    def _format_row_as_toml(self, row: dict[str, Any]) -> str:\n        \"\"\"Convert a dictionary (row) into a TOML-formatted string.\"\"\"\n        formatted_dict = {str(col): {\"value\": str(val)} for col, val in row.items()}\n        return toml.dumps(formatted_dict)\n\n    def _create_base_row(\n        self, original_row: dict[str, Any], model_response: str = \"\", batch_index: int = -1\n    ) -> dict[str, Any]:\n        \"\"\"Create a base row with original columns and additional metadata.\"\"\"\n        row = original_row.copy()\n        row[self.output_column_name] = model_response\n        row[\"batch_index\"] = batch_index\n        return row\n\n    def _add_metadata(\n        self, row: dict[str, Any], *, success: bool = True, system_msg: str = \"\", error: str | None = None\n    ) -> None:\n        \"\"\"Add metadata to a row if enabled.\"\"\"\n        if not self.enable_metadata:\n            return\n\n        if success:\n            row[\"metadata\"] = {\n                \"has_system_message\": bool(system_msg),\n                \"input_length\": len(row.get(\"text_input\", \"\")),\n                \"response_length\": len(row[self.output_column_name]),\n                \"processing_status\": \"success\",\n            }\n        else:\n            row[\"metadata\"] = {\n                \"error\": error,\n                \"processing_status\": \"failed\",\n            }\n\n    async def run_batch(self) -> DataFrame:\n        \"\"\"Process each row in df[column_name] with the language model asynchronously.\n\n        Returns:\n            DataFrame: A new DataFrame containing:\n                - All original columns\n                - The model's response column (customizable name)\n                - 'batch_index' column for processing order\n                - 'metadata' (optional)\n\n        Raises:\n            ValueError: If the specified column is not found in the DataFrame\n            TypeError: If the model is not compatible or input types are wrong\n        \"\"\"\n        model: Runnable = self.model\n        system_msg = self.system_message or \"\"\n        df: DataFrame = self.df\n        col_name = self.column_name or \"\"\n\n        # Validate inputs first\n        if not isinstance(df, DataFrame):\n            msg = f\"Expected DataFrame input, got {type(df)}\"\n            raise TypeError(msg)\n\n        if col_name and col_name not in df.columns:\n            msg = f\"Column '{col_name}' not found in the DataFrame. Available columns: {', '.join(df.columns)}\"\n            raise ValueError(msg)\n\n        try:\n            # Determine text input for each row\n            if col_name:\n                user_texts = df[col_name].astype(str).tolist()\n            else:\n                user_texts = [\n                    self._format_row_as_toml(cast(\"dict[str, Any]\", row)) for row in df.to_dict(orient=\"records\")\n                ]\n\n            total_rows = len(user_texts)\n            await logger.ainfo(f\"Processing {total_rows} rows with batch run\")\n\n            # Prepare the batch of conversations\n            conversations = [\n                [{\"role\": \"system\", \"content\": system_msg}, {\"role\": \"user\", \"content\": text}]\n                if system_msg\n                else [{\"role\": \"user\", \"content\": text}]\n                for text in user_texts\n            ]\n\n            # Configure the model with project info and callbacks\n            model = model.with_config(\n                {\n                    \"run_name\": self.display_name,\n                    \"project_name\": self.get_project_name(),\n                    \"callbacks\": self.get_langchain_callbacks(),\n                }\n            )\n            # Process batches and track progress\n            responses_with_idx = list(\n                zip(\n                    range(len(conversations)),\n                    await model.abatch(list(conversations)),\n                    strict=True,\n                )\n            )\n\n            # Sort by index to maintain order\n            responses_with_idx.sort(key=lambda x: x[0])\n\n            # Build the final data with enhanced metadata\n            rows: list[dict[str, Any]] = []\n            for idx, (original_row, response) in enumerate(\n                zip(df.to_dict(orient=\"records\"), responses_with_idx, strict=False)\n            ):\n                response_text = response[1].content if hasattr(response[1], \"content\") else str(response[1])\n                row = self._create_base_row(\n                    cast(\"dict[str, Any]\", original_row), model_response=response_text, batch_index=idx\n                )\n                self._add_metadata(row, success=True, system_msg=system_msg)\n                rows.append(row)\n\n                # Log progress\n                if (idx + 1) % max(1, total_rows // 10) == 0:\n                    await logger.ainfo(f\"Processed {idx + 1}/{total_rows} rows\")\n\n            await logger.ainfo(\"Batch processing completed successfully\")\n            return DataFrame(rows)\n\n        except (KeyError, AttributeError) as e:\n            # Handle data structure and attribute access errors\n            await logger.aerror(f\"Data processing error: {e!s}\")\n            error_row = self._create_base_row(dict.fromkeys(df.columns, \"\"), model_response=\"\", batch_index=-1)\n            self._add_metadata(error_row, success=False, error=str(e))\n            return DataFrame([error_row])\n"
              },
              "column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": false,
                "info": "The name of the DataFrame column to treat as text messages. If empty, all columns will be formatted in TOML.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Query2"
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The DataFrame whose column (specified by 'column_name') we'll treat as text messages.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "enable_metadata": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Enable Metadata",
                "dynamic": false,
                "info": "If True, add metadata to the output DataFrame.",
                "list": false,
                "list_add_label": "Add More",
                "name": "enable_metadata",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Connect the 'Language Model' output from your LLM component here.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "model",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Output Column Name",
                "dynamic": false,
                "info": "Name of the column where the model's response will be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "model_response_2"
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Instructions",
                "dynamic": false,
                "info": "Multi-line system instruction for all rows in the DataFrame.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "BatchRunComponent"
        },
        "dragging": false,
        "id": "BatchRunComponent-v2I2a",
        "measured": {
          "height": 522,
          "width": 320
        },
        "position": {
          "x": 2981.8533957871045,
          "y": 1259.3510806395823
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "BatchRunComponent-2B7ke",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.",
            "display_name": "Batch Run",
            "documentation": "https://docs.langflow.org/components-processing#batch-run",
            "edited": false,
            "field_order": [
              "model",
              "system_message",
              "df",
              "column_name",
              "output_column_name",
              "enable_metadata"
            ],
            "frozen": false,
            "icon": "List",
            "key": "BatchRunComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "LLM Results",
                "group_outputs": false,
                "method": "run_batch",
                "name": "batch_results",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, cast\n\nimport toml  # type: ignore[import-untyped]\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DataFrameInput, HandleInput, MessageTextInput, MultilineInput, Output\nfrom langflow.logging.logger import logger\nfrom langflow.schema.dataframe import DataFrame\n\nif TYPE_CHECKING:\n    from langchain_core.runnables import Runnable\n\n\nclass BatchRunComponent(Component):\n    display_name = \"Batch Run\"\n    description = \"Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#batch-run\"\n    icon = \"List\"\n\n    inputs = [\n        HandleInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Connect the 'Language Model' output from your LLM component here.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"Instructions\",\n            info=\"Multi-line system instruction for all rows in the DataFrame.\",\n            required=False,\n        ),\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The DataFrame whose column (specified by 'column_name') we'll treat as text messages.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=(\n                \"The name of the DataFrame column to treat as text messages. \"\n                \"If empty, all columns will be formatted in TOML.\"\n            ),\n            required=False,\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"output_column_name\",\n            display_name=\"Output Column Name\",\n            info=\"Name of the column where the model's response will be stored.\",\n            value=\"model_response\",\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_metadata\",\n            display_name=\"Enable Metadata\",\n            info=\"If True, add metadata to the output DataFrame.\",\n            value=False,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"LLM Results\",\n            name=\"batch_results\",\n            method=\"run_batch\",\n            info=\"A DataFrame with all original columns plus the model's response column.\",\n        ),\n    ]\n\n    def _format_row_as_toml(self, row: dict[str, Any]) -> str:\n        \"\"\"Convert a dictionary (row) into a TOML-formatted string.\"\"\"\n        formatted_dict = {str(col): {\"value\": str(val)} for col, val in row.items()}\n        return toml.dumps(formatted_dict)\n\n    def _create_base_row(\n        self, original_row: dict[str, Any], model_response: str = \"\", batch_index: int = -1\n    ) -> dict[str, Any]:\n        \"\"\"Create a base row with original columns and additional metadata.\"\"\"\n        row = original_row.copy()\n        row[self.output_column_name] = model_response\n        row[\"batch_index\"] = batch_index\n        return row\n\n    def _add_metadata(\n        self, row: dict[str, Any], *, success: bool = True, system_msg: str = \"\", error: str | None = None\n    ) -> None:\n        \"\"\"Add metadata to a row if enabled.\"\"\"\n        if not self.enable_metadata:\n            return\n\n        if success:\n            row[\"metadata\"] = {\n                \"has_system_message\": bool(system_msg),\n                \"input_length\": len(row.get(\"text_input\", \"\")),\n                \"response_length\": len(row[self.output_column_name]),\n                \"processing_status\": \"success\",\n            }\n        else:\n            row[\"metadata\"] = {\n                \"error\": error,\n                \"processing_status\": \"failed\",\n            }\n\n    async def run_batch(self) -> DataFrame:\n        \"\"\"Process each row in df[column_name] with the language model asynchronously.\n\n        Returns:\n            DataFrame: A new DataFrame containing:\n                - All original columns\n                - The model's response column (customizable name)\n                - 'batch_index' column for processing order\n                - 'metadata' (optional)\n\n        Raises:\n            ValueError: If the specified column is not found in the DataFrame\n            TypeError: If the model is not compatible or input types are wrong\n        \"\"\"\n        model: Runnable = self.model\n        system_msg = self.system_message or \"\"\n        df: DataFrame = self.df\n        col_name = self.column_name or \"\"\n\n        # Validate inputs first\n        if not isinstance(df, DataFrame):\n            msg = f\"Expected DataFrame input, got {type(df)}\"\n            raise TypeError(msg)\n\n        if col_name and col_name not in df.columns:\n            msg = f\"Column '{col_name}' not found in the DataFrame. Available columns: {', '.join(df.columns)}\"\n            raise ValueError(msg)\n\n        try:\n            # Determine text input for each row\n            if col_name:\n                user_texts = df[col_name].astype(str).tolist()\n            else:\n                user_texts = [\n                    self._format_row_as_toml(cast(\"dict[str, Any]\", row)) for row in df.to_dict(orient=\"records\")\n                ]\n\n            total_rows = len(user_texts)\n            await logger.ainfo(f\"Processing {total_rows} rows with batch run\")\n\n            # Prepare the batch of conversations\n            conversations = [\n                [{\"role\": \"system\", \"content\": system_msg}, {\"role\": \"user\", \"content\": text}]\n                if system_msg\n                else [{\"role\": \"user\", \"content\": text}]\n                for text in user_texts\n            ]\n\n            # Configure the model with project info and callbacks\n            model = model.with_config(\n                {\n                    \"run_name\": self.display_name,\n                    \"project_name\": self.get_project_name(),\n                    \"callbacks\": self.get_langchain_callbacks(),\n                }\n            )\n            # Process batches and track progress\n            responses_with_idx = list(\n                zip(\n                    range(len(conversations)),\n                    await model.abatch(list(conversations)),\n                    strict=True,\n                )\n            )\n\n            # Sort by index to maintain order\n            responses_with_idx.sort(key=lambda x: x[0])\n\n            # Build the final data with enhanced metadata\n            rows: list[dict[str, Any]] = []\n            for idx, (original_row, response) in enumerate(\n                zip(df.to_dict(orient=\"records\"), responses_with_idx, strict=False)\n            ):\n                response_text = response[1].content if hasattr(response[1], \"content\") else str(response[1])\n                row = self._create_base_row(\n                    cast(\"dict[str, Any]\", original_row), model_response=response_text, batch_index=idx\n                )\n                self._add_metadata(row, success=True, system_msg=system_msg)\n                rows.append(row)\n\n                # Log progress\n                if (idx + 1) % max(1, total_rows // 10) == 0:\n                    await logger.ainfo(f\"Processed {idx + 1}/{total_rows} rows\")\n\n            await logger.ainfo(\"Batch processing completed successfully\")\n            return DataFrame(rows)\n\n        except (KeyError, AttributeError) as e:\n            # Handle data structure and attribute access errors\n            await logger.aerror(f\"Data processing error: {e!s}\")\n            error_row = self._create_base_row(dict.fromkeys(df.columns, \"\"), model_response=\"\", batch_index=-1)\n            self._add_metadata(error_row, success=False, error=str(e))\n            return DataFrame([error_row])\n"
              },
              "column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": false,
                "info": "The name of the DataFrame column to treat as text messages. If empty, all columns will be formatted in TOML.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Query3"
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The DataFrame whose column (specified by 'column_name') we'll treat as text messages.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "enable_metadata": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Enable Metadata",
                "dynamic": false,
                "info": "If True, add metadata to the output DataFrame.",
                "list": false,
                "list_add_label": "Add More",
                "name": "enable_metadata",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Connect the 'Language Model' output from your LLM component here.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "model",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Output Column Name",
                "dynamic": false,
                "info": "Name of the column where the model's response will be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "model_response_3"
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Instructions",
                "dynamic": false,
                "info": "Multi-line system instruction for all rows in the DataFrame.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "BatchRunComponent"
        },
        "dragging": false,
        "id": "BatchRunComponent-2B7ke",
        "measured": {
          "height": 522,
          "width": 320
        },
        "position": {
          "x": 3383.897820036066,
          "y": 1268.5406674795584
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "BatchRunComponent-M53dp",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.",
            "display_name": "Batch Run",
            "documentation": "https://docs.langflow.org/components-processing#batch-run",
            "edited": false,
            "field_order": [
              "model",
              "system_message",
              "df",
              "column_name",
              "output_column_name",
              "enable_metadata"
            ],
            "frozen": false,
            "icon": "List",
            "key": "BatchRunComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "LLM Results",
                "group_outputs": false,
                "method": "run_batch",
                "name": "batch_results",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, cast\n\nimport toml  # type: ignore[import-untyped]\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DataFrameInput, HandleInput, MessageTextInput, MultilineInput, Output\nfrom langflow.logging.logger import logger\nfrom langflow.schema.dataframe import DataFrame\n\nif TYPE_CHECKING:\n    from langchain_core.runnables import Runnable\n\n\nclass BatchRunComponent(Component):\n    display_name = \"Batch Run\"\n    description = \"Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#batch-run\"\n    icon = \"List\"\n\n    inputs = [\n        HandleInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Connect the 'Language Model' output from your LLM component here.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"Instructions\",\n            info=\"Multi-line system instruction for all rows in the DataFrame.\",\n            required=False,\n        ),\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The DataFrame whose column (specified by 'column_name') we'll treat as text messages.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=(\n                \"The name of the DataFrame column to treat as text messages. \"\n                \"If empty, all columns will be formatted in TOML.\"\n            ),\n            required=False,\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"output_column_name\",\n            display_name=\"Output Column Name\",\n            info=\"Name of the column where the model's response will be stored.\",\n            value=\"model_response\",\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_metadata\",\n            display_name=\"Enable Metadata\",\n            info=\"If True, add metadata to the output DataFrame.\",\n            value=False,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"LLM Results\",\n            name=\"batch_results\",\n            method=\"run_batch\",\n            info=\"A DataFrame with all original columns plus the model's response column.\",\n        ),\n    ]\n\n    def _format_row_as_toml(self, row: dict[str, Any]) -> str:\n        \"\"\"Convert a dictionary (row) into a TOML-formatted string.\"\"\"\n        formatted_dict = {str(col): {\"value\": str(val)} for col, val in row.items()}\n        return toml.dumps(formatted_dict)\n\n    def _create_base_row(\n        self, original_row: dict[str, Any], model_response: str = \"\", batch_index: int = -1\n    ) -> dict[str, Any]:\n        \"\"\"Create a base row with original columns and additional metadata.\"\"\"\n        row = original_row.copy()\n        row[self.output_column_name] = model_response\n        row[\"batch_index\"] = batch_index\n        return row\n\n    def _add_metadata(\n        self, row: dict[str, Any], *, success: bool = True, system_msg: str = \"\", error: str | None = None\n    ) -> None:\n        \"\"\"Add metadata to a row if enabled.\"\"\"\n        if not self.enable_metadata:\n            return\n\n        if success:\n            row[\"metadata\"] = {\n                \"has_system_message\": bool(system_msg),\n                \"input_length\": len(row.get(\"text_input\", \"\")),\n                \"response_length\": len(row[self.output_column_name]),\n                \"processing_status\": \"success\",\n            }\n        else:\n            row[\"metadata\"] = {\n                \"error\": error,\n                \"processing_status\": \"failed\",\n            }\n\n    async def run_batch(self) -> DataFrame:\n        \"\"\"Process each row in df[column_name] with the language model asynchronously.\n\n        Returns:\n            DataFrame: A new DataFrame containing:\n                - All original columns\n                - The model's response column (customizable name)\n                - 'batch_index' column for processing order\n                - 'metadata' (optional)\n\n        Raises:\n            ValueError: If the specified column is not found in the DataFrame\n            TypeError: If the model is not compatible or input types are wrong\n        \"\"\"\n        model: Runnable = self.model\n        system_msg = self.system_message or \"\"\n        df: DataFrame = self.df\n        col_name = self.column_name or \"\"\n\n        # Validate inputs first\n        if not isinstance(df, DataFrame):\n            msg = f\"Expected DataFrame input, got {type(df)}\"\n            raise TypeError(msg)\n\n        if col_name and col_name not in df.columns:\n            msg = f\"Column '{col_name}' not found in the DataFrame. Available columns: {', '.join(df.columns)}\"\n            raise ValueError(msg)\n\n        try:\n            # Determine text input for each row\n            if col_name:\n                user_texts = df[col_name].astype(str).tolist()\n            else:\n                user_texts = [\n                    self._format_row_as_toml(cast(\"dict[str, Any]\", row)) for row in df.to_dict(orient=\"records\")\n                ]\n\n            total_rows = len(user_texts)\n            await logger.ainfo(f\"Processing {total_rows} rows with batch run\")\n\n            # Prepare the batch of conversations\n            conversations = [\n                [{\"role\": \"system\", \"content\": system_msg}, {\"role\": \"user\", \"content\": text}]\n                if system_msg\n                else [{\"role\": \"user\", \"content\": text}]\n                for text in user_texts\n            ]\n\n            # Configure the model with project info and callbacks\n            model = model.with_config(\n                {\n                    \"run_name\": self.display_name,\n                    \"project_name\": self.get_project_name(),\n                    \"callbacks\": self.get_langchain_callbacks(),\n                }\n            )\n            # Process batches and track progress\n            responses_with_idx = list(\n                zip(\n                    range(len(conversations)),\n                    await model.abatch(list(conversations)),\n                    strict=True,\n                )\n            )\n\n            # Sort by index to maintain order\n            responses_with_idx.sort(key=lambda x: x[0])\n\n            # Build the final data with enhanced metadata\n            rows: list[dict[str, Any]] = []\n            for idx, (original_row, response) in enumerate(\n                zip(df.to_dict(orient=\"records\"), responses_with_idx, strict=False)\n            ):\n                response_text = response[1].content if hasattr(response[1], \"content\") else str(response[1])\n                row = self._create_base_row(\n                    cast(\"dict[str, Any]\", original_row), model_response=response_text, batch_index=idx\n                )\n                self._add_metadata(row, success=True, system_msg=system_msg)\n                rows.append(row)\n\n                # Log progress\n                if (idx + 1) % max(1, total_rows // 10) == 0:\n                    await logger.ainfo(f\"Processed {idx + 1}/{total_rows} rows\")\n\n            await logger.ainfo(\"Batch processing completed successfully\")\n            return DataFrame(rows)\n\n        except (KeyError, AttributeError) as e:\n            # Handle data structure and attribute access errors\n            await logger.aerror(f\"Data processing error: {e!s}\")\n            error_row = self._create_base_row(dict.fromkeys(df.columns, \"\"), model_response=\"\", batch_index=-1)\n            self._add_metadata(error_row, success=False, error=str(e))\n            return DataFrame([error_row])\n"
              },
              "column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": false,
                "info": "The name of the DataFrame column to treat as text messages. If empty, all columns will be formatted in TOML.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Query4"
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The DataFrame whose column (specified by 'column_name') we'll treat as text messages.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "enable_metadata": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Enable Metadata",
                "dynamic": false,
                "info": "If True, add metadata to the output DataFrame.",
                "list": false,
                "list_add_label": "Add More",
                "name": "enable_metadata",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Connect the 'Language Model' output from your LLM component here.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "model",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Output Column Name",
                "dynamic": false,
                "info": "Name of the column where the model's response will be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "model_response_4"
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Instructions",
                "dynamic": false,
                "info": "Multi-line system instruction for all rows in the DataFrame.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "BatchRunComponent"
        },
        "dragging": false,
        "id": "BatchRunComponent-M53dp",
        "measured": {
          "height": 522,
          "width": 320
        },
        "position": {
          "x": 3790.6309747758824,
          "y": 1265.2184134349095
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-9bxjG",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": true,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "hidden": null,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response_1}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-9bxjG",
        "measured": {
          "height": 327,
          "width": 320
        },
        "position": {
          "x": 4792.487882886516,
          "y": 843.0207020156884
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-UK5tM",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": true,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "hidden": null,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response_2}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-UK5tM",
        "measured": {
          "height": 327,
          "width": 320
        },
        "position": {
          "x": 4794.267347440364,
          "y": 1258.2370866955948
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-HadYb",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": true,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "hidden": null,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response_3}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-HadYb",
        "measured": {
          "height": 327,
          "width": 320
        },
        "position": {
          "x": 4793.389094085057,
          "y": 1659.9751469626528
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-90P7C",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": true,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "hidden": null,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response_4}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-90P7C",
        "measured": {
          "height": 327,
          "width": 320
        },
        "position": {
          "x": 4811.175363186791,
          "y": 2076.6698208475204
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CombineText-WjgZh",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
            "display_name": "Combine Text",
            "documentation": "",
            "edited": true,
            "field_order": [
              "text1",
              "text2",
              "text3",
              "text4",
              "text5",
              "delimiter"
            ],
            "frozen": false,
            "icon": "merge",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Combined Text",
                "group_outputs": false,
                "hidden": null,
                "method": "combine_texts",
                "name": "combined_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations"
            ],
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n    legacy: bool = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text3\",\n            display_name=\"Third Text\",\n            info=\"The third text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text4\",\n            display_name=\"4th Text\",\n            info=\"The 4th text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text5\",\n            display_name=\"5th Text\",\n            info=\"The 5th text input to concatenate.\",\n        ),\n        # MessageTextInput(\n        #     name=\"text6\",\n        #     display_name=\"6th Text\",\n        #     info=\"The 6th text input to concatenate.\",\n        # ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2, self.text3, self.text4, self.text5]) #, self.text6\n        self.status = combined\n        return Message(text=combined)\n"
              },
              "delimiter": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Delimiter",
                "dynamic": false,
                "info": "A string used to separate the two text inputs. Defaults to a whitespace.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "delimiter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": " \\n\\n"
              },
              "text1": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "First Text",
                "dynamic": false,
                "info": "The first text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text1",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text2": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Second Text",
                "dynamic": false,
                "info": "The second text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text2",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text3": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Third Text",
                "dynamic": false,
                "info": "The third text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text3",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text4": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "4th Text",
                "dynamic": false,
                "info": "The 4th text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text4",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text5": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "5th Text",
                "dynamic": false,
                "info": "The 5th text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text5",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CombineText"
        },
        "dragging": false,
        "id": "CombineText-WjgZh",
        "measured": {
          "height": 709,
          "width": 320
        },
        "position": {
          "x": 5306.639506464841,
          "y": 1242.0156937839943
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "MessageToLocalFile-gKwMk",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Saves a LangFlow Message as a local file using extracted Program ID.",
            "display_name": "Message to Local File",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input",
              "output_folder",
              "file_extension",
              "custom_filename"
            ],
            "frozen": false,
            "icon": "file",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Result Message",
                "group_outputs": false,
                "hidden": null,
                "method": "build_output",
                "name": "result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from pathlib import Path\r\nimport re\r\nfrom collections.abc import AsyncIterator, Iterator\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import StrInput, MessageInput, Output\r\nfrom langflow.schema import Message\r\nfrom langflow.inputs import MessageTextInput\r\n\r\n\r\nclass FileBuilderComponent(Component):\r\n    display_name = \"Message to Local File\"\r\n    description = \"Saves a LangFlow Message as a local file using extracted Program ID.\"\r\n    icon = \"file\"\r\n    name = \"MessageToLocalFile\"\r\n\r\n    inputs = [\r\n        MessageInput(\r\n            name=\"input\",\r\n            display_name=\"Input Message\",\r\n            required=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"output_folder\",\r\n            display_name=\"Output Folder\",\r\n            info=\"Folder path to save the file locally.\",\r\n            value=\"/app/data\",\r\n            required=False,\r\n        ),\r\n        StrInput(\r\n            name=\"file_extension\",\r\n            display_name=\"File Extension\",\r\n            info=\"Extension for the saved file (e.g. txt, md, json)\",\r\n            value=\"txt\",\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"custom_filename\",\r\n            display_name=\"Custom Filename\",\r\n            info=\"Optional: specify a custom filename (without extension). If left blank, the Program ID will be used.\",\r\n            value=\"\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"Result Message\",\r\n            name=\"result\",\r\n            method=\"build_output\",\r\n        ),\r\n    ]\r\n\r\n    async def build_output(self) -> Message:\r\n        \"\"\"Saves a Message as a local file using the Program ID for naming.\"\"\"\r\n\r\n        message: Message = self.input\r\n        content = self._extract_text(message)\r\n\r\n        program_id = self.custom_filename\r\n        file_name = f\"FSD_{program_id}.{self.file_extension.lstrip('.')}\"\r\n        # raise ValueError(self.output_folder)\r\n        output_path = Path(self.output_folder) / file_name\r\n\r\n        output_path.parent.mkdir(parents=True, exist_ok=True)\r\n        output_path.write_text(content, encoding=\"utf-8\")\r\n\r\n        return Message(text=f\"✅ File saved locally as '{output_path.resolve()}'.\")\r\n\r\n    def _extract_text(self, message: Message) -> str:\r\n        \"\"\"Extracts text from a Message object.\"\"\"\r\n        if isinstance(message.text, AsyncIterator):\r\n            return \"\".join([str(item async for item in message.text)])\r\n        elif isinstance(message.text, Iterator):\r\n            return \"\".join(str(item) for item in message.text)\r\n        return str(message.text)\r\n\r\n    # def _extract_program_id(self, content: str) -> str:\r\n    #     \"\"\"Extracts the Program ID from the message content.\"\"\"\r\n    #     lines = content.splitlines()\r\n    #     if len(lines) >= 3:\r\n    #         line = lines[2].strip()\r\n    #         match = re.search(r\"\\*\\s+\\*\\*Program ID\\*\\*:\\s*(\\w+)\", line)\r\n    #         if match:\r\n    #             return match.group(1)\r\n    #     raise ValueError(\"Could not extract Program ID from message content.\")\r\n"
              },
              "custom_filename": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Custom Filename",
                "dynamic": false,
                "info": "Optional: specify a custom filename (without extension). If left blank, the Program ID will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "custom_filename",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "bmcsoftware_vscode-ispw"
              },
              "file_extension": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "File Extension",
                "dynamic": false,
                "info": "Extension for the saved file (e.g. txt, md, json)",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "file_extension",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "md"
              },
              "input": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input Message",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "output_folder": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Output Folder",
                "dynamic": false,
                "info": "Folder path to save the file locally.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_folder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "/data/projects/cobol-test/FSD_Gen/Output"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "MessageToLocalFile"
        },
        "dragging": false,
        "id": "MessageToLocalFile-gKwMk",
        "measured": {
          "height": 383,
          "width": 320
        },
        "position": {
          "x": 6709.765347373743,
          "y": 1751.3903774211367
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-poa5g",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "Text Input",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextInput",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.00004500241402777085,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "## 1. System Overview\n\n* **System Summary**: This system represents a critical component of the bank's transaction processing infrastructure, designed to handle financial transaction data through a series of structured processing steps that ensure data integrity, compliance, and accurate reporting. The system operates within a batch processing environment on HP Non-Stop Tandem platforms, adhering to strict transactional integrity requirements essential for financial operations. It consists of two primary COBOL programs that work in tandem to process transaction data, validate business rules, and generate standardized summary reports for downstream systems. The system assumes that input transaction data will be provided in a structured format with predefined record layouts, and that all necessary file resources (input, output, and error logs) will be properly configured and accessible. Key system requirements include robust error handling mechanisms to prevent data corruption, comprehensive validation of transaction parameters against banking-specific business rules, and the ability to generate formatted reports that meet regulatory and internal reporting standards. The system must maintain auditability through detailed logging of all processing activities and errors, with specific error codes for different validation failures. It is designed to process large volumes of transaction data efficiently while ensuring data accuracy and consistency across all operations. The system operates within a secure environment where transactional integrity is paramount, with explicit checks for file status codes after every I/O operation to handle unexpected termination scenarios. The system's architecture emphasizes modularity through well-defined subroutines and validation routines that can be independently tested and maintained.\n\n* **Function Description**: The system provides automated transaction processing and reporting capabilities for the bank's financial operations. It processes transaction data to generate comprehensive summary reports that aggregate key metrics including total transaction amounts, transaction counts, and category-specific totals. The system validates transaction records against business rules and regulatory requirements, ensuring data integrity before processing. It handles error conditions through detailed logging and appropriate error handling mechanisms, preventing invalid data from propagating through the system. The system produces formatted output reports suitable for business intelligence systems, management reporting, and compliance requirements. It serves as a critical component in the bank's daily operational reporting pipeline, enabling efficient data consolidation for reconciliation, audit, and regulatory reporting purposes. The system eliminates manual data re-entry and reduces error risk in financial reporting processes, supporting the bank's operational efficiency and compliance obligations.\n\n* **Main Processes**:\n  1. **Input Data Processing**: Reads sequential transaction records from predefined input files, performing field-level validation checks to ensure data integrity. This includes validation of date formats, numeric constraints, and mandatory fields.\n  2. **Transaction Validation**: Validates transaction types against allowed values, checks account types (e.g., SAVINGS, CHECKING), and verifies transaction amounts against business rules including minimum/maximum limits and positive value requirements.\n  3. **Transaction Aggregation**: Computes cumulative totals for transaction amounts, transaction counts, and category-specific aggregates using working storage variables. This includes maintaining separate totals for different transaction categories and account types.\n  4. **Error Handling and Logging**: Checks for invalid data entries and logs errors to a dedicated error file while skipping erroneous records to maintain data integrity. The system implements detailed error logging with specific error codes for different validation failures.\n  5. **Report Generation**: Formats aggregated results into structured output reports with headers, line-item details, and summary totals. The reports adhere to predefined layout specifications for compatibility with downstream systems.\n  6. **File Management**: Manages file I/O operations including opening, closing, and sequential processing of input/output files. Ensures proper file status checks to handle unexpected termination scenarios.\n  7. **Summary Calculation**: Performs arithmetic operations on accumulated metrics during record processing, including calculating averages, minimums, and maximums where applicable.\n  8. **Termination and Cleanup**: Performs final checks on data integrity, closes all open files, and updates system logs with execution metrics before program termination. This includes generating summary status indicators based on processing outcomes."
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-poa5g",
        "measured": {
          "height": 212,
          "width": 320
        },
        "position": {
          "x": 5875.69574029308,
          "y": 767.1671365345998
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SplitMessageToQueryData-jnuZz",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Splits a Message text by '------' and outputs a Data object with keys 'Query1', 'Query2', etc.",
            "display_name": "Split Message to Query Data",
            "documentation": "",
            "edited": true,
            "field_order": [
              "message"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Query Data",
                "group_outputs": false,
                "hidden": null,
                "method": "split_message_to_data",
                "name": "query_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\r\nfrom langflow.inputs.inputs import HandleInput\r\nfrom langflow.io import Output\r\nfrom langflow.schema.message import Message\r\nfrom langflow.schema.data import Data\r\n\r\n\r\nclass SplitMessageToQueryDataComponent(Component):\r\n    display_name = \"Split Message to Query Data\"\r\n    description = \"Splits a Message text by '------' and outputs a Data object with keys 'Query1', 'Query2', etc.\"\r\n    name = \"SplitMessageToQueryData\"\r\n    icon = \"split\"\r\n    legacy = True\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"message\",\r\n            display_name=\"Input Message\",\r\n            input_types=[\"Message\"],\r\n            info=\"The message whose text will be split by '------'.\",\r\n            required=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"Query Data\",\r\n            name=\"query_data\",\r\n            method=\"split_message_to_data\",\r\n        ),\r\n    ]\r\n\r\n    def split_message_to_data(self) -> Data:\r\n        # Ensure valid Message input\r\n        if not isinstance(self.message, Message):\r\n            raise ValueError(\"Input must be a Langflow Message.\")\r\n\r\n        text = (self.message.text or \"\").strip()\r\n        if not text:\r\n            raise ValueError(\"Message text is empty.\")\r\n\r\n        # Split by delimiter and clean whitespace\r\n        split_items = [chunk.strip() for chunk in text.split(\"------\") if chunk.strip()]\r\n\r\n        if not split_items:\r\n            raise ValueError(\"No valid content found after splitting by '------'.\")\r\n\r\n        # Build dictionary with Query1, Query2, ...\r\n        data_dict = {f\"Query{i+1}\": chunk for i, chunk in enumerate(split_items)}\r\n\r\n        # Wrap in Langflow Data object\r\n        data_obj = Data(data=data_dict)\r\n\r\n        # Update component status in UI\r\n        self.status = f\"Created Data with {len(split_items)} queries.\"\r\n        \r\n        \r\n\r\n        return data_obj\r\n"
              },
              "message": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input Message",
                "dynamic": false,
                "info": "The message whose text will be split by '------'.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "message",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SplitMessageToQueryData"
        },
        "dragging": false,
        "id": "SplitMessageToQueryData-jnuZz",
        "measured": {
          "height": 260,
          "width": 320
        },
        "position": {
          "x": 1574.5094243362114,
          "y": 1469.748580828025
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-ByoEB",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": []
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "display_name": "code",
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "\nBy analyzing all cobol Summary document in the knowledge base, provide the Business Overview, write no less than 300 words in this session. Generate the Business Overview one time only, do not repeat. Strictly follow the defined Markdown output format below, without omitting any part.\n\n## 1. Business Overview\n\n* **Business Summary**: Describe the high level business summary including overall concept of the module, business problem. \n* **Business Goal**: A concise summary of the main goal this module is trying archieve, including how to tackle the business problem, and module outcome.\n\n\n------\n\nBy analyzing all cobol Summary document in the knowledge base, provide a high level architecture diagram. Use Mermaid syntax to visualize the architecture diagram. \nPlease strictly generate the document in the following Markdown structure:\n\n## 2. High Level Architecture Diagram\n```mermaid\nflowchart TD\n\n    %% Frontend to Gateway\n    A[Front-End Web/Mobile Client] -->|REST/HTTPS| B[SOA Gateway]\n\n    %% Gateway to Application Server\n    B -->|API Routing / Auth / Logging| C[Application Server]\n\n    %% Application Server to Storage\n    C -->|Business Logic Calls| D[(Storage: Database / Data Lake)]\n\n    %% External Interfaces\n    C -->|External API Calls| E[External System 1 Partner API]\n    C -->|External API Calls| F[External System 2 Payment Gateway]\n\n    %% Tier Grouping\n    subgraph User_Tier [User Tier]\n        A\n    end\n\n    subgraph Integration_Tier [Integration Tier]\n        B\n    end\n\n    subgraph Application_Tier [Application Tier]\n        C\n    end\n\n    subgraph Data_Tier [Data Tier]\n        D\n    end\n\n    subgraph External_Interfaces [External Interfaces]\n        E\n        F\n    end\n```\n\n------\n\nBy analyzing all cobol Summary document in the knowledge base, provide the Functional Overview. Generate the Functional Overview one time only, do not repeat. \nInclude below features in the diagram.\n\t\t1) All participants as swimlanes such as system users, customer, bank's IT team etc. \n\t\t2) The system, including front end UI, system, external parties, and backend database etc.\n\t\t3) Business activities of the participants. Describe what action is performed (e.g., “Validate Order,” “Generate Invoice,” “Send Notification”). Each action should be a box in the diagram. Show the interactions between participants and system.\n\t\t4) Decision diamonds and arrows, showing the business logic. such as “Is Customer Credit Approved?” → Yes → Proceed; No → Reject Order.\n\t\t5) Input and Output, indicate the Starting action and the End of the business flow.\n\nStrictly follow the defined Markdown output format below, without omitting any part.\n\n## 3. Functional Overview\n\nProvide a high-level summary of system functions and business flows.\n\n* **Business Process Diagram**:\n\t```mermaid\n\tflowchart LR\n\t  %% Define directions\n\t  direction LR\n\n\t  %% === Swimlane: Customer ===\n\t  subgraph CUSTOMER[Customer]\n\t\tA1[1. Submit Order]\n\t\tA9[9. Receive Confirmation]\n\t  end\n\n\t  %% === Swimlane: Sales System ===\n\t  subgraph SALES[Sales System]\n\t\tB2[2. Receive Order Request]\n\t\tB5[5. If In Stock?]\n\t\tB8[8. Confirm Order]\n\t  end\n\n\t  %% === Swimlane: Inventory System ===\n\t  subgraph INVENTORY[Inventory System]\n\t\tC3[3. Check Stock Availability]\n\t\tC4[4. Return Stock Result]\n\t  end\n\n\t  %% === Swimlane: Billing System ===\n\t  subgraph BILLING[Billing System]\n\t\tD6[6. Generate Invoice & Payment Request]\n\t\tD7[7. Return Payment Status]\n\t  end\n\n\t  %% === Flows Between Swimlanes ===\n\t  A1 --> B2\n\t  B2 --> C3\n\t  C3 --> C4 --> B5\n\n\t  B5 -->|In Stock| D6\n\t  D6 --> D7 --> B8\n\t  B8 --> A9\n\t```\n------\n\nBy analyzing all cobol Summary document in the knowledge base, provide the General Assumption and Dependencies. State any assumptions or dependencies on other systems, teams, or processes. Generate the Assumption and Dependencies one time only, do not repeat. Strictly follow the defined Markdown output format below, without omitting any part.\n\n## 4. Assumption and Dependencies\n\n* **General Assumption**:\n\t* `[Assumption 1]`: Detailed Assumption descripion. \n\t* `[Assumption 2]`: Detailed Assumption descripion. \n\t...\n\n* **General Dependency**:\n\t* `[Dependency 1]`: Detailed Dependency descripion. \n\t* `[Dependency 2]`: Detailed Dependency descripion. \n\t...\n\t\n------\n\nBy analyzing all cobol Summary document in the knowledge base, provide the Function List. List out all the functions in logical order and provide the summary document as reference for that function. Do not miss out any function. Provide the function name in english and a high level function describtion. Strictly follow the defined Markdown output format below, without omitting any part. Each function has to be seperated with ;;;;;;. Only provide the top 3 most important functions.\n\n* `[Function name 1]`: Function descripion. From [Summary_code_file_name_1]\n;;;;;;\n* `[Function name 2]`: Function descripion. From [Summary_code_file_name_2]\n;;;;;;\n...\n* `[Function name n]`: Function descripion. From [Summary_code_file_name_n]\n\t\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-ByoEB",
        "measured": {
          "height": 292,
          "width": 320
        },
        "position": {
          "x": 1135.0980156932312,
          "y": 1453.0428765065353
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "BatchRunComponent-XXTFh",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.",
            "display_name": "Batch Run",
            "documentation": "https://docs.langflow.org/components-processing#batch-run",
            "edited": false,
            "field_order": [
              "model",
              "system_message",
              "df",
              "column_name",
              "output_column_name",
              "enable_metadata"
            ],
            "frozen": false,
            "icon": "List",
            "key": "BatchRunComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "LLM Results",
                "group_outputs": false,
                "method": "run_batch",
                "name": "batch_results",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, cast\n\nimport toml  # type: ignore[import-untyped]\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DataFrameInput, HandleInput, MessageTextInput, MultilineInput, Output\nfrom langflow.logging.logger import logger\nfrom langflow.schema.dataframe import DataFrame\n\nif TYPE_CHECKING:\n    from langchain_core.runnables import Runnable\n\n\nclass BatchRunComponent(Component):\n    display_name = \"Batch Run\"\n    description = \"Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#batch-run\"\n    icon = \"List\"\n\n    inputs = [\n        HandleInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Connect the 'Language Model' output from your LLM component here.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"Instructions\",\n            info=\"Multi-line system instruction for all rows in the DataFrame.\",\n            required=False,\n        ),\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The DataFrame whose column (specified by 'column_name') we'll treat as text messages.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=(\n                \"The name of the DataFrame column to treat as text messages. \"\n                \"If empty, all columns will be formatted in TOML.\"\n            ),\n            required=False,\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"output_column_name\",\n            display_name=\"Output Column Name\",\n            info=\"Name of the column where the model's response will be stored.\",\n            value=\"model_response\",\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_metadata\",\n            display_name=\"Enable Metadata\",\n            info=\"If True, add metadata to the output DataFrame.\",\n            value=False,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"LLM Results\",\n            name=\"batch_results\",\n            method=\"run_batch\",\n            info=\"A DataFrame with all original columns plus the model's response column.\",\n        ),\n    ]\n\n    def _format_row_as_toml(self, row: dict[str, Any]) -> str:\n        \"\"\"Convert a dictionary (row) into a TOML-formatted string.\"\"\"\n        formatted_dict = {str(col): {\"value\": str(val)} for col, val in row.items()}\n        return toml.dumps(formatted_dict)\n\n    def _create_base_row(\n        self, original_row: dict[str, Any], model_response: str = \"\", batch_index: int = -1\n    ) -> dict[str, Any]:\n        \"\"\"Create a base row with original columns and additional metadata.\"\"\"\n        row = original_row.copy()\n        row[self.output_column_name] = model_response\n        row[\"batch_index\"] = batch_index\n        return row\n\n    def _add_metadata(\n        self, row: dict[str, Any], *, success: bool = True, system_msg: str = \"\", error: str | None = None\n    ) -> None:\n        \"\"\"Add metadata to a row if enabled.\"\"\"\n        if not self.enable_metadata:\n            return\n\n        if success:\n            row[\"metadata\"] = {\n                \"has_system_message\": bool(system_msg),\n                \"input_length\": len(row.get(\"text_input\", \"\")),\n                \"response_length\": len(row[self.output_column_name]),\n                \"processing_status\": \"success\",\n            }\n        else:\n            row[\"metadata\"] = {\n                \"error\": error,\n                \"processing_status\": \"failed\",\n            }\n\n    async def run_batch(self) -> DataFrame:\n        \"\"\"Process each row in df[column_name] with the language model asynchronously.\n\n        Returns:\n            DataFrame: A new DataFrame containing:\n                - All original columns\n                - The model's response column (customizable name)\n                - 'batch_index' column for processing order\n                - 'metadata' (optional)\n\n        Raises:\n            ValueError: If the specified column is not found in the DataFrame\n            TypeError: If the model is not compatible or input types are wrong\n        \"\"\"\n        model: Runnable = self.model\n        system_msg = self.system_message or \"\"\n        df: DataFrame = self.df\n        col_name = self.column_name or \"\"\n\n        # Validate inputs first\n        if not isinstance(df, DataFrame):\n            msg = f\"Expected DataFrame input, got {type(df)}\"\n            raise TypeError(msg)\n\n        if col_name and col_name not in df.columns:\n            msg = f\"Column '{col_name}' not found in the DataFrame. Available columns: {', '.join(df.columns)}\"\n            raise ValueError(msg)\n\n        try:\n            # Determine text input for each row\n            if col_name:\n                user_texts = df[col_name].astype(str).tolist()\n            else:\n                user_texts = [\n                    self._format_row_as_toml(cast(\"dict[str, Any]\", row)) for row in df.to_dict(orient=\"records\")\n                ]\n\n            total_rows = len(user_texts)\n            await logger.ainfo(f\"Processing {total_rows} rows with batch run\")\n\n            # Prepare the batch of conversations\n            conversations = [\n                [{\"role\": \"system\", \"content\": system_msg}, {\"role\": \"user\", \"content\": text}]\n                if system_msg\n                else [{\"role\": \"user\", \"content\": text}]\n                for text in user_texts\n            ]\n\n            # Configure the model with project info and callbacks\n            model = model.with_config(\n                {\n                    \"run_name\": self.display_name,\n                    \"project_name\": self.get_project_name(),\n                    \"callbacks\": self.get_langchain_callbacks(),\n                }\n            )\n            # Process batches and track progress\n            responses_with_idx = list(\n                zip(\n                    range(len(conversations)),\n                    await model.abatch(list(conversations)),\n                    strict=True,\n                )\n            )\n\n            # Sort by index to maintain order\n            responses_with_idx.sort(key=lambda x: x[0])\n\n            # Build the final data with enhanced metadata\n            rows: list[dict[str, Any]] = []\n            for idx, (original_row, response) in enumerate(\n                zip(df.to_dict(orient=\"records\"), responses_with_idx, strict=False)\n            ):\n                response_text = response[1].content if hasattr(response[1], \"content\") else str(response[1])\n                row = self._create_base_row(\n                    cast(\"dict[str, Any]\", original_row), model_response=response_text, batch_index=idx\n                )\n                self._add_metadata(row, success=True, system_msg=system_msg)\n                rows.append(row)\n\n                # Log progress\n                if (idx + 1) % max(1, total_rows // 10) == 0:\n                    await logger.ainfo(f\"Processed {idx + 1}/{total_rows} rows\")\n\n            await logger.ainfo(\"Batch processing completed successfully\")\n            return DataFrame(rows)\n\n        except (KeyError, AttributeError) as e:\n            # Handle data structure and attribute access errors\n            await logger.aerror(f\"Data processing error: {e!s}\")\n            error_row = self._create_base_row(dict.fromkeys(df.columns, \"\"), model_response=\"\", batch_index=-1)\n            self._add_metadata(error_row, success=False, error=str(e))\n            return DataFrame([error_row])\n"
              },
              "column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Column Name",
                "dynamic": false,
                "info": "The name of the DataFrame column to treat as text messages. If empty, all columns will be formatted in TOML.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Query5"
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The DataFrame whose column (specified by 'column_name') we'll treat as text messages.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "enable_metadata": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Enable Metadata",
                "dynamic": false,
                "info": "If True, add metadata to the output DataFrame.",
                "list": false,
                "list_add_label": "Add More",
                "name": "enable_metadata",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Connect the 'Language Model' output from your LLM component here.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "model",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_column_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Output Column Name",
                "dynamic": false,
                "info": "Name of the column where the model's response will be stored.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_column_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "model_response_5"
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Instructions",
                "dynamic": false,
                "info": "Multi-line system instruction for all rows in the DataFrame.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "BatchRunComponent"
        },
        "dragging": false,
        "id": "BatchRunComponent-XXTFh",
        "measured": {
          "height": 522,
          "width": 320
        },
        "position": {
          "x": 4211.464436949036,
          "y": 1268.788657724482
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-a6CY9",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": true,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "hidden": null,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response_5}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-a6CY9",
        "measured": {
          "height": 327,
          "width": 320
        },
        "position": {
          "x": 4807.754508622447,
          "y": 2463.316161072805
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LoopComponent-iCfBD",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Iterates over a list of Data objects, outputting one item at a time and aggregating results from loop inputs.",
            "display_name": "Loop",
            "documentation": "https://docs.langflow.org/components-logic#loop",
            "edited": false,
            "field_order": [
              "data"
            ],
            "frozen": false,
            "icon": "infinity",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": true,
                "cache": true,
                "display_name": "Item",
                "group_outputs": true,
                "method": "item_output",
                "name": "item",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Done",
                "group_outputs": true,
                "method": "done_output",
                "name": "done",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.template.field.base import Output\n\n\nclass LoopComponent(Component):\n    display_name = \"Loop\"\n    description = (\n        \"Iterates over a list of Data objects, outputting one item at a time and aggregating results from loop inputs.\"\n    )\n    documentation: str = \"https://docs.langflow.org/components-logic#loop\"\n    icon = \"infinity\"\n\n    inputs = [\n        HandleInput(\n            name=\"data\",\n            display_name=\"Inputs\",\n            info=\"The initial list of Data objects or DataFrame to iterate over.\",\n            input_types=[\"DataFrame\"],\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Item\", name=\"item\", method=\"item_output\", allows_loop=True, group_outputs=True),\n        Output(display_name=\"Done\", name=\"done\", method=\"done_output\", group_outputs=True),\n    ]\n\n    def initialize_data(self) -> None:\n        \"\"\"Initialize the data list, context index, and aggregated list.\"\"\"\n        if self.ctx.get(f\"{self._id}_initialized\", False):\n            return\n\n        # Ensure data is a list of Data objects\n        data_list = self._validate_data(self.data)\n\n        # Store the initial data and context variables\n        self.update_ctx(\n            {\n                f\"{self._id}_data\": data_list,\n                f\"{self._id}_index\": 0,\n                f\"{self._id}_aggregated\": [],\n                f\"{self._id}_initialized\": True,\n            }\n        )\n\n    def _validate_data(self, data):\n        \"\"\"Validate and return a list of Data objects.\"\"\"\n        if isinstance(data, DataFrame):\n            return data.to_data_list()\n        if isinstance(data, Data):\n            return [data]\n        if isinstance(data, list) and all(isinstance(item, Data) for item in data):\n            return data\n        msg = \"The 'data' input must be a DataFrame, a list of Data objects, or a single Data object.\"\n        raise TypeError(msg)\n\n    def evaluate_stop_loop(self) -> bool:\n        \"\"\"Evaluate whether to stop item or done output.\"\"\"\n        current_index = self.ctx.get(f\"{self._id}_index\", 0)\n        data_length = len(self.ctx.get(f\"{self._id}_data\", []))\n        return current_index > data_length\n\n    def item_output(self) -> Data:\n        \"\"\"Output the next item in the list or stop if done.\"\"\"\n        self.initialize_data()\n        current_item = Data(text=\"\")\n\n        if self.evaluate_stop_loop():\n            self.stop(\"item\")\n        else:\n            # Get data list and current index\n            data_list, current_index = self.loop_variables()\n            if current_index < len(data_list):\n                # Output current item and increment index\n                try:\n                    current_item = data_list[current_index]\n                except IndexError:\n                    current_item = Data(text=\"\")\n            self.aggregated_output()\n            self.update_ctx({f\"{self._id}_index\": current_index + 1})\n\n        # Now we need to update the dependencies for the next run\n        self.update_dependency()\n        return current_item\n\n    def update_dependency(self):\n        item_dependency_id = self.get_incoming_edge_by_target_param(\"item\")\n        if item_dependency_id not in self.graph.run_manager.run_predecessors[self._id]:\n            self.graph.run_manager.run_predecessors[self._id].append(item_dependency_id)\n\n    def done_output(self) -> DataFrame:\n        \"\"\"Trigger the done output when iteration is complete.\"\"\"\n        self.initialize_data()\n\n        if self.evaluate_stop_loop():\n            self.stop(\"item\")\n            self.start(\"done\")\n\n            aggregated = self.ctx.get(f\"{self._id}_aggregated\", [])\n\n            return DataFrame(aggregated)\n        self.stop(\"done\")\n        return DataFrame([])\n\n    def loop_variables(self):\n        \"\"\"Retrieve loop variables from context.\"\"\"\n        return (\n            self.ctx.get(f\"{self._id}_data\", []),\n            self.ctx.get(f\"{self._id}_index\", 0),\n        )\n\n    def aggregated_output(self) -> list[Data]:\n        \"\"\"Return the aggregated list once all items are processed.\"\"\"\n        self.initialize_data()\n\n        # Get data list and aggregated list\n        data_list = self.ctx.get(f\"{self._id}_data\", [])\n        aggregated = self.ctx.get(f\"{self._id}_aggregated\", [])\n        loop_input = self.item\n        if loop_input is not None and not isinstance(loop_input, str) and len(aggregated) <= len(data_list):\n            aggregated.append(loop_input)\n            self.update_ctx({f\"{self._id}_aggregated\": aggregated})\n        return aggregated\n"
              },
              "data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "The initial list of Data objects or DataFrame to iterate over.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "LoopComponent"
        },
        "dragging": false,
        "id": "LoopComponent-iCfBD",
        "measured": {
          "height": 250,
          "width": 320
        },
        "position": {
          "x": 6184.962253176964,
          "y": 2078.693939668163
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SplitMessageToQueryData-jIQQY",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Splits a Message text by '------' and outputs a Data object with keys 'Query1', 'Query2', etc.",
            "display_name": "Split Message to Query Data",
            "documentation": "",
            "edited": true,
            "field_order": [
              "message"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Query Data",
                "group_outputs": false,
                "hidden": null,
                "method": "split_message_to_data",
                "name": "query_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\r\nfrom langflow.inputs.inputs import HandleInput\r\nfrom langflow.io import Output\r\nfrom langflow.schema.message import Message\r\nfrom langflow.schema.data import Data\r\n\r\n\r\nclass SplitMessageToQueryDataComponent(Component):\r\n    display_name = \"Split Message to Query Data\"\r\n    description = \"Splits a Message text by '------' and outputs a Data object with keys 'Query1', 'Query2', etc.\"\r\n    name = \"SplitMessageToQueryData\"\r\n    icon = \"split\"\r\n    legacy = True\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"message\",\r\n            display_name=\"Input Message\",\r\n            input_types=[\"Message\"],\r\n            info=\"The message whose text will be split by '------'.\",\r\n            required=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"Query Data\",\r\n            name=\"query_data\",\r\n            method=\"split_message_to_data\",\r\n        ),\r\n    ]\r\n\r\n    def split_message_to_data(self) -> Data:\r\n        # Ensure valid Message input\r\n        if not isinstance(self.message, Message):\r\n            raise ValueError(\"Input must be a Langflow Message.\")\r\n\r\n        text = (self.message.text or \"\").strip()\r\n        if not text:\r\n            raise ValueError(\"Message text is empty.\")\r\n\r\n        # Split by delimiter and clean whitespace\r\n        split_items = [chunk.strip() for chunk in text.split(\";;;;;;\") if chunk.strip()]\r\n\r\n        if not split_items:\r\n            raise ValueError(\"No valid content found after splitting by '------'.\")\r\n\r\n        # Build dictionary with Query1, Query2, ...\r\n        data_dict = {f\"Sub_Query{i+1}\": chunk for i, chunk in enumerate(split_items)}\r\n\r\n        # Wrap in Langflow Data object\r\n        data_obj = Data(data=data_dict)\r\n\r\n        # Update component status in UI\r\n        self.status = f\"Created Data with {len(split_items)} queries.\"\r\n        \r\n        \r\n\r\n        return data_obj\r\n"
              },
              "message": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input Message",
                "dynamic": false,
                "info": "The message whose text will be split by '------'.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "message",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SplitMessageToQueryData"
        },
        "dragging": false,
        "id": "SplitMessageToQueryData-jIQQY",
        "measured": {
          "height": 260,
          "width": 320
        },
        "position": {
          "x": 5292.664775386178,
          "y": 2497.5700432414
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-Hy5jf",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "Text Input",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "hidden": null,
                "method": "text_response",
                "name": "text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "* [0000-MAINLINE]: The main program flow that coordinates all other functions. It displays parameter information, opens files, validates parameters, initializes variables, reads input records, processes data, generates reports, and closes files. From [Summary_CWKTDATE(1).md]\n;;;;;;\n* [9000-OPEN]: Opens the input employee file and output report file for reading and writing. This is a critical step for establishing file connections before processing begins. From [Summary_CWKTDATE(1).md]\n;;;;;;\n* [9100-CHECK-PARM]: Validates input parameters including parameter length and data format. It checks if the parameter length is valid (0 or 5) and if the parameter data is numeric when length is 5. From [Summary_CWKTDATE(1).md]\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-Hy5jf",
        "measured": {
          "height": 212,
          "width": 320
        },
        "position": {
          "x": 4790.828516366764,
          "y": 2872.2750680639615
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DataToDataFrame-3U1Qo",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Converts one or multiple Data objects into a DataFrame. Each Data object corresponds to one row. Fields from `.data` become columns, and the `.text` (if present) is placed in a 'text' column.",
            "display_name": "Data → DataFrame",
            "documentation": "",
            "edited": true,
            "field_order": [
              "data_list"
            ],
            "frozen": false,
            "icon": "table",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "hidden": null,
                "method": "build_dataframe",
                "name": "dataframe",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.DataOperations",
              "processing.TypeConverterComponent"
            ],
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import DataInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\n\n\nclass DataToDataFrameComponent(Component):\n    display_name = \"Data → DataFrame\"\n    description = (\n        \"Converts one or multiple Data objects into a DataFrame. \"\n        \"Each Data object corresponds to one row. Fields from `.data` become columns, \"\n        \"and the `.text` (if present) is placed in a 'text' column.\"\n    )\n    icon = \"table\"\n    name = \"DataToDataFrame\"\n    legacy = True\n    replacement = [\"processing.DataOperations\", \"processing.TypeConverterComponent\"]\n\n    inputs = [\n        DataInput(\n            name=\"data_list\",\n            display_name=\"Data or Data List\",\n            info=\"One or multiple Data objects to transform into a DataFrame.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"DataFrame\",\n            name=\"dataframe\",\n            method=\"build_dataframe\",\n            info=\"A DataFrame built from each Data object's fields plus a 'text' column.\",\n        ),\n    ]\n\n    def build_dataframe(self) -> DataFrame:\n        \"\"\"Builds a DataFrame from Data objects by combining their fields.\n\n        For each Data object:\n          - Merge item.data (dictionary) as columns\n          - If item.text is present, add 'text' column\n\n        Returns a DataFrame with one row per Data object.\n        \"\"\"\n        data_input = self.data_list[0].data\n\n        # If user passed a single Data, it might come in as a single object rather than a list\n        # if not isinstance(data_input, list):\n        #     data_input = [data_input]\n\n        keys = list(data_input.keys())\n        values = list(data_input.values())\n        \n        \n        # for key, item in data_input.items():\n            \n        #     # if not isinstance(item, Data):\n        #     #     msg = f\"Expected Data objects, got {type(item)} instead.\"\n        #     #     raise TypeError(msg)\n\n        #     # Start with a copy of item.data or an empty dict\n        #     # row_dict = dict(item.data) if item.data else {}\n            \n        #     # # If the Data object has text, store it under 'text' col\n        #     # text_val = item.get_text()\n        #     # if text_val:\n        #     #     row_dict[\"text\"] = text_val\n            \n        #     keys.append({key:item})\n        #     values.append({key:item})\n            # raise ValueError(rows)\n        \n        output_dict = {\"functionID\":keys, \"FunctionDesc\":values}\n\n        # raise ValueError(output_dict)\n        # Build a DataFrame from these row dictionaries\n        df_result = DataFrame(output_dict)\n        self.status = df_result  # store in self.status for logs\n        return df_result\n"
              },
              "data_list": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data or Data List",
                "dynamic": false,
                "info": "One or multiple Data objects to transform into a DataFrame.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data_list",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DataToDataFrame"
        },
        "dragging": false,
        "id": "DataToDataFrame-3U1Qo",
        "measured": {
          "height": 295,
          "width": 320
        },
        "position": {
          "x": 5699.3678507622835,
          "y": 2094.3142633957773
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-qG8s0",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "Function_Info"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "Function_Info": {
                "advanced": false,
                "display_name": "Function_Info",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "Function_Info",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "For below function provide these information base on relavent cobol Summary document in the knowledge base:\n\n{Function_Info}\n\nFirst, list out all the assumptions, including the output of all upstream systems, prerequisite input data existence, parameters setting etc. \nList out all the dependencies, including required upstream and downstream system, required configurations etc. \nList out all the pre and post condition of the function. Describe the state of the system before and after a function executes.\n\nSecond, provide the mermaid flowchart and detailed steps for that function.\nFor both flowcharts and steps, it has to be as detailed as possible to capture all detailed business rules and logic of the function. Assuming the steps will be used for developers to write java code and microservice to reproduce the function. Therefore, detailed fields, validation rules, default values, error handling must be clearly stated in the steps.\nExample:\n- Minimum age must be 18 years.\n- Interest = Principal × Rate × Duration / 100.\n- ERR001: Invalid Account Number\n- INFO002: Transaction Successful\n\nThe steps have to be in sync with the flowchart, to enhance readability. \n\nFinally, describe the outcome of the function. Including any report generated, if exist, or any data to be stored in the database. \n\nWrite no less than 200 words for that function.\nDo not need to generate other section. Only need to generate the Function part.\nProvide the Function of all the cobol Summary document in below md format.\n\n\t\n* **`[Function name 1]`**: \n\n\t* **`[Purpose]`**: High level purpose of this function. Include the function descripion and participants involved. \n\n\t* **Function 1 Assumption**:\n\t\t* `[Assumption 1]`: Detailed Assumption descripion. \n\t\t* `[Assumption 2]`: Detailed Assumption descripion. \n\n\t* **Function 1 Dependency**:\n\t\t* `[Dependency 1]`: Detailed Dependency descripion. \n\t\t* `[Dependency 2]`: Detailed Dependency descripion. \n\t\t\n\t* **Function 1 Precondition**:\n\t\tPrecondition for this function if exist.\n\t\n\t```mermaid\n\tgraph TD\n\t\tflowchart for Function 1\n\t```\n\n\t\t* [Step 1, describe the first step of Function 1 in detail]\n\t\t* [Step 2, describe the second step of Function 1 in detail]\n\t\t...\n\t\n\t* **Function 1 Outcome**: Describe the expected outcome for function 1, if exist. Including any generated report if exist or data stored in database.\n\t\n\t* **Function 1 Postcondition**:\n\t\tPostcondition for this function if exist. What will be the system status after the function completes successfully or fails."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-qG8s0",
        "measured": {
          "height": 374,
          "width": 320
        },
        "position": {
          "x": 7043.807781695911,
          "y": 2082.539382929405
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-4RSNH",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{FunctionDesc}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "id": "ParserComponent-4RSNH",
        "measured": {
          "height": 336,
          "width": 320
        },
        "position": {
          "x": 6589.092811742792,
          "y": 2112.853714259613
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "RAGFlowChatModel-Miup3",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "sunshine_coder",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using RAGFlow.",
            "display_name": "RAGFlow Chat Model",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "ragflow_ca_bundle",
              "ragflow_chat_base_url",
              "ragflow_chat_id",
              "ragflow_chat_api_key",
              "timeout",
              "max_retries",
              "model_name",
              "temperature",
              "max_tokens",
              "json_mode",
              "use_responses_api",
              "model_kwargs"
            ],
            "frozen": false,
            "icon": "SunshineCoder",
            "key": "RAGFlowChatModel",
            "last_updated": "2025-10-30T03:36:33.500Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import httpx\nimport ssl\n\nfrom typing import Any\nfrom pydantic.v1 import SecretStr\nfrom langchain_openai import ChatOpenAI\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    IntInput,\n    MessageInput,\n    MultilineInput,\n    SecretStrInput,\n    SliderInput,\n    StrInput,\n)\nfrom langflow.components.sunshine_coder.constants import (\n    CA_BUNDLE,\n    RAGFLOW_CHAT_BASE_URL,\n    RAGFLOW_CHAT_MODEL_LIST,\n)\nfrom langflow.logging import logger\n\n\nclass RAGFlowChatModelComponent(LCModelComponent):\n    name = \"RAGFlowChatModel\"\n    display_name = \"RAGFlow Chat Model\"\n    description = \"Generates text using RAGFlow.\"\n    icon = \"SunshineCoder\"\n    inputs = [\n        *LCModelComponent._base_inputs,\n        MultilineInput(\n            name=\"ragflow_ca_bundle\",\n            display_name=\"RAGFlow CA Bundle\",\n            info=\"Leave empty unless you're using a self-signed certificate. \"\n            \"Paste the entire certificate including the '-----BEGIN/END CERTIFICATE-----' lines. \"\n            \"Not sure? Just leave it blank!\",\n            value=CA_BUNDLE,\n            advanced=True,\n            dynamic=True,\n        ),\n        StrInput(\n            name=\"ragflow_chat_base_url\",\n            display_name=\"RAGFlow Chat Base URL\",\n            value=RAGFLOW_CHAT_BASE_URL,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"ragflow_chat_id\",\n            display_name=\"RAGFlow Chat Id\",\n            required=True\n        ),\n        SecretStrInput(\n            name=\"ragflow_chat_api_key\",\n            display_name=\"RAGFlow Chat API Key\",\n            required=True\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            value=600,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            value=3,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=RAGFLOW_CHAT_MODEL_LIST,\n            value=RAGFLOW_CHAT_MODEL_LIST[0],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=262144),\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"use_responses_api\",\n            display_name=\"Use Responses API\",\n            info=\"Whether to use the Responses API instead of the Chat API.\",\n            advanced=True,\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            info=\"Additional keyword arguments to pass to the model.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        self.log(f\"Executing request with model: {self.model_name}\")\n        ssl_ctx = None\n        if self.ragflow_ca_bundle:\n            try:\n                ssl_ctx = ssl.create_default_context()\n                ssl_ctx.load_verify_locations(cadata=self.ragflow_ca_bundle)\n            except (ssl.SSLError, ValueError) as e:\n                logger.error(f\"Failed to load CA bundle: {e}\")\n                raise ValueError(f\"Invalid CA bundle: {e}\") from e\n        parameters = {\n            \"base_url\": self.ragflow_chat_base_url + \"/\" + self.ragflow_chat_id,\n            \"api_key\": (\n                SecretStr(self.ragflow_chat_api_key).get_secret_value()\n                if self.ragflow_chat_api_key\n                else None\n            ),\n            \"timeout\": self.timeout,\n            \"max_retries\": self.max_retries,\n            \"model_name\": self.model_name,\n            \"temperature\": self.temperature,\n            \"max_tokens\": self.max_tokens or None,\n            \"use_responses_api\": self.use_responses_api or None,\n            \"model_kwargs\": self.model_kwargs or {},\n        }\n        output = ChatOpenAI(\n            http_client=httpx.Client(verify=ssl_ctx) if self.ragflow_ca_bundle else None,\n            http_async_client=httpx.AsyncClient(verify=ssl_ctx) if self.ragflow_ca_bundle else None,\n            **parameters\n        )\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(\n        self, build_config: dict, field_value: Any, field_name: str | None = None\n    ) -> dict:\n        build_config[\"temperature\"][\"show\"] = True\n        if \"system_message\" in build_config:\n            build_config[\"system_message\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 3
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 262144,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 0
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "external_options": {},
                "info": "",
                "name": "model_name",
                "options": [
                  "qwen3-coder-30b-a3b",
                  "qwen3-30b-a3b-thinking",
                  "qwen3-vl-30b-a3b-thinking"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "qwen3-30b-a3b-thinking"
              },
              "ragflow_ca_bundle": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "RAGFlow CA Bundle",
                "dynamic": true,
                "info": "Leave empty unless you're using a self-signed certificate. Paste the entire certificate including the '-----BEGIN/END CERTIFICATE-----' lines. Not sure? Just leave it blank!",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "ragflow_ca_bundle",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "-----BEGIN CERTIFICATE-----\nMIIFEzCCAvugAwIBAgIQHNtXzZext4JPNifVibRoXzANBgkqhkiG9w0BAQsFADAc\nMRowGAYDVQQDExFOQ1NEZXZOZXQgUm9vdCBDQTAeFw0yMDA0MDIwNjQ5MjBaFw0z\nNTA0MDIwNjU5MTlaMBwxGjAYBgNVBAMTEU5DU0Rldk5ldCBSb290IENBMIICIjAN\nBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAywoxwa5oCujD63Dg+XR2Lre7Nfd/\nNohA4eG5oTbbC3Ng6h95m6QfnyzzrZYcftW8aqRhakIDQITYp9QXR6fJ9DvHxWO9\n7Jb/8TPER7xHPPwiKocPjCNeWPETiWjpNg9YyAzOAwLWJJRNpLzynvdVsD4el6ZD\n43J2iUlohMhE0qGL56PwNgt8Z4BHcr81Ymm8mgpZyaq0CspnzdUQxhZYPsTBqvnh\nzRktfZlNu6C4u9xrGClKNH1Q1H9L8YUoKFf5Y/ePJtNYviAINqvYyDqiba2SnFSC\n4KELQZpLb2SqfEgWLI4T8mSrbAMV17ybsbWxrFrY34dTYA1vKIVQm2ea9sB73Pat\no0uX7gPyZiAneXRXdtwLTBnDz5+PowzE/jwVxth4ZlHq14nODLvrfpjMxmXUDlhO\nuWfpvNiMkWitK5Q6vrPe04V1v7IwNywRb1AqZciPdznOkP79Mv70lUqNid2goYws\ncIOL3sRcDedMuxEtWKIyfyqC38MqgLpjKEfU4ozxrE2nvf2qPrAf4n8KBRy9KDf2\n7BeUr6mJULofseohMh2n3RIljcP02nMVdOy6p9N93AIQwL996Oe0mOikkYU+rFtM\naLHOeCmw7tbASoVymT+ja1NGoO99S7p1UwehF5//pV1PXUQmO5Z3F6fGWebLV6F2\nArnGzR6CXTkdjcECAwEAAaNRME8wCwYDVR0PBAQDAgGGMA8GA1UdEwEB/wQFMAMB\nAf8wHQYDVR0OBBYEFDpqUad1Arn/92XUwq2uqs1hbYtpMBAGCSsGAQQBgjcVAQQD\nAgEAMA0GCSqGSIb3DQEBCwUAA4ICAQACXcOTV7NeAQdvbAM9DO9ef+peFm1oCzJj\nh66VW8wtXknTDykprciB9JRE2ac5fx9xOfIl/gdzVXuddYoVr9JJdD3mKDij0uqS\nkD1BhNxTpc9tD3U5lPcRcjbSXmKGICM+dGG9IUt8Gs0p/NuzYho0P2jDnar8ZFhL\n/BPAFdVifjUlFLRjEE3gET11pSnyaeF6zYrBY6rQVjm3Hk+q/TioAn3P57WCWzzt\nLx2t8WGB8QxZd/A1aBC7TXkOJTOidJp15/98fImyOpu096u9WfRPyrWDCzeUFBkc\n9WeS52P+qlpQksUnLq1c9XJfqGJZiBvf+XeuCLP9S3LXb0ShKyha0xwf3sIos4Hi\ngj7RP30KZRJXXBV9w4RicI/kzCScZhSkvn8EJ2t7qaVJA6v8QVmIQ18R/9inG0TJ\ntRuw7Yfwc+EAdzDp2e4Fijm6wa8OcKx9FGNDKLR6W2o/iGGOrK+5N4L/ZMxXWXtF\nYsJh6dFmWGMmckM0kRXnfIhvQkLv49+lD2np+MzCVeRxvGdEq2/zYjMljyjaTaqA\nYPPrPKH+VqKGXlXHnMM/9UrYw8gj28BRrKfAYbLL38BSOTbsvYa1QqgTvF7u1PDS\nGcLEjC6llllje/0GAo25einsDGvsyUbvn4/gigLYYvE4a1G6oo1Lg4YwhQw5W/s+\nCKGHxKUDLg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIE0zCCA7ugAwIBAgIJANu+mC2Jt3uTMA0GCSqGSIb3DQEBCwUAMIGhMQswCQYD\nVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTERMA8GA1UEBxMIU2FuIEpvc2Ux\nFTATBgNVBAoTDFpzY2FsZXIgSW5jLjEVMBMGA1UECxMMWnNjYWxlciBJbmMuMRgw\nFgYDVQQDEw9ac2NhbGVyIFJvb3QgQ0ExIjAgBgkqhkiG9w0BCQEWE3N1cHBvcnRA\nenNjYWxlci5jb20wHhcNMTQxMjE5MDAyNzU1WhcNNDIwNTA2MDAyNzU1WjCBoTEL\nMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExETAPBgNVBAcTCFNhbiBK\nb3NlMRUwEwYDVQQKEwxac2NhbGVyIEluYy4xFTATBgNVBAsTDFpzY2FsZXIgSW5j\nLjEYMBYGA1UEAxMPWnNjYWxlciBSb290IENBMSIwIAYJKoZIhvcNAQkBFhNzdXBw\nb3J0QHpzY2FsZXIuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA\nqT7STSxZRTgEFFf6doHajSc1vk5jmzmM6BWuOo044EsaTc9eVEV/HjH/1DWzZtcr\nfTj+ni205apMTlKBW3UYR+lyLHQ9FoZiDXYXK8poKSV5+Tm0Vls/5Kb8mkhVVqv7\nLgYEmvEY7HPY+i1nEGZCa46ZXCOohJ0mBEtB9JVlpDIO+nN0hUMAYYdZ1KZWCMNf\n5J/aTZiShsorN2A38iSOhdd+mcRM4iNL3gsLu99XhKnRqKoHeH83lVdfu1XBeoQz\nz5V6gA3kbRvhDwoIlTBeMa5l4yRdJAfdpkbFzqiwSgNdhbxTHnYYorDzKfr2rEFM\ndsMU0DHdeAZf711+1CunuQIDAQABo4IBCjCCAQYwHQYDVR0OBBYEFLm33UrNww4M\nhp1d3+wcBGnFTpjfMIHWBgNVHSMEgc4wgcuAFLm33UrNww4Mhp1d3+wcBGnFTpjf\noYGnpIGkMIGhMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTERMA8G\nA1UEBxMIU2FuIEpvc2UxFTATBgNVBAoTDFpzY2FsZXIgSW5jLjEVMBMGA1UECxMM\nWnNjYWxlciBJbmMuMRgwFgYDVQQDEw9ac2NhbGVyIFJvb3QgQ0ExIjAgBgkqhkiG\n9w0BCQEWE3N1cHBvcnRAenNjYWxlci5jb22CCQDbvpgtibd7kzAMBgNVHRMEBTAD\nAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQAw0NdJh8w3NsJu4KHuVZUrmZgIohnTm0j+\nRTmYQ9IKA/pvxAcA6K1i/LO+Bt+tCX+C0yxqB8qzuo+4vAzoY5JEBhyhBhf1uK+P\n/WVWFZN/+hTgpSbZgzUEnWQG2gOVd24msex+0Sr7hyr9vn6OueH+jj+vCMiAm5+u\nkd7lLvJsBu3AO3jGWVLyPkS3i6Gf+rwAp1OsRrv3WnbkYcFf9xjuaf4z0hRCrLN2\nxFNjavxrHmsH8jPHVvgc1VD0Opja0l/BRVauTrUaoW6tE+wFG5rEcPGS80jjHK4S\npB5iDj2mUZH1T8lzYtuZy0ZPirxmtsk3135+CKNa2OCAhhFjE0xd\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIESzCCAzOgAwIBAgICAQEwDQYJKoZIhvcNAQELBQAwgaExCzAJBgNVBAYTAlVT\nMRMwEQYDVQQIEwpDYWxpZm9ybmlhMREwDwYDVQQHEwhTYW4gSm9zZTEVMBMGA1UE\nChMMWnNjYWxlciBJbmMuMRUwEwYDVQQLEwxac2NhbGVyIEluYy4xGDAWBgNVBAMT\nD1pzY2FsZXIgUm9vdCBDQTEiMCAGCSqGSIb3DQEJARYTc3VwcG9ydEB6c2NhbGVy\nLmNvbTAeFw0yMDA2MDUwNTMyNDRaFw00MTA2MjMwNTMyNDRaMIGuMQswCQYDVQQG\nEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEVMBMGA1UEChMMWnNjYWxlciBJbmMu\nMRUwEwYDVQQLEwxac2NhbGVyIEluYy4xODA2BgNVBAMTL1pzY2FsZXIgSW50ZXJt\nZWRpYXRlIFJvb3QgQ0EgKHpzY2FsZXJ0aHJlZS5uZXQpMSIwIAYJKoZIhvcNAQkB\nFhNzdXBwb3J0QHpzY2FsZXIuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIB\nCgKCAQEAmioqA+ZMX9KzDDO6VXfPWU4dQ3Knj68Y16L50vd6cAxY6CyBclodGxA1\nmwyIv+Q+kV1oaaoowMGjMDQVyCWFa3w7MaiJdx1x0XgtO1u6nEtA7hRaYnJb+/8J\nLRdXjXQpPNRuis7CE/jfpaUn4zikoBWk3GPQ3ZePX8PdQDtPd47Le5AXNd8rCpFR\nMOJSvZYYrlcEWqMbdBs5sSE3B2UKxQ00Qbj8eQHpvH1/aEa48KsY+9q4ZlB2xzS7\nAklK0NFwuebkhR9JTN59o9rxqVwGJhUbQGpUhMnG+g+4b1qrxRsyOFfludc9UjS5\nofjSsZk5ypGZf5W/npp6Ctz+Qc/gkwIDAQABo34wfDAdBgNVHQ4EFgQUB5R6G+iB\ndfUCJzsePyRCVDjsGdkwDAYDVR0TBAUwAwEB/zALBgNVHQ8EBAMCAf4wQAYDVR0f\nBDkwNzA1oDOgMYYvaHR0cDovL2dhdGV3YXkuenNjYWxlcnRocmVlLm5ldC9jcmwv\nenMzLWludC5jcmwwDQYJKoZIhvcNAQELBQADggEBAD4Jc1RkDa/0ktmwdWqEpTGa\nJuKuN8BY9J7yusclOKKXef8XcAH4Zb/D/9sOWc7PSQKZ0jbGcSmuUjkZZfHnpJ8s\nY3chfEdl4BbVYsg1zF+3b0LrD09+8JHYBYIzE1Rc0/WSQtt/wra1aBijDqZWme3t\n/qB7xTH7VyLg0bz5v178+tcbBWyT4YRydInl5rlOFCWheb9wnF0O4wqh2ZdObagf\nxURV25gYLODsE86fWm/GWSTMytp/Cp1+dVpZVqOx2GbTsxhtM+EmTTptu2ixmLMZ\niPwYIidlYicHBgfhnEv6O2ukM3LeD/IeqdCmhptBKgsWDuxj7t/nUgzaETHuJL4=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\n2dbWAFZtIJCBkzFB\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\nKqClq3gnEytH0g==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\nukxwysXvK5fMqjg0G1UVn2pOsgUKGEBzLOwBiq/4xbUja+Y=\n-----END CERTIFICATE-----\n\n\n-----BEGIN CERTIFICATE-----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\nIMLDPEm0C0fPfnNViYnAIx66tXi6cEvSu3cagXeHa8PpAw6O\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----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\nKuaoZ8ZJba4dWrcnuYhfAuZwg/Hcr8YbkzwjdAw2jg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIFHTCCAwWgAwIBAgIQGQAgWCt94IRNpVmNTEmCDDANBgkqhkiG9w0BAQsFADAh\nMR8wHQYDVQQDExZOQ1NEZXZOZXQgUHJvZCBSb290IENBMB4XDTI0MTAwNDA5MTQ0\nNFoXDTQ0MTAwNDA5MjQ0M1owITEfMB0GA1UEAxMWTkNTRGV2TmV0IFByb2QgUm9v\ndCBDQTCCAiIwDQYJKoZIhvcNAQEBBQADggIPADCCAgoCggIBAKeglq4tsgEQuy9u\n1SSFVR0YdjRBBrba95BFRNYYHya8zbvJrUTY3aGwftNGKfvj+PZtLmjwKZUdIIQb\nqXi6ysbC6MBKrREwUxT6j9ONcWvm+pV8kgrFS1+gEt7xSX4KzaIJbR7B2MkR91GV\nQ8rJgDUCYZbbmTEoZ3gZWu+ae8xDfyNcAF12KxyXpdCTwiQ3I84EGUoqW0VlbyNU\nuAc2XIAFB9onQX31gCZLShKE9i41czsi2lXjyXegkuuGfkC1nYbQws4ECXkXl397\nK2GdgJ1E8ePoed26qfYGmu6K4RmfnfY98b7j42n1lu+wwx+Edi//Pus/Sdk29YrX\nA5u5NTq4TVKPocpL1MeOhzc2XshHbKS14ZXdY6VcGWIaGsOB2lJ2b2PEyYytKJVc\nTlr2SUnIRr5Yxn7Dttju1myuOHfDu4AXoYswM5D9MGWT3+HWe2onERd6kICmSe0b\nzaAhH12ml9UUX4UMx0Mw6D4ew//xI2uw8pAv0VzU+r9UontVxuoWMek8zpAimxuY\nPT36oCJUOMkiIEg2ihohNY/+nZ6N3g8s53ldqAn1oGL6sv1SA7B729/yGLIngA6l\nUJ7g5QAtEmR8PcJB2hFRGs2o8eQzrpVZgxM89rikLIPRXCqudLajiIna1iY7TMcA\neESBn86We77wj212hn3G4j+k2j7RAgMBAAGjUTBPMAsGA1UdDwQEAwIBhjAPBgNV\nHRMBAf8EBTADAQH/MB0GA1UdDgQWBBSy94Kn5kkkja5ug0M0yltVMweYCTAQBgkr\nBgEEAYI3FQEEAwIBADANBgkqhkiG9w0BAQsFAAOCAgEACGws1+VsSNwRpy2+sAys\nPAnJ0LF+l0MaW3T3g5c2rExwwR4mYgH9EghWnarLNAO28yxhtemovXcmBWsIurK1\nX0wgYqFBMoizjxtjA4SrqDHqkSMWpsF7yGAMhc3x5MFsM2WCGD3mcjJRPTQmcRRL\nGcGmaUdgm2v+q3BwyRsZAiSgSnrjpPjnFuPI+RF9mOxF5mpsR5DFBCzYp2deptvF\nNnRf506h0nJbCUXbDeAxdacKqL5jO/06hO7OW/uYyc51GE1C5+SM1Wfe4e54KQQM\niXJM/2m7YNtHmJSPCvJzpeEKhMkXRwxmQeRNqFzvxyVBNQaqAmFd2Gij+boDfHBJ\n4KlF77+730RVZeIVL8cTBMizTFkAk7DUsDo+99+M5SNQTuxyQvj1WiUed518DjS5\nZ6dGNhZbNx2bgx0hi0a5C19SvtKa1OFRwCgiS0M6PgVnm59uA3FwHrLwlhhzmVTU\nsCxyTWh7lx1GEPOwXf0NdSn6kXs4X3MWoOAlDslo28a8hN50fkON4JaNcCIi0koQ\n+rCOs9M5G4ZNvQVrkBqccOWUewEn3NNeo+Yy5Nx4kmKn0nZ6bICb0ek/GaWcaGQZ\nEepzgY+Efq00LL8qXH4QWg+B/+rL1rBJndoI1JB0fmtUJSD7XGcim2bYEiE/eSaT\njvlvccMaCzx1UZGSJhZNxiQ=\n-----END CERTIFICATE-----\n\n\n-----BEGIN CERTIFICATE-----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\n-----END CERTIFICATE-----\n"
              },
              "ragflow_chat_api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "RAGFlow Chat API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "ragflow_chat_api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "ragflow_chat_base_url": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "RAGFlow Chat Base URL",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "ragflow_chat_base_url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://ragflow-ui.devnet.int/api/v1/chats_openai"
              },
              "ragflow_chat_id": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "RAGFlow Chat Id",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "ragflow_chat_id",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "4ee54264b4ab11f0b2056ec56199ba7f"
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "# Role\nYou are a professional business analyst with more than 20-year experience in a world class software development company. Having functional user from the bank as the audience of your documentation. The bank is now requesting you to write a functional specification document on the cobol code they provide. Please provide information in a business formal, professional style. Please write in a concise and informative tone. By referring to the knowledge base in the dataset, it gives you a better understanding of the cobol structure and definition. \n\n# Task\nYour primary task is to analyze the COBOL Summary documents and the source codes running on HP non-stop tandem provided by the user and generate a comprehensive, structured Markdown functional document. This document must be purely diecribing the function of all the Summary documents, the document is also code language independent. Focus on the functionality and outcome of the codes and summary.\n\n# Instructions and Workflow\n1.  **Complete Summary Analysis**: First, thoroughly read and understand the entire Summary files including the business logic and funcations. \n\n# Background\nEach module consists of a list of COBOL summary documents in markdown format. Each COBOL summary document summarizes one COBOL source code file. The summaries and the source code are stored in the dataset as a knowledge base. All provided Summary and codes belongs to the same module. \n\n# Constraints and Limitations\n* **Adhere to Original Text**: All explanations and analyses must strictly be based on the provided COBOL code; do not guess or add functionalities do not present in the code.\n* **Professional Terminology**: Use professional and accurate terminology while ensuring clarity.\n* **Language**: Conduct analysis and documentation writing in English.\n* **Format**: Strictly follow the defined Markdown output format below, without omitting any part.\n"
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 3600
              },
              "use_responses_api": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Use Responses API",
                "dynamic": false,
                "info": "Whether to use the Responses API instead of the Chat API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "use_responses_api",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "RAGFlowChatModel"
        },
        "dragging": false,
        "id": "RAGFlowChatModel-Miup3",
        "measured": {
          "height": 783,
          "width": 320
        },
        "position": {
          "x": 7473.665592472462,
          "y": 1722.2207652159404
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TypeConverterComponent-Bj8Tq",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert between different types (Message, Data, DataFrame)",
            "display_name": "Type Convert",
            "documentation": "https://docs.langflow.org/components-processing#type-convert",
            "edited": false,
            "field_order": [
              "input_data",
              "output_type"
            ],
            "frozen": false,
            "icon": "repeat",
            "key": "TypeConverterComponent",
            "last_updated": "2025-11-17T09:33:40.115Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data Output",
                "group_outputs": false,
                "hidden": null,
                "method": "convert_to_data",
                "name": "data_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.008834292878014125,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, Output, TabInput\nfrom langflow.schema import Data, DataFrame, Message\n\n\ndef convert_to_message(v) -> Message:\n    \"\"\"Convert input to Message type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Message: Converted Message object\n    \"\"\"\n    return v if isinstance(v, Message) else v.to_message()\n\n\ndef convert_to_data(v: DataFrame | Data | Message | dict) -> Data:\n    \"\"\"Convert input to Data type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Data: Converted Data object\n    \"\"\"\n    if isinstance(v, dict):\n        return Data(v)\n    if isinstance(v, Message):\n        return v.to_data()\n    return v if isinstance(v, Data) else v.to_data()\n\n\ndef convert_to_dataframe(v: DataFrame | Data | Message | dict) -> DataFrame:\n    \"\"\"Convert input to DataFrame type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        DataFrame: Converted DataFrame object\n    \"\"\"\n    if isinstance(v, dict):\n        return DataFrame([v])\n    return v if isinstance(v, DataFrame) else v.to_dataframe()\n\n\nclass TypeConverterComponent(Component):\n    display_name = \"Type Convert\"\n    description = \"Convert between different types (Message, Data, DataFrame)\"\n    documentation: str = \"https://docs.langflow.org/components-processing#type-convert\"\n    icon = \"repeat\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Input\",\n            input_types=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Accept Message, Data or DataFrame as input\",\n            required=True,\n        ),\n        TabInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Select the desired output data type\",\n            real_time_refresh=True,\n            value=\"Message\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message Output\",\n            name=\"message_output\",\n            method=\"convert_to_message\",\n        )\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"output_type\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n\n            # Add only the selected output type\n            if field_value == \"Message\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Message Output\",\n                        name=\"message_output\",\n                        method=\"convert_to_message\",\n                    ).to_dict()\n                )\n            elif field_value == \"Data\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Data Output\",\n                        name=\"data_output\",\n                        method=\"convert_to_data\",\n                    ).to_dict()\n                )\n            elif field_value == \"DataFrame\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"DataFrame Output\",\n                        name=\"dataframe_output\",\n                        method=\"convert_to_dataframe\",\n                    ).to_dict()\n                )\n\n        return frontend_node\n\n    def convert_to_message(self) -> Message:\n        \"\"\"Convert input to Message type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_message(input_value)\n        self.status = result\n        return result\n\n    def convert_to_data(self) -> Data:\n        \"\"\"Convert input to Data type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_data(input_value)\n        self.status = result\n        return result\n\n    def convert_to_dataframe(self) -> DataFrame:\n        \"\"\"Convert input to DataFrame type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_dataframe(input_value)\n        self.status = result\n        return result\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Accept Message, Data or DataFrame as input",
                "input_types": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_type": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Output Type",
                "dynamic": false,
                "info": "Select the desired output data type",
                "name": "output_type",
                "options": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Data"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TypeConverterComponent"
        },
        "dragging": false,
        "id": "TypeConverterComponent-Bj8Tq",
        "measured": {
          "height": 270,
          "width": 320
        },
        "position": {
          "x": 7913.485080125861,
          "y": 2151.662316500882
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-rtFpp",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Use as a template to create your own component.",
            "display_name": "Custom Component",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "edited": true,
            "field_order": [
              "input_df"
            ],
            "frozen": false,
            "icon": "code",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output",
                "group_outputs": false,
                "hidden": null,
                "method": "build_output",
                "name": "output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# from langflow.field_typing import Data\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import MessageTextInput, Output, DataFrameInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.message import Message\n\n\nclass CustomComponent(Component):\n    display_name = \"Custom Component\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"code\"\n    name = \"CustomComponent\"\n\n    inputs = [\n        DataFrameInput(\n            name=\"input_df\",\n            display_name=\"Input df\",\n            info=\"This is a custom component Input\",\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Message:\n        dataframe = self.input_df\n        # raise ValueError(df)\n        text_series = dataframe[\"text\"].astype(str)\n        concatenated_text = \"\\n\\n\".join(text_series.tolist())\n        return Message(text = concatenated_text)\n"
              },
              "input_df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "Input df",
                "dynamic": false,
                "info": "This is a custom component Input",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_df",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CustomComponent"
        },
        "dragging": false,
        "id": "CustomComponent-rtFpp",
        "measured": {
          "height": 165,
          "width": 320
        },
        "position": {
          "x": 6203.314653237544,
          "y": 2545.4228787883517
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": -1591.2261758108916,
      "y": 758.0998826515532,
      "zoom": 1.269810345486669
    }
  },
  "description": "Driving Innovation in Business Communication.",
  "endpoint_name": null,
  "id": "1cf2e908-dcd4-43b1-b2ab-df12d7607aa0",
  "is_component": false,
  "last_tested_version": "1.7.3",
  "name": "FSD_Gen_Langflow_18Nov",
  "tags": []
}